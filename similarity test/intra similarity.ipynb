{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jafar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import numpy as np\n",
    "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
    "import logging\n",
    "from scipy import stats\n",
    "import random\n",
    "from math import floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database opened successfully\n",
      "5983238\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "q='''SELECT tweet FROM manager_world_tweets_ph2 \n",
    "    Where \n",
    "    tweet_created_at like '%2019%';'''\n",
    "cur.execute(q)\n",
    "rows_mng = cur.fetchall()\n",
    "# there is no repetative tweet\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database opened successfully\n",
      "5237437\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "q='''SELECT tweet FROM ent_world_tweets_ph2 \n",
    "    Where \n",
    "    tweet_created_at like '%2019%';'''\n",
    "cur.execute(q)\n",
    "rows_ent = cur.fetchall()\n",
    "# there is no repetative tweet\n",
    "con.close()\n",
    "\n",
    "print(len(rows_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "Stem=stemmer.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text)   \n",
    "\n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', '', text)\n",
    "\n",
    "    #removing some special charachter  \n",
    "    text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`;•«,@:~!=%&]+\", ' ',text) # except ' ’\n",
    "    \n",
    "    #removing hashtag\n",
    "    text=re.sub('#', '', text) \n",
    "    \n",
    "    #removing numbers\n",
    "    text=re.sub(\"(\\d+)\",' ',text)\n",
    "#    print(text)\n",
    "    #removing numbers (not attached)\n",
    "#    text=re.sub(r\"(^|\\s)-?(\\d+)\\.?(\\d*)(\\s)\", '', text)\n",
    "#    text=re.sub(\"(^||\\d+)\\.(\\d+) \",'',text)\n",
    "#    text=re.sub(\"[0-9+]\\.?(\\d+)(\\.)\",' ',text)\n",
    "#    text=re.sub(\"[0-9+]\\.?(\\d+)($)\",' ',text)\n",
    "#    print(text)\n",
    "    \n",
    "#    return text\n",
    "\n",
    "#def lower_case (text):\n",
    "    text = text.lower() \n",
    "#    print(text)\n",
    "#    return text_lower\n",
    "\n",
    "#def tokenization (text):\n",
    "    text= nltk.word_tokenize(text)\n",
    "#    print (text)\n",
    "#    return text_tokens\n",
    "\n",
    "#def removing_stopwords (text):\n",
    "    #text_without_sw = [word.lower() for word in text if word.lower() not in stopwords.words()]\n",
    "#    text = [word for word in text if word not in stopwords.words()]\n",
    "    text = [word for word in text if word not in cachedStopWords]\n",
    "#    print(text)\n",
    "#    return text_without_sw\n",
    "\n",
    "#def stemming (text):\n",
    "    #stemmer = SnowballStemmer(\"english\")\n",
    "    #text_stems=stemmer.stem(tokens_without_sw)\n",
    "#    text = [stemmer.stem(word) for word in text]\n",
    "    text = [Stem(word) for word in text]\n",
    "\n",
    "#    print(text)\n",
    "    \n",
    "    text=' '.join(text)\n",
    "#    print(text)\n",
    "#    print(text,'\\n')   \n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng_cleaned=[]\n",
    "for tweet in rows_mng:\n",
    "    ans=cleaning(tweet[0])\n",
    "    if ans!=[]:\n",
    "        mng_cleaned.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_cleaned=[]\n",
    "for tweet in rows_ent:\n",
    "    ans=cleaning(tweet[0])\n",
    "    if ans!=[]:\n",
    "        ent_cleaned.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rows_ent[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_words=[]\n",
    "for tweet in ent_cleaned:\n",
    "    ent_words += tweet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng_words=[]\n",
    "for tweet in mng_cleaned:\n",
    "    mng_words += tweet.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For intra similarity, for example, for ent tweets we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chi2=[]\n",
    "p_value=[]\n",
    "\n",
    "for kk in range(3):\n",
    "    \n",
    "    rang=range(len(ent_words))\n",
    "    ind1=random.sample(rang,floor(len(ent_words)/2))\n",
    "    ind2=[x for x in rang if x not in ind1]\n",
    "    \n",
    "    ent1_words_random=[]\n",
    "    for ii in range(len(ind1)):\n",
    "        ent1_words_random.append(ent_words[ind1[ii]])\n",
    "        \n",
    "    ent2_words_random=[]\n",
    "    for ii in range(len(ind2)):\n",
    "        ent2_words_random.append(ent_words[ind2[ii]])  \n",
    "            \n",
    "    all_words=ent_words\n",
    "\n",
    "    d_ent1 = dict()\n",
    "    for c in ent1_words_random:\n",
    "        if c not in d_ent1:\n",
    "            d_ent1[c] = 1\n",
    "        else:\n",
    "            d_ent1[c] = d_ent1[c] + 1\n",
    "\n",
    "    d_ent1_new=dict(sorted(d_ent1.items(), key=lambda x: x[1], reverse=True))\n",
    "    key_list_ent1=list(d_ent1_new.keys())\n",
    "    values_list_ent1=list(d_ent1_new.values())\n",
    "#    print(list(d_ent1_new.keys())[0:10])\n",
    "#    print(list(d_ent1_new.values())[0:10]) \n",
    "#    print()\n",
    "    \n",
    "    d_ent2 = dict()\n",
    "    for c in ent2_words_random:\n",
    "        if c not in d_ent2:\n",
    "            d_ent2[c] = 1\n",
    "        else:\n",
    "            d_ent2[c] = d_ent2[c] + 1\n",
    "            \n",
    "#    print(list(d_ent2_new.keys())[0:10])\n",
    "#    print(list(d_ent2_new.values())[0:10])   \n",
    "#    print()\n",
    "\n",
    "    d_ent2_new=dict(sorted(d_ent2.items(), key=lambda x: x[1], reverse=True))\n",
    "    key_list_ent2=list(d_ent2_new.keys())\n",
    "    values_list_ent2=list(d_ent2_new.values())\n",
    "#    print(list(d_all_new.keys())[0:10])\n",
    "#    print(list(d_all_new.values())[0:10]) \n",
    "#    print()\n",
    "\n",
    "    d_all = dict()\n",
    "    for c in all_words:\n",
    "        if c not in d_all:\n",
    "            d_all[c] = 1\n",
    "        else:\n",
    "            d_all[c] = d_all[c] + 1\n",
    "\n",
    "    d_all_new=dict(sorted(d_all.items(), key=lambda x: x[1], reverse=True))\n",
    "    key_list_all=list(d_all_new.keys())\n",
    "    values_list_all=list(d_all_new.values())\n",
    "        \n",
    "\n",
    "    frequent=key_list_all[0:10] # \n",
    "#    print(frequent)\n",
    "\n",
    "    text1_freq_values=[]\n",
    "    text2_freq_values=[]\n",
    "\n",
    "    for ii in frequent:\n",
    "\n",
    "        text1_freq_values.append(d_ent1_new[ii])\n",
    "        text2_freq_values.append(d_ent2_new[ii])\n",
    "        \n",
    "        \n",
    "#    print(text1_freq_values)  \n",
    "#    print(text2_freq_values)  \n",
    "\n",
    "    chi2_stat, p_val, dof, ex = stats.chi2_contingency([text1_freq_values,text2_freq_values])\n",
    "    chi2.append(chi2_stat)\n",
    "    p_value.append(p_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHI2_mean=np.mean(chi2)\n",
    "CHI2_std=np.std(chi2)\n",
    "P_VALUE_mean=np.mean(p_value)\n",
    "P_VALUE_std=np.mean(p_value)\n",
    "\n",
    "print('chi2:',chi2)\n",
    "print('CHI2_mean:',CHI2_mean)\n",
    "print('CHI2_std:',CHI2_std)\n",
    "print('p_value:',p_value)\n",
    "print('P_VALUE_mean:',P_VALUE_mean)\n",
    "print('P_VALUE_std:',P_VALUE_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example for one random sampling from the ent tweets and ctreating two subsets  we have these frequent words for the two subsets with this frequencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()  \n",
    "rang=range(10)  \n",
    "ind1=random.sample(rang,floor(len(rang)/2))  \n",
    "  \n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_set=set(rang)\n",
    "ind1_set=set(ind1)\n",
    "#ind1_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() \n",
    "ans1=a_set-ind1_set\n",
    "ans1\n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time() \n",
    "ans2=a_set.difference(ind1_set)\n",
    "ans2\n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1==ans2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 2, 5, 6, 9}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=list(ans1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[:floor(len(aa)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 6, 9]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[floor(len(aa)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rang=range(20)\n",
    "slice1_ind=random.sample(rang,floor(20/4))\n",
    "temp=list( set(rang) - set(slice1_ind)  ) # list(a.diference(b))\n",
    "slice2_ind=random.sample(temp,floor(len(temp)/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 7, 18, 15]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice1_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 14, 17, 8, 11]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slice2_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
