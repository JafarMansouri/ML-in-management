{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "### export PYTHONIOENCODING=utf-8  # at cmd of linux\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "import html\n",
    "import xml.sax.saxutils as saxutils\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel,DistilBertTokenizer\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "Stem=stemmer.stem\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemm=wordnet_lemmatizer.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_bert = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )  \n",
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(cachedStopWords))\n",
    "#print(len(cachedStopWords))\n",
    "#print(type(cachedStopWords))\n",
    "\n",
    "nltk_stopwords=set(cachedStopWords)\n",
    "\n",
    "english_alghabet=['b','c','e','f','g','h','j','k','l','n','p','q','r','u','v','w','x','z']\n",
    "\n",
    "numbers_remove=['one','two','three','four','five','six','seven','eight','nine','ten','tens','twenty',\n",
    "                'fourty','fifty','sixty','seventy','eighty','ninety','hundred','hundreds','million','billion','trillion',\n",
    "                'millions','thousand','thousands','second','third','forth','tenth','billions','trillions'] \n",
    "\n",
    "miscellaneous_remove=['absolutely', 'actually', 'adieu', 'ain', \"ain't\", 'aint', 'almost',\n",
    "                       'awesome','awfully','amazing','interesting',\n",
    "                       'alright','alrighty', 'amoungst', 'anybody', 'anymore', 'anyways', 'apart', 'apparently', 'anytime',\n",
    "                       'appropriate',  'approximately', 'arent', 'behold', 'better', 'bravo','briefly','bad','best','brilliant',\n",
    "                       'bye', 'cant', 'certainly', 'chrissakes', 'clearly', 'completely',\n",
    "                       'congrat', 'congrats','congratulation', 'congratulations', 'consequently', 'cool', 'couldnt',\n",
    "                       'darnit', 'de','dear', 'definitely','disappointing', 'didn', 'doesn', 'don', 'downwards',\n",
    "                       'disgusting','dude','down','eg',\"e.g.\",'i.e.',\n",
    "                       'encore','entirely', 'especially', 'et', 'etc', 'everybody', 'ex', 'exactly', 'excellent',\n",
    "                       'fantastic','far', 'farewell','funny',\n",
    "                       'felicitation', 'felicitations','finally', 'fully','furthermore', 'gadzooks', \n",
    "                       'good', 'goodby','goodness', 'gracious', 'great', \n",
    "                       'greetings', 'hallo', 'hardly', 'hasnt', 'haven', 'hello', 'here','hi', 'hither','higher','hopefully',\n",
    "                       'here','there','including',\n",
    "                       'howbeit', 'ie', 'immediately', 'inasmuch', 'inner', 'insofar', 'instead', 'inward', 'important',\n",
    "                       'indeed','just', \"it'd\", \"it'll\", 'inside','kertyschoo', 'kg', 'km', 'lackaday', \n",
    "                       'largely', 'lately', 'later','lovely','large','big','small',\n",
    "                       'lest', 'let', 'lets', 'likely', 'little', 'ltd', 'lower','magnificent', 'mainly', 'marvelous',\n",
    "                       'myself','yourself','yourselves','himself','herself','hisself','ourselves','themsleves',\n",
    "                       'maybe', 'meantime', 'merely', 'minus', 'near', 'nearly', 'necessary', 'never', \n",
    "                       'non', 'normally', 'obviously', 'ok', 'okay', 'ones', 'outside', 'over','other','others','only',\n",
    "                       'overall', 'particular', 'particularly', 'please', 'plus', 'poorly', 'possible','up',\n",
    "                       'possibly', 'potentially', 'predominantly', 'presumably', 'previously','primarily', 'probably',\n",
    "                       'promising',\n",
    "                       'promptly', 'readily', 'really', 'reasonably', 'recent', 'recently', 'ref',\n",
    "                       'refs', 'regardless', 'related', 'relatively', 'respectively', 'resulting', 'right', 'sec', \n",
    "                       'secondly','self', 'selves', 'seriously', 'shall', 'shucks','somebody', 'somethan','sorry',\n",
    "                       'somewhat', 'soon', 'late' , 'sorry', 'stupid', 'sub', 'substantially', 'successfully', 'sufficiently',\n",
    "                       'useful',\n",
    "                       'super', 'sure', \"t's\", 'th', 'thank', 'thanks', 'thanx', \"that've\", 'thats', 'there', \"there'll\",\n",
    "                       \"there've\", 'thered', 'thereof', 'therere', 'theres', 'thereto', 'theyd', 'theyre', 'thorough',\n",
    "                       'then','thankfully','too','today','yesterday','tomorrow','night',\"morning\",'afternoon','noon','tonight',\n",
    "                       'evening','day','everyday', 'everynight','todays','nights','mornings','noons','afternoons','days',\n",
    "                       'evenings','week','month','year',\n",
    "                       'thoroughly', 'tnx', 'too','truly', 'twice', 'undoubtedly','unfortunately', 'unlike','unlikely',\n",
    "                       'unto',  'usually', 'vs', 'welcome', 'well', 'went', 'werent', 'what', 'whatever', 'wheres', 'widely',\n",
    "                       'wonderful', 'wont', 'wouldnt', 'wrong', 'worst','worse','www', 'yes', 'youd', 'youre', 'yummy', \n",
    "                       'zoinks','shit','literally','literal','pleasure','effective','fabulous','delighted',\n",
    "                       'saturday','sunday','monday','tuesday','wednesday','thursday', 'friday','past','future','suitable',\n",
    "                       'much','many','less','least','few','lots','lot','fewer','fewset','therefore','pm',\n",
    "                       'afaik', 'br', 'idk','smh','qotd', 'ftw','bfn','yw', 'icymi','fomo','smdh', 'b4','imho',\n",
    "                       'urdddd','fab' ,'delightful','absolute','pleasure','huge','latest','nowadays',\n",
    "                       'january','february','april','june','july','august','september','october',\n",
    "                       'november','december', 'autumn' ,'spring','winter','summer',\n",
    "                       'mr','madam','sir','mrs','easy', 'difficult',\n",
    "                       'weekend','south','north','west','east','asia','africa','europe','america','totally',\n",
    "                       'come', 'comes', 'coming', 'came', 'seems', 'gives', 'gave', 'makes', 'made', 'keeps', 'kept', \n",
    "                       'calls', 'called', 'says', 'saying', 'said', 'goes', 'went', 'gone', 'got', 'saw', 'seen', 'shows',\n",
    "                       'shown', 'took', 'taken', 'uses', 'moved', 'moves', 'puts',\n",
    "                       'using','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "                       'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use',\n",
    "                       'find', 'finds', 'finding','aka',\n",
    "                       'lol' , 'brb', 'lmk', 'ama', 'tbh', 'irl', \"tl;dr\", 'fml', 'bfn' ,' br', 'ht', \"hth\",'j/k', 'lmao' ] #cool\n",
    "\n",
    "interjection_remove=['aaaahh', 'aaah', 'aaargh', 'aaay', 'aagh', 'aah',\n",
    "                   'aargh', 'achoo', 'adios', 'ah', 'aha', 'ahem', 'ahh', 'ahhh',\n",
    "                   'ahoy', 'alas', 'allo', 'amen', 'areet', 'argh', 'arrggh',\n",
    "                   'arrividerci', 'asap', 'attaboy', 'avaunt', 'aw', 'aw', 'aww',\n",
    "                   'awww', 'ay', 'ay', 'aye', 'ayeaugh', 'bada', 'badum', 'bah',\n",
    "                   'bahaha', 'bam', 'bazinga', 'behold', 'bingce', 'bingo', 'blah',\n",
    "                   'blech', 'bleh', 'blimey', 'bonjour', 'boo', 'booh', 'boohoo',\n",
    "                   'booyah', 'bravo', 'brr', 'brrrr', 'btw', 'bwahaha', 'capeesh',\n",
    "                   'capisce', 'cheerio', 'cheers', 'ciao', 'cor', 'cowabunga',\n",
    "                   'crikey', 'cripes', 'da', 'dabba', 'dah', 'dammit', 'damn', 'dang',\n",
    "                   'darn', 'de', 'dee', 'di', 'dizamn', 'doh', 'doo', 'drat', 'duh',\n",
    "                   'dum', 'eeeek', 'eek', 'eep', 'egad', 'egads', 'eh', 'ehem', 'em',\n",
    "                   'er', 'eureka', 'eww', 'ewww', 'eyh', 'fiddledeedee', 'fie',\n",
    "                   'fore', 'foul', 'fuff', 'gah', 'gak', 'gee', 'geez', 'gesundheit',\n",
    "                   'giddyap', 'golly', 'gosh', 'grr', 'grrrr', 'ha', 'hah', 'haha',\n",
    "                   'hahaha', 'hallelujah', 'halloa', 'harrumph', 'harumph', 'haw',\n",
    "                   'heck', 'heck', 'heeey', 'heh', 'hehe', 'hey', 'hhh', 'hic', 'hm',\n",
    "                   'hmm', 'hmmm', 'hmmmm', 'hmmph', 'hmpf', 'ho', 'hola', 'hoo',\n",
    "                   'hooray', 'howdy', 'hrmm', 'hrmph', 'hrmph', 'hrrmph', 'hu', 'huh',\n",
    "                   'hullo', 'humph', 'hurrah', 'huzza', 'huzzah', 'ich', 'ick',\n",
    "                   'ixnay', 'jeepers', 'jeez', 'kaboom', 'kapow', 'kerwham', 'la',\n",
    "                   'lala', 'lo', 'lordy', 'meh', 'mhm', 'ml', 'mm', 'mmh', 'mmhm',\n",
    "                   'mmm', 'muahaha', 'mwah', 'mwahaha', 'na','nay','nah', 'nanu', 'nooo', 'nope',\n",
    "                   'nuh', 'oh', 'ohh', 'oho', 'oi', 'okeydoke', 'om', 'oof', 'ooh',\n",
    "                   'oomph', 'oooh', 'ooooh', 'oops', 'ouch', 'ow', 'oww', 'oy',\n",
    "                   'oyez', 'oyh', 'pew', 'pff', 'pffh', 'pfft', 'phew', 'phut',\n",
    "                   'phweep', 'phwoar', 'phwoarr', 'poof', 'poogh', 'prethee',\n",
    "                   'prithee', 'prosit', 'pssh', 'psst', 'queep', 'roger', 'salaam',\n",
    "                   'salam', 'sheesh', 'shh', 'shhh', 'shitfire', 'shoo', 'shoop',\n",
    "                   'shush', 'sigh', 'sssh', 'strewth', 'ta', 'tarnations', 'tchah',\n",
    "                   'teehee', 'tish', 'touché', 'tsk', 'tss', 'tut', 'uggh', 'ugh',\n",
    "                   'uh', 'uhh', 'uhm', 'um', 'umm', 'ummm', 'umph', 'unh', 'upadaisy',\n",
    "                   'upsadaisy', 'ur', 'urgh', 'vay', 'vayf', 'viva', 'voila', 'waa',\n",
    "                   'waaaaah', 'waah', 'wah', 'wahey', 'wassup', 'weee', 'welp',\n",
    "                   'wham', 'whamo', 'whee', 'whew', 'whizz', 'whoa',\n",
    "                   'whoo', 'whoopee','whoop', 'whoops', 'whoopsy', 'whoosh', 'woah', 'woo',\n",
    "                   'woohoo', 'wotcha', 'wotcher', 'wow', 'wowsers', 'wowsers',\n",
    "                   'wuzzup', 'wuzzup', 'wuzzup', 'ya', 'yabba', 'yada', 'yadda',\n",
    "                   'yak', 'yarooh', 'yay', 'yea', 'yeah', 'yech', 'yee', 'yeeeeaah',\n",
    "                   'yeehaw', 'yeow', 'yes', 'yessiree', 'yew', 'yikes', 'yippee',\n",
    "                   'yo', 'yoo', 'yoohoo', 'yow', 'yowza', 'yuck', 'yuh', 'zing',\n",
    "                   'zoiks', 'zomfg', 'zomg', 'zounds', 'zut']\n",
    "             \n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "type(spacy_stopwords)\n",
    "#spacy_exclude=['using','name','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "#               'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use']# serious\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "stop_words1 = get_stop_words('english')\n",
    "#print(type(stop_words1))\n",
    "#print()\n",
    "#print(stop_words1)\n",
    "lib_stopwords=set(stop_words1)\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "#print(type(ENGLISH_STOP_WORDS))\n",
    "#print()\n",
    "#print(set(ENGLISH_STOP_WORDS))\n",
    "#sklearn_exclude=['find','get','found','go','see','seem','seems','give','seemed','take','keep','show','put','made'] # system  cry\n",
    "sklearn_stopwords=set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "#spacy_stopwords.difference_update(set(spacy_exclude))\n",
    "#sklearn_stopwords.difference_update(set(sklearn_stopwords))\n",
    "#for removing \"just\" one item, use \"remove\"\n",
    "temp_1=set([])\n",
    "#temp_1.update(nltk_stopwords)\n",
    "#temp_1.update(lib_stopwords)\n",
    "#temp_1.update(sklearn_stopwords)\n",
    "#temp_1.update(spacy_stopwords)\n",
    "#temp_1.update(set(english_alghabet))\n",
    "#temp_1.update(set(numbers_remove)) \n",
    "#temp_1.update(set(miscellaneous_remove))\n",
    "#temp_1.update(set(interjection_remove))\n",
    "#temp_1.update(['rt','be','will','was','were','is','am','are','have','has','had','do','does','done'])\n",
    "#temp_1.update(['rt'])\n",
    "cachedStopWords=temp_1\n",
    "#len(cachedStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "#print(lemmatizer.lemmatize(\"I am loving it\")) #I am loving it\n",
    "#print(lemmatizer.lemmatize(\"loving\")) #loving\n",
    "#print(lemmatizer.lemmatize(\"loving\", \"v\")) #love\n",
    "#print(lemmatize_sentence(\"I am loving it\")) #I be love it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "    \n",
    "    #order of lines is important\n",
    "    \n",
    "    text=strip_tags(text)\n",
    "    #text=html.unescape(text)   # stripping or converting html entities \n",
    "    #text=saxutils.unescape(text) \n",
    "    \n",
    "    #convertings words that their lower and uper cases are different\n",
    "    text=re.sub(\" US | U\\.S\\. \", ' USA ', text) # before lower\n",
    "    \n",
    "    #converting\n",
    "    text = re.sub(\"“|”\", ''' \" ''', text)  #before next lines\n",
    "    text = re.sub(\"’|′|‘|`\", \" ' \", text)  #before next lines\n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', ' ', text)\n",
    "    \n",
    "    #converting lower_case\n",
    "    text = text.lower() \n",
    "    \n",
    "    #converting\n",
    "#    text=re.sub('\\$|£|€|¥|dollar|dollars|yen|yens|euros', ' money ', text)   # not euro \n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text) \n",
    "\n",
    "    #removing emojis and non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', text)  \n",
    "\n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "\n",
    "    '''\n",
    "    #removing common expressions\n",
    "    text=re.sub(\"looking forward to|look forward to|make sure|kidding me|\\\n",
    "                |in my opinion|by the way,|as soon as possible|shaking my head|i don't know|I do not know|\\\n",
    "                |in real life|quote of the day|as far as i know|shake my head|\\\n",
    "                |to be honest|in other words|let me know|just kidding|hope that helps|hat tip|\\\n",
    "                |just like that|happy birthday|never mind|well-done|\\\n",
    "                |in my humble opinion|happy new year|you're welcome|you are welcome| \\\n",
    "                |it doesn't matter|it does not matter|i think|i wonder|do you think\", ' ', text)  \n",
    "    '''\n",
    "    \n",
    "    #convertings\n",
    "    text=re.sub(\"can't\", 'cannot', text) # before other n't \n",
    "    text=re.sub(\"can not \", 'cannot ', text)  \n",
    "    text=re.sub(\"'ve\",' have', text)\n",
    "    text=re.sub(\"n't\",' not', text)\n",
    "    text=re.sub(\"'ll\",' will', text)\n",
    "#    text=re.sub(\"'d\",' would', text)\n",
    "    text=re.sub(\"'re\",' are', text)\n",
    "    text=re.sub(\"i'm\",'i am', text)\n",
    "    text=re.sub(\"&\",' and ', text)\n",
    "    text=re.sub(\" w/ \",' with ', text)\n",
    "    text=re.sub(\" w/i | w/in \",' within ', text)\n",
    "    text=re.sub(\" w/o \",' without ', text)\n",
    "    text=re.sub(\" c/o \",' care of ', text)\n",
    "    text=re.sub(\" h/t \",' hat tip ', text)\n",
    "    text=re.sub(\" b/c \",' because ', text)\n",
    "#    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"=\",' = ', text)\n",
    "#    text=re.sub(\"\\+\",' plus ', text)\n",
    "    text=re.sub(\"\\+\",' + ', text)\n",
    "    text=re.sub(\"united states\",'usa', text)\n",
    "    text=re.sub(\"united kingdom\",'uk', text)\n",
    "    text=re.sub(\" the us \",' usa ', text)\n",
    "    text=re.sub(\"start-up|start_up\",'startup', text)\n",
    "    text=re.sub(\"u\\.s\\.a\", 'usa', text)  #try text=re.sub(\"u.s.a\", 'usa', text) with text=substantially \n",
    "    #text=re.sub(\"aka\", 'also known as', text)     \n",
    "    text=re.sub(\"'\",\" ' \", text)     \n",
    "    \n",
    "    text= re.sub(\"(\\?)+\", '? ',text)     \n",
    "    text= re.sub(\"(!)+\", '! ',text)     \n",
    "    text= re.sub(\"(\\.\\.)+\", ' ',text)   \n",
    "\n",
    "#    text = \"\".join(lemmatize_sentence(text))\n",
    "    \n",
    "    #removing some special charachter  \n",
    "#    text= re.sub(\"[\\\"\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]``<>\\.{}`′’‘'_;•«»,@:~!\\=%&]+\", ' ',text) \n",
    "#    text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`′’‘';•«,@:~!\\=%&]+\", ' ',text) \n",
    "    \n",
    "    #removing hashtag\n",
    "#    text=re.sub('#', ' ', text) \n",
    "    \n",
    "    #removing numbers not attached to alphabets\n",
    "    '''\n",
    "    text=re.sub(\"(^)(\\d+)?(\\.)?(\\d+)? \",' ',text)   #removing numer at the beginning\n",
    "    text=re.sub(\"(\\s)[0-9]?(\\.)?(\\d+) \",' ',text) #py6 and py9\n",
    "    text= re.sub(\" (\\.)(\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+)$\", ' ',text)\n",
    "    '''\n",
    "    #text=re.sub(\"\\S+(\\d+) \",' ',text) # alphabet+digit (attached)\n",
    "    #text=re.sub(\" (\\d+)\\S+\",' ',text) # digit+alphabet (attached)\n",
    "    #text=re.sub(\" \\S+(\\d+)\\S+ \",' ',text) # alphabet+digit+alphabet (attached)\n",
    "    #text=re.sub(\"(\\d+)\",' ',text)  #removing any number anywhere but keeps \\. for decimal numbers\n",
    "\n",
    "    #removing space\n",
    "    text=re.sub('\\s+',' ',text)    \n",
    "    \n",
    "    text=re.sub('(^)rt ','',text)    # if we do not want to remove stopwords\n",
    "\n",
    "#    text= nltk.word_tokenize(text) # necessary for removing stopwords\n",
    "    #text= text.split() #sometimes\n",
    "\n",
    "    #removing_stopwords \n",
    "    #text_without_sw = [word.lower() for word in text if word.lower() not in stopwords.words()] #very slow\n",
    "#    text = [word for word in text if word not in cachedStopWords]\n",
    "\n",
    "    #lemmatization\n",
    "    #text= [ lemm(word, pos=\"v\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"n\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"a\") for word in text]\n",
    "    \n",
    "    #stemming \n",
    "    #text = [Stem(word) for word in text]\n",
    "    \n",
    "#    text=' '.join(text)\n",
    "#    text=re.sub(\"''\",'''\"''', text)    #since nltk.tokenize converts second \" to ''\"\n",
    "#    text=re.sub(\"``\",'''\"''', text)   # since nltk.tokenize converts first \" to \" ``\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(text):\n",
    "    text=text.translate(str.maketrans({'&': ' & ', '#': ' # ' , '\\\"':' \" ', '\\+': ' + ', '\\-': ' - ',\n",
    "                                       '\\|': ' | ', '\\*': ' * ', '\\?': ' ? ', '\\(':' ( ', '\\)':' ) ',\n",
    "                                       '\\/': ' / ', '\\\\':' \\ ', '\\^':' ^ ', '\\[':' [ ', '\\]':' ] ', \n",
    "                                       '<': ' < ', '>':' > ', '\\.':' . ' , '{':' { ', '}': ' } ', '`': ' ` ',\n",
    "                                       '′':' ′ ', '’':' ’ ', '‘':' ‘ ', \"'\":\" ' \", ';': ' ; ','•':' • ', '«':' « ',\n",
    "                                       '»': ' » ', ',':' , ', '@':' @ ', ':':' : ', '\\=': ' =', '!': ' ! ', '~':' ~ ', \n",
    "                                       '%': ' % ' })) #except _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "##cur.execute(\"SELECT user_id, tweet from mng_2019_100K limit 100000 \")\n",
    "cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46502302, 4)\n",
      "Index(['user_id', 'tweet', 'tweet_created_at', 'location_profile'], dtype='object')\n",
      "Number of tweets in mng: 46502302\n",
      "Memory size of mng: 402267520\n"
     ]
    }
   ],
   "source": [
    "#df_mng = pd.read_csv('/archives1/Datasets/TweetsWorld/mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "df_mng = pd.read_csv('mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "print(df_mng.shape)\n",
    "print(df_mng.columns)\n",
    "#print(df_mng.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_mng=list(df_mng[['user_id', 'tweet','tweet_created_at']].itertuples(index=False, name=None)) #rows_mng0\n",
    "#rows_mng= list(zip(df_mng.user_id, df_mng.tweet))\n",
    "#rows_mng=df_mng[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_mng\n",
    "\n",
    "print(\"Number of tweets in mng:\",len(rows_mng))  #rows_mng0\n",
    "print('Memory size of mng:',sys.getsizeof(rows_mng)) #rows_mng0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_mng = pd.read_csv('mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_mng = pd.read_csv('/archives1/Datasets/TweetsWorld/mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_mng.shape)\n",
    "print(df_mng.columns)\n",
    "#print(df_mng.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_mng=list(df_mng[['user_id', 'tweet','tweet_created_at']].itertuples(index=False, name=None)) #rows_mng0\n",
    "#rows_mng= list(zip(df_mng.user_id, df_mng.tweet))\n",
    "#rows_mng=df_mng[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_mng\n",
    "print(len(rows_mng)) #rows_mng0\n",
    "print('memry size of mng:', sys.getsizeof(rows_mng)) #rows_mng0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from public_2019_1000k\")\n",
    "rows_public = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_public))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_public = pd.read_csv('public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "#df_public = pd.read_csv('/archives1/Datasets/TweetsWorld/public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "\n",
    "print(df_public.shape)\n",
    "print(df_public.columns)\n",
    "#print(df_public.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_public00=list(df_public[['user_id', 'tweet', 'tweet_created_at']].itertuples(index=False, name=None))\n",
    "#rows_public= list(zip(df_public.user_id, df_public.tweet))\n",
    "#rows_public=df_public[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_public\n",
    "print(len(rows_public00))\n",
    "print('memory size of public:', sys.getsizeof(rows_public00))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rows_public0=[]\n",
    "for i in rows_public00:\n",
    "    if ('2021' not in i[2] ) and ('2020-12' not in i[2]) and ('2020-11' not in i[2]) and ('2020-10' not in i[2]):\n",
    "        rows_public0.append(i)\n",
    "\n",
    "        \n",
    "print(len(rows_public0))\n",
    "del rows_public00\n",
    "\n",
    "\n",
    "#with open(\"rand_inds3.txt\", \"rb\") as fp:   \n",
    "#    rand_inds3=pickle.load(fp)\n",
    "    \n",
    "    \n",
    "rand_inds0e=np.sort(random.sample(range(0, len(rows_public0)), 1000000))  \n",
    "\n",
    "rows_public=[]\n",
    "for i in rand_inds0e:\n",
    "    rows_public.append(rows_public0[i])\n",
    "print(len(rows_public))\n",
    "\n",
    "del rows_public0\n",
    "\n",
    "\n",
    "with open(\"rand_inds0e.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(rand_inds0e, fp , protocol=4)\n",
    "\n",
    "print('memory size of public:',sys.getsizeof(rows_public))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "year='2018'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mng_filtering.txt\", \"rb\") as fp:   \n",
    "    mng_filter = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/\"+year+\"_seed_mng_pos_1.txt\", \"rb\") as fp:   \n",
    "    id_mng_rel = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/\"+year+\"_seed_mng_neg_1.txt\", \"rb\") as fp:   \n",
    "    id_mng_irrel = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./years/\"+year+\"_tweets_mng_scores_1.txt\", \"rb\") as fp:   \n",
    "#    dic_mng_tweets_scores = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1137835, 808207, 1946042)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_mng_rel), len(id_mng_irrel), len(id_mng_rel)+len(id_mng_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/\"+year+\"_mng_year_ind.txt\", \"rb\") as fp:   \n",
    "    mng_year_ind=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mng_year_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.43217325210571\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "mng_year_ind_all=set()\n",
    "#mng_tweets_rows=[]\n",
    "\n",
    "for k, i in enumerate(rows_mng):\n",
    "    #mng_tweets_rows.append(cleaning(i[1]))\n",
    "    if year in i[2]:\n",
    "        if str(i[0]) not in mng_filter:\n",
    "            mng_year_ind_all.add(k)\n",
    "\n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3375928"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mng_year_ind_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./years/\"+year+\"_mng_year_ind.txt\", \"rb\") as fp:   \n",
    "    mng_year_ind=pickle.load(fp)\n",
    "\n",
    "len(mng_year_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "\n",
    "#mng_users_rows=[]\n",
    "mng_tweets_rows=[]\n",
    "for i in rows_mng:\n",
    "    #mng_users_rows.append(i[0])\n",
    "    mng_tweets_rows.append(cleaning(i[1]))\n",
    "    \n",
    "print( time.time() - t0)\n",
    "\n",
    "#mng_users_rows_np=np.array(mng_users_rows)  \n",
    "#mng_users=np.unique(mng_users_rows_np)\n",
    "#print(len(mng_users))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./years/mng_cleaning_classification.txt\", \"wb\") as fp:  \n",
    "#    pickle.dump(mng_tweets_rows, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/mng_cleaning_classification.txt\", \"rb\") as fp:  \n",
    "    mng_tweets_rows=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "\n",
    "mng_users_rows=[]\n",
    "mng_tweets_rows=[]\n",
    "for i in rows_mng:\n",
    "    mng_users_rows.append(i[0])\n",
    "    mng_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "mng_users_rows_np=np.array(mng_users_rows)  \n",
    "mng_users=np.unique(mng_users_rows_np)\n",
    "print(len(mng_users))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "public_users_rows=[]\n",
    "public_tweets_rows=[]\n",
    "\n",
    "for i in rows_public:\n",
    "    public_users_rows.append(i[0])\n",
    "    public_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "public_users_rows_np=np.array(public_users_rows)  \n",
    "public_users=np.unique(public_users_rows_np)\n",
    "print(len(public_users))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder (tweets):\n",
    "    # padding after {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        \n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if len(tokenized_text)>max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "        segments_ids= segments_ids + [0] * (max_len_tokens+2 - len(segments_ids)) \n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,temp-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder2 (tweets):\n",
    "    #padding before {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = '[CLS]'+ text \n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "#        print(temp)\n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if temp>=max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "        else:\n",
    "#            print(type(tokenized_text))\n",
    "            tokenized_text = tokenized_text + ['[PAD]'] * (max_len_tokens+1 - temp)+ ['[SEP]']\n",
    "#            print('a44',tokenized_text)\n",
    "\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#                sequences, maxlen=10, dtype='int32', padding='post',\n",
    "#                truncating='post', value=0.0)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "#        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "#        segments_ids = [1] * len(tokenized_text)\n",
    "        segments_ids= [1]* min(temp,max_len_tokens+1) + [0] * (max_len_tokens+1 - temp)  + [1]\n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder0 (tweets):\n",
    "    #padding before {SEP} forcing zero\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=30\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "#    print('a11',np.shape(vector_temp))\n",
    "\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "        \n",
    "        \n",
    "                \n",
    "        marked_text = '[CLS]'+ text + '[SEP]'\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)-2\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('a88',len(token_embeddings))\n",
    "        if len(token_embeddings)>=max_len_tokens:\n",
    "            vector_temp= token_embeddings[0:max_len_tokens]\n",
    "#            print('a9',vector_temp)\n",
    "        else:\n",
    "            vector_temp = np.zeros([max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "            vector_temp[0:temp] = token_embeddings\n",
    "#            print('a99',vector_temp)\n",
    "        tweets_embedded[i]=vector_temp\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa=embedder0(['That is very good and joy '])\n",
    "#aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rand_inds1e=random.sample(range(0, 1000000), 300000) #200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"rand_inds1e.txt\", \"wb\") as fp:   \n",
    "#    pickle.dump(rand_inds1e, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "temp_set=set()\n",
    "seed_public0=[]\n",
    "for i in rand_inds1e:\n",
    "    temp=public_tweets_rows[i]\n",
    "    if temp !='' and temp !=' ':\n",
    "        if temp not in temp_set:\n",
    "            seed_public0.append(public_tweets_rows[i])\n",
    "            temp_set.add(temp) # in order that we do not have repetative tweets\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(seed_public0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_public=seed_public0[0:200000]\n",
    "#len(seed_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"./seed_tweets_mng10m.txt\", \"rb\") as fp:   \n",
    "#    seed_tweets_mng = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_mng=[]\n",
    "#for tweet in seed_tweets_mng:\n",
    "#    seed_mng.append(cleaning(tweet))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_mng=seed_mng[0:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "# be careful: it has been changed \n",
    "seed_negative_all=[]\n",
    "for index in id_mng_irrel:\n",
    "    #print(index)\n",
    "    #print(mng_tweets_rows[index])\n",
    "    #print(rows_mng[index])\n",
    "    seed_negative_all.append(mng_tweets_rows[index])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808207"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_negative_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "808207"
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_mng_irrel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle=math.floor(len(seed_negative_all)/2)\n",
    "num=50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rand_inds_n=np.sort(random.sample(range(0, len(seed_negative_all)), num ))\n",
    "\n",
    "seed_negative=[]\n",
    "for i in rand_inds_n:\n",
    "    seed_negative.append(seed_negative_all[i])\n",
    "print(len(seed_negative) )  \n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_neg=[]\n",
    "for i in rand_inds_n:\n",
    "    id_neg.append(id_mng_irrel[i])\n",
    "\n",
    "len(id_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_negative=seed_negative_all[0:len(seed_negative_all)]\n",
    "#seed_negative=seed_negative_all[0:num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_negative=seed_negative_all[len(seed_negative_all)-num:len(seed_negative_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mng_all=[]\n",
    "for index in id_mng_rel:\n",
    "    #print(index)\n",
    "    #print(mng_tweets_rows[index])\n",
    "    #print(rows_mng[index]) \n",
    "    seed_mng_all.append(mng_tweets_rows[index])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1137835"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_mng_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mng=seed_mng_all[0:len(seed_negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seed_mng=seed_mng_all[len(seed_mng_all)-len(seed_negative):len(seed_mng_all)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rand_inds_p=np.sort(random.sample(range(0, len(seed_mng_all)), len(seed_negative)))  \n",
    "\n",
    "seed_mng=[]\n",
    "for i in rand_inds_p:\n",
    "    seed_mng.append(seed_mng_all[i])\n",
    "print(len(seed_mng))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "id_pos=[]\n",
    "for i in rand_inds_p:\n",
    "    id_pos.append(id_mng_rel[i])\n",
    "\n",
    "len(id_pos)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_mng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=[1]*len(seed_mng)+[0]*len(seed_negative)\n",
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0:10], y_data[-10:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_mng = pd.DataFrame({'tweet':seed_mng})\n",
    "df_mng['len'] = df_mng['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "df_mng\n",
    "\n",
    "print('mng')\n",
    "print(\"mean length of tweets: \" + str(df_mng['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_mng['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_mng['len'].std()))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_public = pd.DataFrame({'tweet':seed_public})\n",
    "df_public['len'] = df_public['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_public\n",
    "\n",
    "print('public')\n",
    "print(\"mean length of tweets: \" + str(df_public['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_public['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_public['len'].std()))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 503,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data=seed_mng+seed_negative\n",
    "len(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices=np.arange(len(x_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 505,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set size 80000\n",
      "test set size 20000\n"
     ]
    }
   ],
   "source": [
    "train_texts, test_texts, y_train, y_test,idx1,idx2 = train_test_split(x_data, y_data,indices ,test_size=0.2,shuffle=True, stratify= y_data)\n",
    "print(\"train set size \" + str(len(train_texts)))\n",
    "print(\"test set size \" + str(len(test_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 0, 1, 0, 1, 1, 0, 0],\n",
       " [0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       " array([42594,  8746, 16597, 60984, 47711, 63747, 20171,  7926, 78875,\n",
       "        58980]))"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10],y_test[0:10],idx1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=embedder0(mng_all[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_texts=seed_mng+seed_public\n",
    "#len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in mng_tweets_rows:\n",
    "#    texts.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "#tknzr.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.64244031906128"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0=time.time()\n",
    "train_texts_tokens=[]\n",
    "for text in train_texts:\n",
    "#    tokens=text.split()\n",
    "    #tokens=nltk.word_tokenize(text)\n",
    "    tokens=tknzr.tokenize(text)\n",
    "    train_texts_tokens.append(tokens)\n",
    "    \n",
    "print(len(train_texts_tokens))\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext.util.reduce_model(ft, 100)\n",
    "#ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.880743741989136"
      ]
     },
     "execution_count": 516,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "embedding_dim=300\n",
    "max_tokens=50\n",
    "#X_train_test=[]\n",
    "x_train=np.zeros([len(train_texts_tokens),max_tokens,embedding_dim],dtype='float32')\n",
    "\n",
    "for kk,tokens in enumerate(train_texts_tokens):\n",
    "    if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "        a1=[]\n",
    "        for token in tokens:\n",
    "            a1.append( ft.get_word_vector(token) )\n",
    "                    \n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "        if len(tokens)>max_tokens:\n",
    "            temp=a1[0:max_tokens]\n",
    "        elif len(tokens)==max_tokens:\n",
    "            temp=a1\n",
    "        else: # if len(tokens)<max_tokens:\n",
    "            temp[0:len(tokens)]=a1\n",
    "#        X_train_test.append(temp) \n",
    "        x_train[kk]=temp\n",
    "\n",
    "    else:\n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "#        X_train_test.append(temp)\n",
    "        x_train[kk]=temp\n",
    "        \n",
    "time.time()-t0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train, tf.float32)\n",
    "y_train = tf.cast(y_train, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train1, x_test1, y_train, y_test = train_test_split(data, y_data, test_size=0.2, shuffle=True, stratify= y_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=50\n",
    "num_filters=100\n",
    "embedding_dim=300   #768 for bert\n",
    "dropout_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 50, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 50, 300, 1)   0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 50, 1, 100)   30100       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 49, 1, 100)   60100       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 48, 1, 100)   90100       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 47, 1, 100)   120100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 46, 1, 100)   150100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 45, 1, 100)   180100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 44, 1, 100)   210100      reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 50, 1, 100)   400         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 49, 1, 100)   400         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 48, 1, 100)   400         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 47, 1, 100)   400         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 46, 1, 100)   400         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 45, 1, 100)   400         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 44, 1, 100)   400         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_49 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_52 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_53 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_54 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_55 (MaxPooling2D) (None, 1, 1, 100)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 1, 700)    0           max_pooling2d_49[0][0]           \n",
      "                                                                 max_pooling2d_50[0][0]           \n",
      "                                                                 max_pooling2d_51[0][0]           \n",
      "                                                                 max_pooling2d_52[0][0]           \n",
      "                                                                 max_pooling2d_53[0][0]           \n",
      "                                                                 max_pooling2d_54[0][0]           \n",
      "                                                                 max_pooling2d_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 700)          0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_56 (Dense)                (None, 512)          358912      flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_49 (Dropout)            (None, 512)          0           dense_56[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_57 (Dense)                (None, 256)          131328      dropout_49[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_50 (Dropout)            (None, 256)          0           dense_57[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_58 (Dense)                (None, 128)          32896       dropout_50[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_51 (Dropout)            (None, 128)          0           dense_58[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_59 (Dense)                (None, 64)           8256        dropout_51[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_52 (Dropout)            (None, 64)           0           dense_59[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_60 (Dense)                (None, 32)           2080        dropout_52[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_53 (Dropout)            (None, 32)           0           dense_60[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 16)           528         dropout_53[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_54 (Dropout)            (None, 16)           0           dense_61[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 8)            136         dropout_54[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_55 (Dropout)            (None, 8)            0           dense_62[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 1)            9           dropout_55[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 1,377,645\n",
      "Trainable params: 1,376,245\n",
      "Non-trainable params: 1,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "#inputs = Input(shape=(sequence_length,), dtype='float32')\n",
    "\n",
    "#embedded_inputs = embedding_layer(inputs)\n",
    "#embedding_layer = Embedding(input_dim=20000, output_dim=embedding_dim, input_length=sequence_length, weights=[inputs])(inputs)\n",
    "\n",
    "#inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(embedded_inputs)\n",
    "inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(1, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_1 = LeakyReLU(alpha=0.2)(conv_1) #without activation at Conv2D\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(2, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_2 = LeakyReLU(alpha=0.2)(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_3 = LeakyReLU(alpha=0.2)(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_4 = LeakyReLU(alpha=0.2)(conv_4)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_5 = LeakyReLU(alpha=0.2)(conv_5)\n",
    "conv_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(num_filters, kernel_size=(6, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_6 = LeakyReLU(alpha=0.2)(conv_6)\n",
    "conv_6 = BatchNormalization()(conv_6)\n",
    "\n",
    "conv_7 = Conv2D(num_filters, kernel_size=(7, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_7 = LeakyReLU(alpha=0.2)(conv_7)\n",
    "conv_7 = BatchNormalization()(conv_7)\n",
    "\n",
    "#conv_8 = Conv2D(num_filters, kernel_size=(8, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_8 = LeakyReLU(alpha=0.2)(conv_8)\n",
    "#conv_8 = BatchNormalization()(conv_8)\n",
    "\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 1 + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 2 + 1, 1), strides=(1,1))(conv_2)\n",
    "maxpool_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1))(conv_3)\n",
    "maxpool_4 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1))(conv_4)\n",
    "maxpool_5 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1))(conv_5)\n",
    "maxpool_6 = MaxPool2D(pool_size=(sequence_length - 6 + 1, 1), strides=(1,1))(conv_6)\n",
    "maxpool_7 = MaxPool2D(pool_size=(sequence_length - 7 + 1, 1), strides=(1,1))(conv_7)\n",
    "#maxpool_8 = MaxPool2D(pool_size=(sequence_length - 8 + 1, 1), strides=(1,1))(conv_8)\n",
    "\n",
    "#concatenated_m1 = Concatenate(axis=3)([maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5])\n",
    "concatenated_m1 = Concatenate(axis=3)([ maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5, maxpool_6, maxpool_7 ])\n",
    "\n",
    "X = Flatten()(concatenated_m1)\n",
    "\n",
    "X = Dense(units=512, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=256, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=128, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=64, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=32, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=16, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=8, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "#outputs = Dense(units=5, activation='softmax')(X) \n",
    "outputs = Dense(units=1, activation='sigmoid')(X) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "classifier.summary()\n",
    "#classifier.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3) , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.compile(optimizer=keras.optimizers.Adamax() , loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#optim= adamax, adam\n",
    "#loss:categorical_crossentropy, KLDivergence, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# not good results ##type 2( small kernels like images)\n",
    "#sequence_length=16 # or 24 or 32 or 64 \n",
    "##encoder\n",
    "print(sequence_length,embedding_dim)\n",
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "\n",
    "x = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x) \n",
    "print(x.shape)\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "x = Flatten()(x)\n",
    "print(np.shape(x))\n",
    "#x = Dense(1764, activation=\"relu\")(x)\n",
    "\n",
    "#x = Dense(units=8, activation='linear')(x)\n",
    "#x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = Dense(units=5, activation='softmax')(x) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "#optim = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#classifier.compile(optimizer=optim)\n",
    "classifier.compile(optimizer=keras.optimizers.Adam() , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 1., 1., 0., 1., 0., 1., 1., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 50, 300)\n",
      "Epoch 1/10\n",
      "137/137 [==============================] - 168s 1s/step - loss: 0.3042 - accuracy: 0.9552 - val_loss: 0.4848 - val_accuracy: 0.9432\n",
      "Epoch 2/10\n",
      "137/137 [==============================] - 170s 1s/step - loss: 0.2558 - accuracy: 0.9654 - val_loss: 0.2846 - val_accuracy: 0.9735\n",
      "Epoch 3/10\n",
      "137/137 [==============================] - 153s 1s/step - loss: 0.2436 - accuracy: 0.9692 - val_loss: 0.1986 - val_accuracy: 0.9735\n",
      "Epoch 4/10\n",
      "137/137 [==============================] - 157s 1s/step - loss: 0.2096 - accuracy: 0.9742 - val_loss: 0.2042 - val_accuracy: 0.9774\n",
      "Epoch 5/10\n",
      "137/137 [==============================] - 162s 1s/step - loss: 0.2123 - accuracy: 0.9763 - val_loss: 0.1884 - val_accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "137/137 [==============================] - 162s 1s/step - loss: 0.2107 - accuracy: 0.9770 - val_loss: 0.2225 - val_accuracy: 0.9737\n",
      "Epoch 7/10\n",
      "137/137 [==============================] - 162s 1s/step - loss: 0.2008 - accuracy: 0.9785 - val_loss: 0.2868 - val_accuracy: 0.9389\n",
      "Epoch 8/10\n",
      "137/137 [==============================] - 157s 1s/step - loss: 0.1943 - accuracy: 0.9797 - val_loss: 0.1858 - val_accuracy: 0.9857\n",
      "Epoch 9/10\n",
      "137/137 [==============================] - 149s 1s/step - loss: 0.1896 - accuracy: 0.9814 - val_loss: 0.2353 - val_accuracy: 0.9615\n",
      "Epoch 10/10\n",
      "137/137 [==============================] - 167s 1s/step - loss: 0.2006 - accuracy: 0.9798 - val_loss: 0.2086 - val_accuracy: 0.9793\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "#history= classifier.fit(x_train,x_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,batch_size=32,epochs=1000)\n",
    "print(np.shape(x_train))\n",
    "\n",
    "history=classifier.fit(x_train,y_train,\n",
    "                        epochs=10,\n",
    "                        #callbacks=[monitor],\n",
    "                        batch_size=512, # or 64\n",
    "                        shuffle= True,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.125) #0.25\n",
    "\n",
    "#history = classifier.fit(x_train, y_train, epochs=8, batch_size=512, verbose=1, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001B56B579168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001B56B579168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x000001B56B579168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F779D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F779D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F779D8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D4C8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F778B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F778B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F778B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F77288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F77288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B513F77288> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B56A88B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B56A88B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B56A88B438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Layer._handle_weight_regularization.<locals>._loss_for_variable at 0x000001B2E355D8B8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "INFO:tensorflow:Assets written to: ./all_neg_first_pos/2018/case5_mng\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./all_neg_first_pos/2018/case5_mng\\assets\n"
     ]
    }
   ],
   "source": [
    "classifier.save('./all_neg_first_pos/2018/case5_mng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classifier = keras.models.load_model('./all_neg_first_pos/2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# for bert\n",
    "t0=time.time()\n",
    "mng_ind_detected=[]\n",
    "b=mng_tweets_rows[0:200000]\n",
    "mng_test_embedded=embedder0(b)\n",
    "y_predicted=classifier.predict(mng_test_embedded)\n",
    "for ind, value in enumerate(y_predicted):\n",
    "    if value >= 0.5:\n",
    "        mng_ind_detected.append(ind)\n",
    "print(time.time()-t0) \n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B56A88B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B56A88B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x000001B56A88B168> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.65882873535156"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0=time.time()\n",
    "\n",
    "max_tokens=50\n",
    "embedding_dim=300\n",
    "batch_size=1000\n",
    "batch=0\n",
    "#len_mng=len(mng_tweets_rows)\n",
    "len_mng=len(test_texts)\n",
    "\n",
    "results_mng=np.zeros([len_mng,1])\n",
    "\n",
    "while batch <len_mng:\n",
    "    test =  test_texts [batch : batch + batch_size]\n",
    "\n",
    "#    test =  mng_tweets_rows [batch : batch + batch_size]\n",
    "    test_data=[]\n",
    "    \n",
    "    for tweet in test:\n",
    "    #    tokens=text.split()\n",
    "        #tokens=nltk.word_tokenize(tweet)\n",
    "        tokens=tknzr.tokenize(tweet)\n",
    "        if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "            a1=[]\n",
    "            for token in tokens[0:max_tokens]:\n",
    "                a1.append( ft.get_word_vector(token) )\n",
    "            \n",
    "            a1=np.asarray(a1, dtype=np.float32)            \n",
    "            temp=np.zeros([max_tokens,embedding_dim])\n",
    "\n",
    "            if len(tokens)>max_tokens:\n",
    "                temp=a1[0:max_tokens]\n",
    "            elif len(tokens)==max_tokens:\n",
    "                temp=a1\n",
    "            else: #if len(tokens)<max_tokens:\n",
    "                temp[0:len(tokens)]=a1\n",
    "        \n",
    "            #x_test=temp.reshape((1,max_tokens,embedding_dim))  \n",
    "            #print(np.shape(temp))\n",
    "            #x_test = tf.cast(temp, tf.float32)\n",
    "            test_data.append(temp)\n",
    "            \n",
    "        else:\n",
    "            test_data.append(np.zeros([max_tokens,embedding_dim]))\n",
    "              \n",
    "#    test_data = tf.cast(test_data, tf.float32)\n",
    "    test_data = np.asarray(test_data, dtype=np.float32)\n",
    "    res_test=classifier.predict(test_data)\n",
    "    results_mng [ batch: batch +len (res_test)]= res_test\n",
    "    batch += batch_size\n",
    "     \n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20000)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_mng),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97925"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_correct=0\n",
    "for k,i in enumerate(results_mng):\n",
    "    #print(k)\n",
    "    #print(i)\n",
    "    if i>0.5:\n",
    "        temp=1\n",
    "    else:\n",
    "        temp=0\n",
    "    \n",
    "    if temp == y_test[k]:\n",
    "        n_correct +=1\n",
    "        \n",
    "        \n",
    "accuracy=    n_correct/len(results_mng)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/\"+year+\"_tweets_mng_scores_1.txt\", \"rb\") as fp:  \n",
    "    dic_mng_tweets_scores=pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p_set=set(id_pos)\n",
    "n_set=set(id_neg)\n",
    "id_used=p_set.union(n_set)\n",
    "len(id_used)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ind=id_mng_rel +  id_mng_irrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_unused=[]\n",
    "for i in all_ind:\n",
    "    if i not in id_used:\n",
    "        id_unused.append(i)\n",
    "        \n",
    "len(id_unused)   \n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_unused=id_mng_rel[0:len(seed_mng_all)-num]+id_mng_irrel[0:len(seed_negative_all)-num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1446042"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(id_unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rand_inds=np.sort(random.sample(range(0, len(id_unused)), 100000))\n",
    "len(rand_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "id_new=[]\n",
    "for i in rand_inds:\n",
    "    id_new.append(id_unused[i])\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xxx1=set(id_mng_rel[len(seed_mng_all)-num:])\n",
    "yyy1=set(id_mng_irrel[len(seed_negative_all)-num:])\n",
    "for i in id_new:\n",
    "    if i in xxx1 or i in yyy1:\n",
    "        print('yes')\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_test=[]\n",
    "for i in id_new:\n",
    "    new_test.append(mng_tweets_rows[i])\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_test1=seed_mng_all[0:len(seed_mng_all)-num]\n",
    "#len(new_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_test2=seed_negative_all[0:len(seed_negative_all)-num]\n",
    "#len(new_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_test=new_test1+new_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#indices=id_mng_rel[0:len(seed_mng_all)-num]+id_mng_irrel[0:len(seed_negative_all)-num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "new_test=[]\n",
    "new_test_score=[]\n",
    "for i, k in enumerate(seed_mng_all):\n",
    "    if i not in rand_inds3:\n",
    "        new_test.append(k)\n",
    "        new_test_score.append(dic_mng_tweets_scores[id_mng_rel[i]])\n",
    "print(len(new_test))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_test=seed_mng_all[0:len(seed_mng_all)-len(seed_negative)]\n",
    "#len(new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99.18132162094116"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0=time.time()\n",
    "\n",
    "batch_size=1000\n",
    "batch=0\n",
    "\n",
    "len_mng_test_new=len(new_test)\n",
    "\n",
    "results_mng_test_new=np.zeros([len_mng_test_new,1])\n",
    "\n",
    "while batch <len_mng_test_new:\n",
    "    test =  new_test [batch : batch + batch_size]\n",
    "    test_data=[]\n",
    "    \n",
    "    for tweet in test:\n",
    "    #    tokens=text.split()\n",
    "        #tokens=nltk.word_tokenize(tweet)\n",
    "        tokens=tknzr.tokenize(tweet)\n",
    "\n",
    "        if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "            a1=[]\n",
    "            for token in tokens[0:max_tokens]:\n",
    "                a1.append( ft.get_word_vector(token) )\n",
    "            \n",
    "            a1=np.asarray(a1, dtype=np.float32)            \n",
    "            temp=np.zeros([max_tokens,embedding_dim])\n",
    "\n",
    "            if len(tokens)>max_tokens:\n",
    "                temp=a1[0:max_tokens]\n",
    "            elif len(tokens)==max_tokens:\n",
    "                temp=a1\n",
    "            else: #if len(tokens)<max_tokens:\n",
    "                temp[0:len(tokens)]=a1\n",
    "        \n",
    "            #x_test=temp.reshape((1,max_tokens,embedding_dim))  \n",
    "            #print(np.shape(temp))\n",
    "            #x_test = tf.cast(temp, tf.float32)\n",
    "            test_data.append(temp)\n",
    "            \n",
    "        else:\n",
    "            test_data.append(np.zeros([max_tokens,embedding_dim]))\n",
    "              \n",
    "#    test_data = tf.cast(test_data, tf.float32)\n",
    "    test_data = np.asarray(test_data, dtype=np.float32)\n",
    "    res_test=classifier.predict(test_data)\n",
    "    results_mng_test_new [ batch: batch +len (res_test)]= res_test\n",
    "    batch += batch_size\n",
    "     \n",
    "time.time()-t0\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./years/\"+year+\"_tweets_mng_scores_1.txt\", \"rb\") as fp:  \n",
    "    dic_mng_tweets_scores=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8428607, 0.4447795084252878)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mng_rel[0],dic_mng_tweets_scores[id_mng_rel[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35842959, -0.587412610046608)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_mng_irrel[0],dic_mng_tweets_scores[id_mng_irrel[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=list(dic_mng_tweets_scores.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_mng_test_new),len(id_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88258"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "n_correct=0\n",
    "false_values=[]\n",
    "correct_values=[]\n",
    "\n",
    "for k,i in enumerate(results_mng_test_new):\n",
    "    #print(k)\n",
    "    #print(i)\n",
    "    if i>0.5:\n",
    "        temp=1\n",
    "    else:\n",
    "        temp=-1\n",
    "    \n",
    "    #print(k)\n",
    "    #temp1=k+len(seed_public)\n",
    "    #print(temp1)\n",
    "    #print(id_mng_rel[temp1])\n",
    "    #print(dic_mng_tweets_scores[id_mng_rel[temp1]])\n",
    "    #print(dic_mng_tweets_scores[id_mng_rel[len(seed_public)+k]])\n",
    "    if np.sign(temp) == np.sign(dic_mng_tweets_scores[id_new[k]]):\n",
    "        n_correct +=1\n",
    "       # correct_values.append(dic_mng_tweets_scores[id_mng_rel[len(seed_public)+k]])\n",
    "        #correct_values.append(dic_mng_tweets_scores[id_mng_rel[k]])\n",
    "        correct_values.append(dic_mng_tweets_scores[id_new[k]])\n",
    "        \n",
    "    else:\n",
    "        #false_values.append(dic_mng_tweets_scores[id_mng_rel[len(seed_public)+k]])\n",
    "        #false_values.append(dic_mng_tweets_scores[id_mng_rel[k]])\n",
    "        false_values.append(dic_mng_tweets_scores[id_new[k]])\n",
    "        \n",
    "accuracy=    n_correct/len(results_mng_test_new)\n",
    "accuracy\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "positive_values=[]\n",
    "for i in id_mng_rel:\n",
    "    positive_values.append(dic_mng_tweets_scores[i])\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "plt.title('false distribution')\n",
    "plt.xlabel('score')\n",
    "plt.ylabel('number of samples')\n",
    "#n_max=dic_mng_tweets_scores[id_mng_rel[len(seed_public)]]\n",
    "#x = np.random.randn(1000)\n",
    "plt.hist(false_values, bins=40)\n",
    "fig.savefig('./all_neg_first_pos/'+year+'/false_distribution2.jpg')\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "plt.title('correct distribution')\n",
    "plt.xlabel(' score')\n",
    "plt.ylabel('number of samples')\n",
    "#n_max=dic_mng_tweets_scores[id_mng_rel[len(seed_public)]]\n",
    "#x = np.random.randn(1000)\n",
    "plt.hist(correct_values, bins=40)\n",
    "fig.savefig('./all_neg_first_pos/'+year+'/correct_distribution2.jpg')\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in correct_values:\n",
    "    if i<dic_mng_tweets_scores[id_mng_rel[-num]] and i > dic_mng_tweets_scores[id_mng_irrel[-num]]:\n",
    "        print('yes')\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(8, 10))\n",
    "plt.title('all positive distribution')\n",
    "plt.xlabel('positive score')\n",
    "plt.ylabel('number of samples')\n",
    "#n_max=dic_mng_tweets_scores[id_mng_rel[len(seed_public)]]\n",
    "#x = np.random.randn(1000)\n",
    "plt.hist(positive_values, bins=40)\n",
    "fig.savefig('./all_neg_first_pos/2017/all_distribution3.jpg')\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11742, 88258, 100000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(false_values), len(correct_values), len(false_values)+len(correct_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"mng_results300.txt\", \"wb\") as fp:   \n",
    "#    pickle.dump(results_mng, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_mng_numpy=np.asarray(results_mng, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(results_mng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(\"mng_results300_np.txt\", \"wb\") as fp:   \n",
    "#    pickle.dump(results_mng_numpy, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
