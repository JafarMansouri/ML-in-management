{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "import html\n",
    "import xml.sax.saxutils as saxutils\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "    \n",
    "    #order of lines is important\n",
    "    \n",
    "    text=strip_tags(text)\n",
    "    #text=html.unescape(text)   # stripping or converting html entities \n",
    "    #text=saxutils.unescape(text)\n",
    " \n",
    "    \n",
    "    #converting\n",
    "    text = re.sub(\"“|”\", '', text)  #before next lines\n",
    "    text = re.sub(\"’|′|‘|`\", \"\", text)  #before next lines\n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', ' ', text)\n",
    "    \n",
    "    #converting lower_case\n",
    "    text = text.lower() \n",
    "    \n",
    "    #converting\n",
    "    text=re.sub('\\$|£|€|¥|dollar|dollars|yen|yens|euros', ' money ', text)   # not euro \n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text) \n",
    "\n",
    "    #removing emojis and non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', text)  \n",
    "    \n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "\n",
    "    #removing common expressions\n",
    "    '''\n",
    "    text=re.sub(\"looking forward to|look forward to|make sure|kidding me|\\\n",
    "                |in my opinion|by the way,|as soon as possible|shaking my head|i don't know|I do not know|\\\n",
    "                |in real life|quote of the day|as far as i know|shake my head|\\\n",
    "                |to be honest|in other words|let me know|just kidding|hope that helps|hat tip|\\\n",
    "                |just like that|happy birthday|never mind|well-done|\\\n",
    "                |in my humble opinion|happy new year|you're welcome|you are welcome| \\\n",
    "                |it doesn't matter|it does not matter|i think|i wonder|do you think\", ' ', text) \n",
    "    '''\n",
    "    \n",
    "    #convertings\n",
    "    text=re.sub(\"can't\", 'cannot', text) # before other n't \n",
    "    text=re.sub(\"can not \", 'cannot ', text)  \n",
    "    text=re.sub(\"'ve\",' have', text)\n",
    "    text=re.sub(\"n't\",' not', text)\n",
    "    text=re.sub(\"'ll\",' will', text)\n",
    "    #text=re.sub(\"'d\",' would', text)\n",
    "    text=re.sub(\"'re\",' are', text)\n",
    "    text=re.sub(\"i'm\",'i am', text)\n",
    "    text=re.sub(\"&\",' and ', text)\n",
    "    text=re.sub(\" w/ \",' with ', text)\n",
    "    text=re.sub(\" w/i | w/in \",' within ', text)\n",
    "    text=re.sub(\" w/o \",' without ', text)\n",
    "    text=re.sub(\" c/o \",' care of ', text)\n",
    "    text=re.sub(\" h/t \",' hat tip ', text)\n",
    "    text=re.sub(\" b/c \",' because ', text)\n",
    "    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"=\",' = ', text)\n",
    "    text=re.sub(\"\\+\",' + ', text)\n",
    "    text=re.sub(\"\\+\",' plus ', text)\n",
    "    text=re.sub(\"united states\",'usa', text)\n",
    "    text=re.sub(\"united kingdom\",'uk', text)\n",
    "    text=re.sub(\" the us \",' usa ', text)\n",
    "    text=re.sub(\"start-up|start_up\",'startup', text)\n",
    "    text=re.sub(\"u\\.s\\.a\", 'usa', text)  #try text=re.sub(\"u.s.a\", 'usa', text) with text=substantially \n",
    "    text=re.sub(\"aka\", 'also known as', text)     \n",
    "    text=re.sub(\"'\",\" ' \", text)     \n",
    "    \n",
    "    text= re.sub(\"(\\?)+\", '? ',text)     \n",
    "    text= re.sub(\"(!)+\", '! ',text)     \n",
    "    text= re.sub(\"(\\.\\.)+\", ' ',text)   \n",
    "\n",
    "#    text = \"\".join(lemmatize_sentence(text))\n",
    "    \n",
    "    #removing some special charachter  \n",
    "#    text= re.sub(\"[\\\"\\+\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]``<>\\.{}`′’‘';•«»,@:~!\\=%&]+\", ' ',text)  #except _ -\n",
    "#    text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`′’‘';•«,@:~!\\=%&]+\", ' ',text) \n",
    "    \n",
    "\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_words=set(['game','games','gamer','ganmeplay','basketball','nba','football','league','play','playing','player','players',])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database opened successfully\n",
      "46502302\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet, screen_name from mng_world_tweets_ph2_light ;\")\n",
    "#cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_mng0 = pd.read_csv('mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_mng0 = pd.read_csv('/archives1/Datasets/TweetsWorld/mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_mng0.shape)\n",
    "print(df_mng0.columns)\n",
    "print(df_mng0.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_mng=list(df_mng0[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_mng0\n",
    "#rows_mng= list(zip(df_mng0.user_id, df_mng.tweet))\n",
    "#rows_mng=df_mng0[['user_id','tweet']].apply(tuple, axis=1) \n",
    "#df_mng = df_mng0[['user_id', 'tweet','tweet_created_at','location_profile']]\n",
    "\n",
    "del df_mng0\n",
    "\n",
    "print(len(rows_mng)) #rows_mng0\n",
    "print('memry size of mng:', sys.getsizeof(rows_mng)) #rows_mng0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_ent0 = pd.read_csv('ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_ent0 = pd.read_csv('/archives1/Datasets/TweetsWorld/ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_ent0.shape)\n",
    "print(df_ent0.columns)\n",
    "print(df_ent0.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_ent=list(df_ent0[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_ent0\n",
    "#rows_ent= list(zip(df_ent0.user_id, df_ent.tweet))\n",
    "#rows_ent=df_ent0[['user_id','tweet']].apply(tuple, axis=1) \n",
    "#df_ent = df_ent0[['user_id', 'tweet','tweet_created_at','location_profile']]\n",
    "\n",
    "del df_ent0\n",
    "\n",
    "print(len(rows_ent)) #rows_ent0\n",
    "print('memry size of ent:', sys.getsizeof(rows_ent)) #rows_ent0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_public0 = pd.read_csv('public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_public0 = pd.read_csv('/archives1/Datasets/TweetsWorld/public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_public0.shape)\n",
    "print(df_public0.columns)\n",
    "print(df_public0.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_public=list(df_public0[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_public0\n",
    "#rows_public= list(zip(df_public0.user_id, df_public.tweet))\n",
    "#rows_public=df_public0[['user_id','tweet']].apply(tuple, axis=1) \n",
    "#df_public = df_public0[['user_id', 'tweet','tweet_created_at','location_profile']]\n",
    "\n",
    "del df_public0\n",
    "\n",
    "print(len(rows_public)) #rows_public0\n",
    "print('memry size of public:', sys.getsizeof(rows_public)) #rows_public0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database opened successfully\n",
      "47604376\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet, screen_name from ent_world_tweets_ph2_light ;\")\n",
    "#cur.execute(\"SELECT user_id, tweet from ent_2019_1000k \")\n",
    "rows_ent = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_ent))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database opened successfully\n",
      "72182875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet, screen_name from public_world_tweets_ph2_light ;\")\n",
    "#cur.execute(\"SELECT user_id, tweet from public_2019_1000k \")\n",
    "rows_public = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_public))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'25150538'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_mng[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('25150538',\n",
       "  'RT @Z925FM: @Jessica_Z925 is at @AshleyKokomo until noon today with crazy good deals!!! Come out &amp; shop and snag a prize! Girls Scout Cooki…',\n",
       "  'Jessica_Z925'),\n",
       " ('3087448180',\n",
       "  \"RT @MailOnline: New evidence of China's coronavirus cover-up https://t.co/jbGewDBlLC\",\n",
       "  'janet_cutts'),\n",
       " ('1251215371870171136',\n",
       "  'RT @dopeitsdavey: White ppl think this stay at home Order is bad...imagine being inslaved',\n",
       "  '__sassyjazzy'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows_mng[0],rows_ent[0],rows_public[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-7fd975c433ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrows_mng\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mid_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscreen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mid_\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mid_screen_mng\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mid_screen_mng\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscreen\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "id_screen_mng=dict()\n",
    "for i in rows_mng:\n",
    "    id_=i[0]\n",
    "    screen=i[2]\n",
    "    if id_ not in id_screen_mng:\n",
    "        id_screen_mng[id_]=screen\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_mng=dict()\n",
    "for i in rows_mng:\n",
    "    tweet=i[1]\n",
    "    text=strip_tags(tweet)\n",
    "    text=text.lower()\n",
    "    words=text.split()\n",
    "    for word in words:\n",
    "        if word in filter_words:\n",
    "            user_id=i[0]\n",
    "            if user_id not in user_dic_mng:\n",
    "                user_dic_mng[user_id] = 1\n",
    "            else:\n",
    "                user_dic_mng[user_id] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_mng = dict(sorted(user_dic_mng.items(), key=operator.itemgetter(1), reverse=True))\n",
    "user_dic_mng = (sorted(user_dic_mng.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_mng[0],user_dic_mng[0][0],user_dic_mng[5318],id_screen_mng[user_dic_mng[5318][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mng_filter=set()\n",
    "for id_freq in user_dic_mng:\n",
    "    if id_freq[1] >= 100 :\n",
    "        mng_filter.add(int(id_freq[0]))\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mng_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mng_filtering.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(mng_filter, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_screen_ent=dict()\n",
    "for i in rows_ent:\n",
    "    id_=i[0]\n",
    "    screen=i[2]\n",
    "    if id_ not in id_screen_ent:\n",
    "        id_screen_ent[id_]=screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_ent=dict()\n",
    "for i in rows_ent:\n",
    "    tweet=i[1]\n",
    "    text=strip_tags(tweet)\n",
    "    text=text.lower()\n",
    "    words=text.split()\n",
    "    for word in words:\n",
    "        if word in filter_words:\n",
    "            user_id=i[0]\n",
    "            if user_id not in user_dic_ent:\n",
    "                user_dic_ent[user_id] = 1\n",
    "            else:\n",
    "                user_dic_ent[user_id] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_ent = dict(sorted(user_dic_ent.items(), key=operator.itemgetter(1), reverse=True))\n",
    "user_dic_ent = (sorted(user_dic_ent.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ent_filter=set()\n",
    "for id_freq in user_dic_ent:\n",
    "    if id_freq[1] >= 100 :\n",
    "        ent_filter.add(id_freq[0])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5319"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mng_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ent_filtering.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(ent_filter, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_screen_public=dict()\n",
    "for i in rows_public:\n",
    "    id_=i[0]\n",
    "    screen=i[2]\n",
    "    if id_ not in id_screen_public:\n",
    "        id_screen_public[id_]=screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_public=dict()\n",
    "for i in rows_public:\n",
    "    tweet=i[1]\n",
    "    text=strip_tags(tweet)\n",
    "    text=text.lower()\n",
    "    words=text.split()\n",
    "    for word in words:\n",
    "        if word in filter_words:\n",
    "            user_id=i[0]\n",
    "            if user_id not in user_dic_public:\n",
    "                user_dic_public[user_id] = 1\n",
    "            else:\n",
    "                user_dic_public[user_id] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_dic_public = dict(sorted(user_dic_public.items(), key=operator.itemgetter(1), reverse=True))\n",
    "user_dic_public = (sorted(user_dic_public.items(), key=operator.itemgetter(1), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_filter=set()\n",
    "for id_freq in user_dic_public:\n",
    "    if id_freq[1] >= 100 :\n",
    "        public_filter.add(id_freq[0])\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3426"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(public_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"public_filtering.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(public_filter, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.modules[__name__].__dict__.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
