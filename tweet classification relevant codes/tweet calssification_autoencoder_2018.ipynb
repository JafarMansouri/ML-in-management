{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer  \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import Constant  \n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "import html\n",
    "import xml.sax.saxutils as saxutils\n",
    "from io import StringIO\n",
    "from html.parser import HTMLParser\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel,DistilBertTokenizer\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "#from nltk.stem.snowball import SnowballStemmer\n",
    "#stemmer = SnowballStemmer(\"english\")\n",
    "#Stem=stemmer.stem\n",
    "\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#wordnet_lemmatizer = WordNetLemmatizer()\n",
    "#lemm=wordnet_lemmatizer.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_bert = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )  \n",
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(cachedStopWords))\n",
    "#print(len(cachedStopWords))\n",
    "#print(type(cachedStopWords))\n",
    "nltk_stopwords=set(cachedStopWords)\n",
    "\n",
    "english_alghabet=['b','c','e','f','g','h','j','k','l','n','p','q','r','u','v','w','x','z']\n",
    "\n",
    "numbers_remove=['one','two','three','four','five','six','seven','eight','nine','ten','tens','twenty',\n",
    "                'fourty','fifty','sixty','seventy','eighty','ninety','hundred','hundreds','million','billion','trillion',\n",
    "                'millions','thousand','thousands','second','third','forth','tenth','billions','trillions'] \n",
    "\n",
    "\n",
    "miscellaneous_remove=['absolutely', 'actually', 'adieu', 'ain', \"ain't\", 'aint', 'almost','approximately','arent',\n",
    "                      'bravo', 'briefly', 'bye','cant', 'certainly', 'chrissakes', 'clearly', 'completely','couldnt',\n",
    "                      'alright','alrighty', 'apparently', 'brilliant','congrat', 'congrats','congratulation', \n",
    "                      'congratulations','consequently', 'darnit', 'de','dear', 'definitely','didn', 'doesn', 'don',\n",
    "                      'eg','e.g.','i.e.','encore','entirely', 'especially', 'et', 'etc','hopefully','important',\n",
    "                      'ex', 'exactly', 'excellent','fantastic','here','there','hello', 'hi','ie','just', \"it'd\", \"it'll\",\n",
    "                      'felicitation', 'felicitations','finally', 'fully','furthermore', 'gadzooks','hallo',\n",
    "                      'immediately', 'kg', 'km','let', 'lets', 'likely', 'greetings','hardly','hasnt', 'haven', \n",
    "                      'magnificent', 'necessary', 'non','merely', 'then','too',\n",
    "                      'myself','yourself','yourselves','himself','herself','hisself','ourselves','themsleves',\n",
    "                      'maybe', 'never',  'nearly', 'normally', 'obviously', 'ok', 'okay', 'ones',\n",
    "                      'other','others','only', 'great', 'particular', 'particularly', 'please',\n",
    "                      'awesome','awfully','amazing','interesting','amoungst', 'anybody', 'anymore', 'anyways', 'apart', \n",
    "                      'anytime', 'appropriate', 'behold', 'better', 'bad','best', 'good', 'goodby','goodness',\n",
    "                      'aka','lol' , 'brb', 'lmk', 'ama', 'tbh', 'irl', 'tl;dr','overall', 'overally', \n",
    "                      'possibly', 'potentially', 'predominantly', 'presumably', 'previously','primarily', 'probably',\n",
    "                      'promptly', 'readily', 'really', 'reasonably', 'recent', 'recently', 'ref','refs',\n",
    "                      'relatively', 'respectively','substantially', 'successfully', 'sufficiently',\n",
    "                      'sure', \"t's\", 'th', 'thank', 'thanks', 'thanx', \"that've\", 'thats', 'there', \"there'll\",\n",
    "                      \"there've\", 'thered', 'thereof', 'therere', 'theres', 'thereto', 'theyd', 'theyre', \n",
    "                      'thoroughly', 'tnx', 'truly', 'usually','welcome', 'well', 'yes','urdddd','fab' ,\n",
    "                      'much','many','less','least','few','lots','lot','fewer','fewset','therefore','pm',\n",
    "                      'afaik', 'br', 'idk','smh','qotd', 'ftw','bfn','yw', 'icymi','fomo','smdh', 'b4','imho',\n",
    "                      'mr','madam','sir','mrs','easy', 'difficult','totally',\n",
    "                      \n",
    "                      'disappointing',  'downwards', 'disgusting','dude','down',\n",
    "                      'everybody', 'far', 'funny', 'gracious', \n",
    "                      'hither','higher', 'including', 'howbeit',  'inasmuch', 'inner', 'insofar', 'instead', 'inward', \n",
    "                      'indeed', 'inside','kertyschoo',  'lackaday', \n",
    "                      'largely', 'lately', 'later','lovely','large','big','small',\n",
    "                      'lest', 'little', 'ltd', 'lower', 'mainly', 'marvelous', 'meantime', 'minus', 'near',\n",
    "                      'outside', 'over','plus', 'poorly', 'possible','up','promising',\n",
    "                      'regardless', 'related',  'resulting', 'right', 'sec', \n",
    "                      'secondly','self', 'selves', 'seriously', 'shall', 'shucks','somebody', 'somethan',\n",
    "                      'somewhat', 'soon', 'late' , 'sorry', 'stupid', 'sub', 'useful','super', 'thorough',\n",
    "                      'today','yesterday','tomorrow','night',\"morning\",'afternoon','noon','tonight',\n",
    "                      'evening','day','everyday', 'everynight','todays','nights','mornings','noons','afternoons','days',\n",
    "                      'evenings','week','month','year',\n",
    "                      'twice', 'undoubtedly','unfortunately', 'unlike','unlikely',\n",
    "                      'unto',   'vs', 'went', 'werent', 'what', 'whatever', 'wheres', 'widely',\n",
    "                      'wonderful', 'wont', 'wouldnt', 'wrong', 'worst','worse','www',  'youd', 'youre', 'yummy', \n",
    "                      'zoinks','literally','literal','pleasure','effective','fabulous','delighted',\n",
    "                      'saturday','sunday','monday','tuesday','wednesday','thursday', 'friday','past','future','suitable',\n",
    "                      'delightful','absolute','pleasure','huge','latest','nowadays',\n",
    "                      'january','february','april','june','july','august','september','october',\n",
    "                      'november','december', 'autumn' ,'spring','winter','summer',\n",
    "                      'weekend','south','north','west','east','asia','africa','europe','america',\n",
    "                      'come', 'comes', 'coming', 'came', 'seems', 'gives', 'gave', 'makes', 'made', 'keeps', 'kept', \n",
    "                      'calls', 'called', 'says', 'saying', 'said', 'goes', 'went', 'gone', 'got', 'saw', 'seen', 'shows',\n",
    "                      'shown', 'took', 'taken', 'uses', 'moved', 'moves', 'puts',\n",
    "                      'using','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "                      'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use',\n",
    "                      'find', 'finds', 'finding']                  \n",
    "                      \n",
    "\n",
    "interjection_remove=['aaaahh', 'aaah', 'aaargh', 'aaay', 'aagh', 'aah',\n",
    "                   'aargh', 'achoo', 'adios', 'ah', 'aha', 'ahem', 'ahh', 'ahhh',\n",
    "                   'ahoy', 'alas', 'allo', 'amen', 'areet', 'argh', 'arrggh',\n",
    "                   'arrividerci', 'asap', 'attaboy', 'avaunt', 'aw', 'aw', 'aww',\n",
    "                   'awww', 'ay', 'ay', 'aye', 'ayeaugh', 'bada', 'badum', 'bah',\n",
    "                   'bahaha', 'bam', 'bazinga', 'behold', 'bingce', 'bingo', 'blah',\n",
    "                   'blech', 'bleh', 'blimey', 'bonjour', 'boo', 'booh', 'boohoo',\n",
    "                   'booyah', 'bravo', 'brr', 'brrrr', 'btw', 'bwahaha', 'capeesh',\n",
    "                   'capisce', 'cheerio', 'cheers', 'ciao', 'cor', 'cowabunga',\n",
    "                   'crikey', 'cripes', 'da', 'dabba', 'dah', 'dammit', 'damn', 'dang',\n",
    "                   'darn', 'de', 'dee', 'di', 'dizamn', 'doh', 'doo', 'drat', 'duh',\n",
    "                   'dum', 'eeeek', 'eek', 'eep', 'egad', 'egads', 'eh', 'ehem', 'em',\n",
    "                   'er', 'eureka', 'eww', 'ewww', 'eyh', 'fiddledeedee', 'fie',\n",
    "                   'fore', 'foul', 'fuff', 'gah', 'gak', 'gee', 'geez', 'gesundheit',\n",
    "                   'giddyap', 'golly', 'gosh', 'grr', 'grrrr', 'ha', 'hah', 'haha',\n",
    "                   'hahaha', 'hallelujah', 'halloa', 'harrumph', 'harumph', 'haw',\n",
    "                   'heck', 'heck', 'heeey', 'heh', 'hehe', 'hey', 'hhh', 'hic', 'hm',\n",
    "                   'hmm', 'hmmm', 'hmmmm', 'hmmph', 'hmpf', 'ho', 'hola', 'hoo',\n",
    "                   'hooray', 'howdy', 'hrmm', 'hrmph', 'hrmph', 'hrrmph', 'hu', 'huh',\n",
    "                   'hullo', 'humph', 'hurrah', 'huzza', 'huzzah', 'ich', 'ick',\n",
    "                   'ixnay', 'jeepers', 'jeez', 'kaboom', 'kapow', 'kerwham', 'la',\n",
    "                   'lala', 'lo', 'lordy', 'meh', 'mhm', 'ml', 'mm', 'mmh', 'mmhm',\n",
    "                   'mmm', 'muahaha', 'mwah', 'mwahaha', 'na','nay','nah', 'nanu', 'nooo', 'nope',\n",
    "                   'nuh', 'oh', 'ohh', 'oho', 'oi', 'okeydoke', 'om', 'oof', 'ooh',\n",
    "                   'oomph', 'oooh', 'ooooh', 'oops', 'ouch', 'ow', 'oww', 'oy',\n",
    "                   'oyez', 'oyh', 'pew', 'pff', 'pffh', 'pfft', 'phew', 'phut',\n",
    "                   'phweep', 'phwoar', 'phwoarr', 'poof', 'poogh', 'prethee',\n",
    "                   'prithee', 'prosit', 'pssh', 'psst', 'queep', 'roger', 'salaam',\n",
    "                   'salam', 'sheesh', 'shh', 'shhh', 'shitfire', 'shoo', 'shoop',\n",
    "                   'shush', 'sigh', 'sssh', 'strewth', 'ta', 'tarnations', 'tchah',\n",
    "                   'teehee', 'tish', 'touché', 'tsk', 'tss', 'tut', 'uggh', 'ugh',\n",
    "                   'uh', 'uhh', 'uhm', 'um', 'umm', 'ummm', 'umph', 'unh', 'upadaisy',\n",
    "                   'upsadaisy', 'ur', 'urgh', 'vay', 'vayf', 'viva', 'voila', 'waa',\n",
    "                   'waaaaah', 'waah', 'wah', 'wahey', 'wassup', 'weee', 'welp',\n",
    "                   'wham', 'whamo', 'whee', 'whew', 'whizz', 'whoa',\n",
    "                   'whoo', 'whoopee','whoop', 'whoops', 'whoopsy', 'whoosh', 'woah', 'woo',\n",
    "                   'woohoo', 'wotcha', 'wotcher', 'wow', 'wowsers', 'wowsers',\n",
    "                   'wuzzup', 'wuzzup', 'wuzzup', 'ya', 'yabba', 'yada', 'yadda',\n",
    "                   'yak', 'yarooh', 'yay', 'yea', 'yeah', 'yech', 'yee', 'yeeeeaah',\n",
    "                   'yeehaw', 'yeow', 'yes', 'yessiree', 'yew', 'yikes', 'yippee',\n",
    "                   'yo', 'yoo', 'yoohoo', 'yow', 'yowza', 'yuck', 'yuh', 'zing',\n",
    "                   'zoiks', 'zomfg', 'zomg', 'zounds', 'zut'\n",
    "                   'lol' , 'brb', 'lmk', 'ama', 'tbh', 'irl', \"tl;dr\"]\n",
    "\n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "type(spacy_stopwords)\n",
    "#spacy_exclude=['using','name','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "#               'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use']# serious\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "stop_words1 = get_stop_words('english')\n",
    "#print(type(stop_words1))\n",
    "#print()\n",
    "#print(stop_words1)\n",
    "lib_stopwords=set(stop_words1)\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "#print(type(ENGLISH_STOP_WORDS))\n",
    "#print()\n",
    "#print(set(ENGLISH_STOP_WORDS))\n",
    "#sklearn_exclude=['find','get','found','go','see','seem','seems','give','seemed','take','keep','show','put','made'] # system  cry\n",
    "sklearn_stopwords=set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "#spacy_stopwords.difference_update(set(spacy_exclude))\n",
    "#sklearn_stopwords.difference_update(set(sklearn_stopwords))\n",
    "#for removing \"just\" one item, use \"remove\"\n",
    "\n",
    "temp_1=set(nltk_stopwords)\n",
    "temp_1.update(lib_stopwords)\n",
    "temp_1.update(sklearn_stopwords)\n",
    "temp_1.update(spacy_stopwords)\n",
    "temp_1.update(set(english_alghabet))\n",
    "temp_1.update(set(numbers_remove)) \n",
    "temp_1.update(set(miscellaneous_remove))\n",
    "temp_1.update(set(interjection_remove))\n",
    "cachedStopWords=temp_1\n",
    "#print(cachedStopWords)\n",
    "cachedStopWords.update(['rt','be','will','was','were','is','am','are','have','has','had','do','does','done'])\n",
    "len(cachedStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "\n",
    "    #order of lines is important\n",
    "    \n",
    "    text=strip_tags(text)\n",
    "    #text=html.unescape(text) \n",
    "    #text=saxutils.unescape(text)\n",
    "    \n",
    "    #converting\n",
    "    text = re.sub(\"“|”\", '''\"''', text)  #before next lines\n",
    "    text = re.sub(\"’|′|‘|`\", \"'\", text)  #before next lines\n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', ' ', text)\n",
    "    \n",
    "    #converting\n",
    "    text=re.sub('\\$|£|€|¥|dollar|dollars|yen|yens|euros', ' money ', text)    # not euro \n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE) \n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text) \n",
    "    \n",
    "    #removing emojis and non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', text)  \n",
    "        \n",
    "    #convertings words that their lower and uper cases are different\n",
    "    text=re.sub(\" US | U\\.S\\. \", ' USA ', text) # before lower    \n",
    "\n",
    "    #converting lower_case\n",
    "    text = text.lower() \n",
    "\n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "\n",
    "    '''\n",
    "    #removing common expressions\n",
    "    text=re.sub(\"looking forward to|look forward to|make sure|kidding me|\\\n",
    "                in my opinion|by the way,|as soon as possible|shaking my head|i don't know|I do not know|\\\n",
    "                in real life|quote of the day|as far as i know|shake my head|\\\n",
    "                to be honest|in other words|let me know|just kidding|hope that helps|hat tip|\\\n",
    "                just like that|happy birthday|never mind|well-done|\\\n",
    "                in my humble opinion|happy new year|you're welcome|you are welcome| j/k | lmao | \\\n",
    "                it doesn't matter|it does not matter|i think|i wonder|do you think| fml | bfn | br | ht | hth \", ' ', text)   \n",
    "    '''          \n",
    "    #convertings\n",
    "    text=re.sub(\"can't\", 'cannot', text) # before other n't \n",
    "    text=re.sub(\"can not \", 'cannot ', text)  \n",
    "    text=re.sub(\"'ve\",' have', text)\n",
    "    text=re.sub(\"n't\",' not', text)\n",
    "    text=re.sub(\"'ll\",' will', text)\n",
    "    text=re.sub(\"'d\",' would', text)\n",
    "    text=re.sub(\"'re\",' are', text)\n",
    "    text=re.sub(\"i'm\",'i am', text)\n",
    "    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"&\",' and ', text)\n",
    "    text=re.sub(\" w/ \",' with ', text)\n",
    "    text=re.sub(\" w/i | w/in \",' within ', text)\n",
    "    text=re.sub(\" w/o \",' without ', text)\n",
    "    text=re.sub(\" c/o \",' care of ', text)\n",
    "    text=re.sub(\" h/t \",' hat tip ', text)\n",
    "    text=re.sub(\" b/c \",' because ', text)\n",
    "#    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"=\",' = ', text)\n",
    "#    text=re.sub(\"\\+\",' plus ', text)\n",
    "    text=re.sub(\"\\+\",' + ', text)\n",
    "    text=re.sub(\"united states\",'usa', text)\n",
    "    text=re.sub(\"united kingdom\",'uk', text)\n",
    "    text=re.sub(\" the us \",' usa ', text)\n",
    "    text=re.sub(\"start-up|start_up\",'startup', text)\n",
    "    text=re.sub(\"u\\.s\\.a\", 'usa', text)     \n",
    "    #text=re.sub(\"aka\", 'also known as', text)\n",
    "    text=re.sub(\"'\",\" ' \", text)     \n",
    "\n",
    "    '''\n",
    "    text= re.sub(\"(\\?)+\", '? ',text) \n",
    "    text= re.sub(\"(!)+\", '! ',text) \n",
    "    text= re.sub(\"(\\.\\.)+\", ' ',text)    \n",
    "    \n",
    "    #removing some special charachter  \n",
    "    text= re.sub(\"[\\\"\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]<>{}_';•«»,@:~!\\=%&]+\", ' ',text) #except \\.\n",
    "    #text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`′’‘';•«,@:~!\\=%&]+\", ' ',text) \n",
    "\n",
    "    #removing hashtag\n",
    "    text=re.sub('#', ' ', text) \n",
    "       \n",
    "    #removing numbers not attached to alphabets\n",
    "    text=re.sub(\"(^)(\\d+)(\\.)?(\\d+)? \",' ',text)   #removing numer at the beginning\n",
    "    text=re.sub(\"(\\s)[0-9]?(\\.)?(\\d+) \",' ',text)\n",
    "    text= re.sub(\" (\\.)(\\d+) \", ' ',text)\n",
    "    #text=re.sub(\"\\S+(\\d+) \",' ',text) # alphabet+digit (attached)\n",
    "    #text=re.sub(\" (\\d+)\\S+\",' ',text) # digit+alphabet (attached)\n",
    "    #text=re.sub(\" \\S+(\\d+)\\S+ \",' ',text) # alphabet+digit+alphabet (attached)\n",
    "    #text=re.sub(\"(\\d+)\",' ',text)  #removing any number anywhere but keeps \\. for decimal numbers\n",
    "    '''\n",
    "    #removing space\n",
    "    text=re.sub('\\s+',' ',text)      \n",
    "\n",
    "    text= nltk.word_tokenize(text)\n",
    "    #text= text.split() #sometimes\n",
    "\n",
    "    #removing_stopwords \n",
    "    #text_without_sw = [word.lower() for word in text if word.lower() not in stopwords.words()] #very slow\n",
    "#    text = [word for word in text if word not in cachedStopWords]\n",
    "\n",
    "    #lemmatization\n",
    "#    text= [ lemm(word, pos=\"v\") for word in text]\n",
    "#    text= [ lemm(word, pos=\"n\") for word in text]\n",
    "#    text= [ lemm(word, pos=\"a\") for word in text]\n",
    "    \n",
    "    #stemming \n",
    "    #text = [Stem(word) for word in text]\n",
    "    \n",
    "    text=' '.join(text)\n",
    "    text=re.sub(\"''\",'''\"''', text)    #since nltk.tokenize converts second \" to ''\"\n",
    "    text=re.sub(\"``\",'''\"''', text)    # since nltk.tokenize converts first \" to \" ``\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=('http://sdsdfdf.www.f.com 6 going US BY the euro $ way &amp; to #home at 29! 9 0.3 4.5 b2b 6dd ca8 and his book). by the way, He is boy??? and .... ')\n",
    "cleaning(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "##cur.execute(\"SELECT user_id, tweet from ent_2019_100K limit 100000 \")\n",
    "cur.execute(\"SELECT user_id, tweet from ent_2019_1000k \")\n",
    "rows_ent = cur.fetchall()\n",
    "# there is no repetative tweet\n",
    "con.close()\n",
    "\n",
    "print(len(rows_ent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from public_2019_1000k \")\n",
    "rows_public = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_public))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#marked_text='''along w/the 'ball' : \"fashionable truths\"  & good?! ,'''\n",
    "#text2='''with w/the ' fashionable truths : ' a `` generous noble native , '' a `` sport man '' in the'''\n",
    "#a=tokenizer.tokenize(text2)\n",
    "#print(a)\n",
    "#b=nltk.word_tokenize(marked_text)\n",
    "#print(b)\n",
    "#print(cleaning(marked_text))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221.86518907546997\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "ent_users_rows=[]\n",
    "ent_tweets_rows=[]\n",
    "for i in rows_ent:\n",
    "    ent_users_rows.append(i[0])\n",
    "    ent_tweets_rows.append(cleaning(i[1]))\n",
    "    \n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606\n"
     ]
    }
   ],
   "source": [
    "ent_users_rows_np=np.array(ent_users_rows)  \n",
    "ent_users=np.unique(ent_users_rows_np)\n",
    "print(len(ent_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "ent_all_words=[]\n",
    "for i in ent_tweets_rows:\n",
    "    ent_all_words.extend(i)\n",
    "len(ent_all_words)  \n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dic_ent_user=dict()\n",
    "for user in ent_users_rows:\n",
    "    if user not in dic_ent_user:\n",
    "        dic_ent_user[user]=1\n",
    "    else:\n",
    "        dic_ent_user[user]+=1   \n",
    "sorted_x = sorted(dic_ent_user.items(), key=operator.itemgetter(1), reverse=False) \n",
    "f = open(\"ent_user.txt\", \"w\")\n",
    "for xx in sorted_x:\n",
    "    f.write(str(xx)+'\\n')\n",
    "f.close()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215.50108885765076\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "mng_users_rows=[]\n",
    "mng_tweets_rows=[]\n",
    "for i in rows_mng:\n",
    "    mng_users_rows.append(i[0])\n",
    "    mng_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1648\n"
     ]
    }
   ],
   "source": [
    "mng_users_rows_np=np.array(mng_users_rows)  \n",
    "mng_users=np.unique(mng_users_rows_np)\n",
    "print(len(mng_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mng_all_words=[]\n",
    "for i in mng_tweets_rows:\n",
    "    mng_all_words.extend(i)\n",
    "len(mng_all_words)  \n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dic_mng_user=dict()\n",
    "for user in mng_users_rows:\n",
    "    if user not in dic_mng_user:\n",
    "        dic_mng_user[user]=1\n",
    "    else:\n",
    "        dic_mng_user[user]+=1  \n",
    "        \n",
    "sorted_z = sorted(dic_mng_user.items(), key=operator.itemgetter(1), reverse=False) \n",
    "f = open(\"mng_user.txt\", \"w\")\n",
    "for zz in sorted_z:\n",
    "    f.write(str(zz)+'\\n')\n",
    "f.close()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179.22886061668396\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "\n",
    "public_users_rows=[]\n",
    "public_tweets_rows=[]\n",
    "\n",
    "for i in rows_public:\n",
    "    public_users_rows.append(i[0])\n",
    "    public_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1662\n"
     ]
    }
   ],
   "source": [
    "public_users_rows_np=np.array(public_users_rows)  \n",
    "public_users=np.unique(public_users_rows_np)\n",
    "print(len(public_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "public_all_words=[]\n",
    "for i in public_tweets_rows:\n",
    "    public_all_words.extend(i)\n",
    "len(public_all_words)  \n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dic_public_user=dict()\n",
    "for user in public_users_rows:\n",
    "    if user not in dic_public_user:\n",
    "        dic_public_user[user]=1\n",
    "    else:\n",
    "        dic_public_user[user]+=1   \n",
    "sorted_y = sorted(dic_public_user.items(), key=operator.itemgetter(1), reverse=False) \n",
    "f = open(\"public_user.txt\", \"w\")\n",
    "for yy in sorted_y:\n",
    "    f.write(str(yy)+'\\n')\n",
    "f.close()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder (tweets):\n",
    "    # padding after {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        \n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if len(tokenized_text)>max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "        segments_ids= segments_ids + [0] * (max_len_tokens+2 - len(segments_ids)) \n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,temp-1), axis = 0)\n",
    "#        print('a9',token_embeddings)\n",
    "#        token_embeddings[temp-2:]=0\n",
    "#        print(token_embeddings)\n",
    "\n",
    "        #token_embeddings_list=token_embeddings.tolist()\n",
    "        #print(len(token_embeddings_list))\n",
    "        #tokenized_text.pop(0)\n",
    "        #tokenized_text.pop(-1)\n",
    "        #token_embeddings_list.pop(0)\n",
    "        #token_embeddings_list.pop(-1)\n",
    "        #for ii in range(len(tokenized_text)-1 ,0 ,-1):\n",
    "            #print(ii)\n",
    "            #print(tokenized_text[ii][0:2])\n",
    "            #if tokenized_text[ii][0:2]==\"##\":\n",
    "                #print(tokenized_text[ii])\n",
    "               #token_embeddings_list[ii-1]=token_embeddings_list[ii-1]+token_embeddings_list[ii]\n",
    "               #token_embeddings_list.pop(ii) # or del token_vecs_sum[ii]\n",
    "               #tokenized_text[ii-1]=tokenized_text[ii-1]+tokenized_text[ii][2:]\n",
    "               #tokenized_text.pop(ii) # or del tokenized_text[ii]      \n",
    "        #print(len(token_embeddings_list))\n",
    "        #mng_full_embedding_word.append(token_embeddings_list)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "    print(np.shape(tweets_embedded))\n",
    "    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder2 (tweets):\n",
    "    #padding before {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = '[CLS]'+ text \n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "#        print(temp)\n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if len(tokenized_text)>=max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "        else:\n",
    "#            print(type(tokenized_text))\n",
    "            tokenized_text = tokenized_text + ['[PAD]'] * (max_len_tokens+1 - len(tokenized_text))+ ['[SEP]']\n",
    "#            print('a44',tokenized_text)\n",
    "\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#                sequences, maxlen=10, dtype='int32', padding='post',\n",
    "#                truncating='post', value=0.0)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "#        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "#        segments_ids = [1] * len(tokenized_text)\n",
    "        segments_ids= [1]* min(temp,max_len_tokens+1) + [0] * (max_len_tokens+1 - temp)  + [1]\n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('a9',token_embeddings)\n",
    "#        token_embeddings[temp-2:]=0\n",
    "#        print(token_embeddings)\n",
    "\n",
    "        #token_embeddings_list=token_embeddings.tolist()\n",
    "        #print(len(token_embeddings_list))\n",
    "        #tokenized_text.pop(0)\n",
    "        #tokenized_text.pop(-1)\n",
    "        #token_embeddings_list.pop(0)\n",
    "        #token_embeddings_list.pop(-1)\n",
    "        #for ii in range(len(tokenized_text)-1 ,0 ,-1):\n",
    "            #print(ii)\n",
    "            #print(tokenized_text[ii][0:2])\n",
    "            #if tokenized_text[ii][0:2]==\"##\":\n",
    "                #print(tokenized_text[ii])\n",
    "               #token_embeddings_list[ii-1]=token_embeddings_list[ii-1]+token_embeddings_list[ii]\n",
    "               #token_embeddings_list.pop(ii) # or del token_vecs_sum[ii]\n",
    "               #tokenized_text[ii-1]=tokenized_text[ii-1]+tokenized_text[ii][2:]\n",
    "               #tokenized_text.pop(ii) # or del tokenized_text[ii]      \n",
    "        #print(len(token_embeddings_list))\n",
    "        #mng_full_embedding_word.append(token_embeddings_list)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "    print(np.shape(tweets_embedded))\n",
    "    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder0 (tweets):\n",
    "    #padding before {SEP} forcing zero\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=1\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "#    print('a11',np.shape(vector_temp))\n",
    "\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "        \n",
    "        \n",
    "                \n",
    "        marked_text = '[CLS]'+ text + '[SEP]'\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)-2\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('a88',len(token_embeddings))\n",
    "        if len(token_embeddings)>=max_len_tokens:\n",
    "            vector_temp= token_embeddings[0:max_len_tokens]\n",
    "#            print('a9',vector_temp)\n",
    "        else:\n",
    "            vector_temp = np.zeros([max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "            vector_temp[0:temp] = token_embeddings\n",
    "#            print('a99',vector_temp)\n",
    "        tweets_embedded[i]=vector_temp\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "        '''\n",
    "\n",
    "        marked_text = '[CLS]'+ text + '[SEP]'\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        temp=len(tokenized_text)-2\n",
    "#        print('b1',tokenized_text)\n",
    "        if len(tokenized_text)>=max_len_tokens+2:\n",
    "#            print('b2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('b3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('b4',tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "        token_embeddings = torch.squeeze(out, dim=0) \n",
    "#        print('b8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('b88',len(token_embeddings))\n",
    "        if len(token_embeddings)==max_len_tokens:\n",
    "            vector_temp= token_embeddings\n",
    "#            print('b9',vector_temp)\n",
    "        else:\n",
    "            vector_temp = np.zeros([max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "            vector_temp[0:temp] = token_embeddings\n",
    "#            print('b99',vector_temp)\n",
    "        tweets_embedded[i]=vector_temp\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "        '''\n",
    "\n",
    "    print(np.shape(tweets_embedded))\n",
    "    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\naa=embedder0(['That is very good and joy '])\\n#aa=embedder0([''])\\naa\\n\""
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "aa=embedder0(['That is very good and joy '])\n",
    "#aa=embedder0([''])\n",
    "aa\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef customLoss1(yTrue,yPred):\\n    res=np.abs(yTrue - yPred )\\n    res= res+1\\n#    res=tf.cast(res,tf.float32)\\n    res=np.power(res,0.1)\\n#    print(res)\\n    res=np.prod(res)\\n    res= res -1\\n#    print(res)\\n    return res\\n\\nx1=np.random.rand(1,1,3)\\nprint(x1)\\nx2=np.zeros([1,1,3])\\ncustomLoss1(x1,x2)\\n\\npass\\n\\nb1=embedder0(['hated'])\\nb2=embedder0(['song'])\\nb3=embedder0(['money'])\\nb4=embedder0(['marketing'])\\nb5=embedder0(['team'])\\nb6=embedder0(['group'])\\n\\n\\nfrom scipy.spatial.distance import cosine\\n\\nprint(1 - cosine(b1, b2 ))\\nprint(1 - cosine(b1, b3 ))\\nprint(1 - cosine(b1, b4 ))\\nprint(1 - cosine(b2, b3 ))\\nprint(1 - cosine(b2, b4 ))\\nprint(1 - cosine(b3, b4 ))\\nprint(1 - cosine(b5, b6 ))\\n\\nprint(customLoss1(b1,b2))\\nprint(customLoss1(b1,b3))\\nprint(customLoss1(b1,b4))\\nprint(customLoss1(b2,b3))\\nprint(customLoss1(b2,b4))\\nprint(customLoss1(b3,b4))\\nprint(customLoss1(b5,b6))\\n\\n\\nprint(np.linalg.norm(b1-b2))\\nprint(np.linalg.norm(b1-b3))\\nprint(np.linalg.norm(b1-b4))\\nprint(np.linalg.norm(b3-b2))\\nprint(np.linalg.norm(b4-b2))\\nprint(np.linalg.norm(b3-b4))\\nprint(np.linalg.norm(b5-b6))\\n\""
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "def customLoss1(yTrue,yPred):\n",
    "    res=np.abs(yTrue - yPred )\n",
    "    res= res+1\n",
    "#    res=tf.cast(res,tf.float32)\n",
    "    res=np.power(res,0.1)\n",
    "#    print(res)\n",
    "    res=np.prod(res)\n",
    "    res= res -1\n",
    "#    print(res)\n",
    "    return res\n",
    "\n",
    "x1=np.random.rand(1,1,3)\n",
    "print(x1)\n",
    "x2=np.zeros([1,1,3])\n",
    "customLoss1(x1,x2)\n",
    "\n",
    "pass\n",
    "\n",
    "b1=embedder0(['hated'])\n",
    "b2=embedder0(['song'])\n",
    "b3=embedder0(['money'])\n",
    "b4=embedder0(['marketing'])\n",
    "b5=embedder0(['team'])\n",
    "b6=embedder0(['group'])\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(1 - cosine(b1, b2 ))\n",
    "print(1 - cosine(b1, b3 ))\n",
    "print(1 - cosine(b1, b4 ))\n",
    "print(1 - cosine(b2, b3 ))\n",
    "print(1 - cosine(b2, b4 ))\n",
    "print(1 - cosine(b3, b4 ))\n",
    "print(1 - cosine(b5, b6 ))\n",
    "\n",
    "print(customLoss1(b1,b2))\n",
    "print(customLoss1(b1,b3))\n",
    "print(customLoss1(b1,b4))\n",
    "print(customLoss1(b2,b3))\n",
    "print(customLoss1(b2,b4))\n",
    "print(customLoss1(b3,b4))\n",
    "print(customLoss1(b5,b6))\n",
    "\n",
    "\n",
    "print(np.linalg.norm(b1-b2))\n",
    "print(np.linalg.norm(b1-b3))\n",
    "print(np.linalg.norm(b1-b4))\n",
    "print(np.linalg.norm(b3-b2))\n",
    "print(np.linalg.norm(b4-b2))\n",
    "print(np.linalg.norm(b3-b4))\n",
    "print(np.linalg.norm(b5-b6))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(\"./New folder/seed_tweets_mng.txt\", \"rb\") as fp:   \n",
    "    seed_tweets_mng = pickle.load(fp)\n",
    "'''    \n",
    "with open(\"./New folder/seed_tweets_ent.txt\", \"rb\") as fp:   \n",
    "    seed_tweets_ent = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "seed_mng=[]\n",
    "for tweet in seed_tweets_mng:\n",
    "    seed_mng.append(cleaning(tweet))\n",
    "'''    \n",
    "seed_ent=[]\n",
    "for tweet in seed_tweets_ent:\n",
    "    seed_ent.append(cleaning(tweet))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range(100):\n",
    "    print(seed_tweets_ent[i])\n",
    "    print(seed_ent[i])\n",
    "    print()\n",
    "''' \n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['finally have a product + a market !',\n",
       " 'all in one small business marketing ! at its best !',\n",
       " \"entrepreneur : it ' s not all about business\",\n",
       " 'come and invest money you are not using',\n",
       " 'what are you saying ? i will take money , and invest here .',\n",
       " 'the latest # business and # money by thanks to # investment # investing',\n",
       " 'make money marketing',\n",
       " 'the latest # business and # money by thanks to # investment # markets',\n",
       " 'there are strategies we use for every market .',\n",
       " 'marketing is an investment . thats it .']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_ent[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ent = pd.DataFrame({'tweet':ent_tweets_rows})\n",
    "df_ent['len'] = df_ent['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent\n",
      "mean length of tweets: 19.740617\n",
      "max length of tweets:  227\n",
      "std length of tweets:  13.50367504823555\n"
     ]
    }
   ],
   "source": [
    "print('ent')\n",
    "print(\"mean length of tweets: \" + str(df_ent['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_ent['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_ent['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mng = pd.DataFrame({'tweet':mng_tweets_rows})\n",
    "df_mng['len'] = df_mng['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_mng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mng\n",
      "mean length of tweets: 18.521694\n",
      "max length of tweets:  258\n",
      "std length of tweets:  12.719456558951313\n"
     ]
    }
   ],
   "source": [
    "print('mng')\n",
    "print(\"mean length of tweets: \" + str(df_mng['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_mng['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_mng['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_public = pd.DataFrame({'tweet':public_tweets_rows})\n",
    "df_public['len'] = df_public['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_public"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public\n",
      "mean length of tweets: 14.536518\n",
      "max length of tweets:  135\n",
      "std length of tweets:  9.546267520175629\n"
     ]
    }
   ],
   "source": [
    "print('public')\n",
    "print(\"mean length of tweets: \" + str(df_public['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_public['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_public['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#length  and indices of non empty tweets after cleaning\n",
    "len_pub=[]\n",
    "public_all=[]\n",
    "for i in public_tweets_rows:\n",
    "    if len(i)!=0:\n",
    "        len_pub.append(len(i.split(' ')))\n",
    "        public_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_mng=[]\n",
    "mng_all=[]\n",
    "for i in mng_tweets_rows:\n",
    "    if len(i)!=0:\n",
    "        len_mng.append(len(i.split(' ')))\n",
    "        mng_all.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_ent=[]\n",
    "ent_all=[]\n",
    "for i in ent_tweets_rows:\n",
    "    if len(i)!=0:\n",
    "        len_ent.append(len(i.split(' ')))\n",
    "        ent_all.append(i)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean length for ent , mng and public without empty tweets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19.74065448130896, 18.52171152171152, 14.536518)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('mean length for ent , mng and public without empty tweets')        \n",
    "np.mean(len_ent),np.mean(len_mng),np.mean(len_pub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"a sovereign people must always have responsibility & desire to be substantially self-reliant , from which derives our human dignity . that dignity canot be derived from gov ' t cradle to grave schemes & dependence , nor mere tribal identity . true identity comes only from our creator !\",\n",
       " 'and last , good neighbors go together to mend their walls , & in that work together mend trust & pay their share , that law between them may be restored & their security assured . while at this work , the cause of this trespass must be addressed , & both must lend a hand & repair it .',\n",
       " 'and we all celebrate life , as do the president and first lady ! we are here at the egg convention center in albany ny today celebrating our god-given right to life at the day of mourning following the nys legislature approving 3rd term abortion .',\n",
       " 'british & american cultures share much in common . but trump represents the best of a sovereignty culture unique to america , yet still its vestiges are rooted in british culture . your choice is between a sovereignty culture of sovereign citizens or slave culture of absolute rulers',\n",
       " 'british common law is the foundation on which american jurisprudence is built including property rights & the sacred value of human life & rights . and this judeo-christian value system informs the british culture which like usa culture is under attack by relativists . clear , mayor ?']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ent_all[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#print(\"test set size \" + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(\"data_public.txt\", \"wb\") as fp:\n",
    "  pickle.dump(data_public, fp, protocol=4) # for data with size more than 4GB\n",
    "'''  \n",
    "'''\n",
    "with open(\"data_mng.txt\", \"wb\") as fp:   \n",
    "  pickle.dump(data_mng, fp, protocol=4)\n",
    "'''\n",
    "'''\n",
    "with open(\"data_train_ent.txt\", \"wb\") as fp:   \n",
    "  pickle.dump(data_ent, fp, protocol=4)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open(\"data_train_mng.txt\", \"rb\") as fp:   \n",
    "  data_mng = pickle.load(fp)\n",
    "'''\n",
    "'''\n",
    "with open(\"data_train_public.txt\", \"rb\") as fp:   \n",
    "  data_train_public = pickle.load(fp)\n",
    "'''\n",
    "'''\n",
    "with open(\"data_train_ent.txt\", \"rb\") as fp:   \n",
    "  data_ent = pickle.load(fp)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000,)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(seed_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,j in enumerate(seed_ent[0:120]):\n",
    "#    print(i,j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ent_exclude=[29,30,38,39,49,50,51,52,59,60,68,69,78,94,102,103,156,157,179,201,203,204,237,\n",
    "             257,288,304,313,341,425,476,492,508,542,545,548,633,634,663,674,694,741,751,768,\n",
    "             801,802,809,835,847,852,856,857,868,869]\n",
    "seed_ent_exclude=sorted(seed_ent_exclude) \n",
    "#for i in seed_ent_exclude:\n",
    "#    print(seed_ent[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1258,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ent1 = [j for i, j in enumerate(seed_ent[0:120]) if i not in seed_ent_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "104"
      ]
     },
     "execution_count": 1259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_ent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_train=embedder0(seed_ent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=embedder0(ent_all[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sys.getsizeof(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install \"tensorflow_hub>=0.6.0\"\n",
    "#!pip install \"tensorflow>=2.0.0\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ent2 = [j for i, j in enumerate(seed_ent[0:28]) if i not in [13,14,26]]\n",
    "#seed_ent2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(seed_ent))\n",
    "texts=[]\n",
    "texts=seed_ent+ent_all[0:2000]\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#texts[0],texts[1],texts[2],texts[3],texts[4],texts[5],texts[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts.append(\"great work group\")\n",
    "#texts.append(\"I like #apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4001"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6742 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_NB_WORDS=25000\n",
    "MAX_SEQUENCE_LENGTH=25\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "sequences = tokenizer.texts_to_sequences(texts)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "\n",
    "'''\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "tokens=[]\n",
    "for sometext in texts:\n",
    "    tokens.extend(word_tokenize(sometext))\n",
    "    \n",
    "token=list(set(tokens))\n",
    "my_vocab = Dictionary([tokens])\n",
    "\n",
    "sequences=[]\n",
    "for i, sometext in enumerate(texts) :\n",
    "    tokens=word_tokenize(sometext)\n",
    "    temp=[]\n",
    "    for token in tokens:\n",
    "        temp.append(my_vocab.token2id[token]+1)\n",
    "    if len(temp)>num_words:\n",
    "        temp=temp[0:num_words]\n",
    "    sequences.append(temp)\n",
    "\n",
    "word_index={}\n",
    "for i in range(len(my_vocab)):\n",
    "    word_index[my_vocab[i]]= 1+i    \n",
    "    \n",
    "data = pad_sequences(sequences, maxlen=25, padding='post')\n",
    "'''\n",
    "    \n",
    "# split the data into a training set and a test set\n",
    "indices = np.arange(data.shape[0])\n",
    "#np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "nb_train_samples=len(seed_ent)\n",
    "x_train1 = data[:nb_train_samples]\n",
    "x_test1 = data[nb_train_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "f = open(os.path.join(\"C:/Users/jafar/My codes/glove/\", 'glove.twitter.27B.25d.txt'),encoding='cp437')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(type(embeddings_index))\n",
    "#print(embeddings_index['#'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "a1=embeddings_index['hated']\n",
    "a2=embeddings_index['song']\n",
    "a3=embeddings_index['money']\n",
    "a4=embeddings_index['marketing']\n",
    "a5=embeddings_index['team']\n",
    "a6=embeddings_index['group']\n",
    "a7=embeddings_index['club']\n",
    "a8=embeddings_index['time']\n",
    "a9=embeddings_index['market']\n",
    "a10=embeddings_index['heater']\n",
    "\n",
    "np.linalg.norm(a7-a8),np.linalg.norm(a7-a9) , np.linalg.norm(a7-a10)\n",
    "\n",
    "def customLoss(yTrue,yPred):\n",
    "    res=K.abs(yTrue - yPred )\n",
    "    res =res+ 1\n",
    "#    print(res)\n",
    "    res=K.prod(res,axis=-1)\n",
    "#    print(res)\n",
    "    res=tf.cast(res,tf.float32)\n",
    "    res=K.pow(res,1)\n",
    "    res=K.prod(res)\n",
    "    res= res -1\n",
    "    return res\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(1 - cosine(a1, a2 ))\n",
    "print(1 - cosine(a1, a3 ))\n",
    "print(1 - cosine(a1, a4 ))\n",
    "print(1 - cosine(a2, a3 ))\n",
    "print(1 - cosine(a2, a4 ))\n",
    "print(1 - cosine(a3, a4 ))\n",
    "print(1 - cosine(a5, a6 ))\n",
    "print(1 - cosine(a4, a7 ))\n",
    "print(1 - cosine(a8, a7 ))\n",
    "print(1 - cosine(a9, a7 ))\n",
    "\n",
    "print(customLoss(a1,a2))\n",
    "print(customLoss(a1,a3))\n",
    "print(customLoss(a1,a4))\n",
    "print(customLoss(a2,a3))\n",
    "print(customLoss(a2,a4))\n",
    "print(customLoss(a3,a4))\n",
    "print(customLoss(a5,a6))\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM=25\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "#    print(word,i)\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "#        print(embedding_vector)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "MAX_SEQUENCE_LENGTH=25\n",
    "\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            output_dim=EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 25, 25)\n",
      "(2001, 25, 25)\n"
     ]
    }
   ],
   "source": [
    "#result = embedding_layer(tf.constant([0, 5, 6, 10]))\n",
    "x_train = embedding_layer(x_train1)\n",
    "x_test = embedding_layer(x_test1)\n",
    "print(np.shape(x_train))\n",
    "print(np.shape(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=data_train[0:50000]\n",
    "#x_test=data_test[0:1000000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2000, 25, 25]), TensorShape([2001, 25, 25]))"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(x_train), np.shape(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "min_val = np.min(x_train) \n",
    "max_val = np.max(x_train)\n",
    "max_val, min_val\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "min_val = np.min(np.vstack((data_train,data_test))) \n",
    "max_val = np.max(np.vstack((data_train,data_test)))\n",
    "max_val, min_val\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Normalising to  [-1,1]\n",
    "x_train = 2.*(x_train - np.min(x_train))/np.ptp(x_train)-1\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Normalising to  [-1,1]\n",
    "x_train = 2.*(x_train - np.min(np.vstack((data_train,data_test))))/np.ptp(np.vstack((data_train,data_test)))-1\n",
    "x_test = 2.*(x_test - np.min(np.vstack((data_train,data_test))))/np.ptp(np.vstack((data_train,data_test)))-1\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.6008, -6.3371)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_valx = np.min(np.vstack((x_train,x_test))) \n",
    "max_valx = np.max(np.vstack((x_train,x_test)))\n",
    "max_valx,min_valx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Normalising to  [0,1]\n",
    "x_train = (x_train - min_valx) / (max_valx - min_valx)\n",
    "x_test = (x_test - min_valx) / (max_valx - min_valx)\n",
    "\n",
    "#x_train = tf.cast(x_train, tf.float32)\n",
    "#x_test = tf.cast(x_test, tf.float32)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zero_pad = (0-min_valx) / (max_valx - min_valx)\n",
    "#zero_pad= 2.*(0 - np.min(np.vstack((data_train,data_test))))/np.ptp(np.vstack((data_train,data_test)))-1\n",
    "#zero_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flatten_arr = np.ravel(arr_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range( len(x_train)):\n",
    "    for j in range(len(x_train[i])):\n",
    "        if np.all(np.isclose(x_train[i,j,:] , zero_pad)): # for integers: if np.all(a[1,:]==2)\n",
    "            x_train[i,j,:]=0\n",
    "'''            \n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for i in range( len(x_test)):\n",
    "    for j in range(len(x_test[i])):\n",
    "        if np.all(np.isclose(x_test[i,j,:] , zero_pad)): # for integers: if np.all(a[1,:]==2)\n",
    "            x_test[i,j,:]=0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "min_valx = np.min(x_train) \n",
    "max_valx = np.max(x_train)\n",
    "max_valx,min_valx\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.6008, -6.3371)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "min_valx = np.min(np.vstack((x_train,x_test))) \n",
    "max_valx = np.max(np.vstack((x_train,x_test)))\n",
    "max_valx,min_valx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.argwhere(np.isnan(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=25\n",
    "num_filters=10\n",
    "embedding_dim=25 #768\n",
    "latent_dim=20\n",
    "dropout_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (None, 25, 25)\n",
      "Model: \"CVAE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        [(None, 25, 25)]          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 625)               0         \n",
      "_________________________________________________________________\n",
      "dense_78 (Dense)             (None, 512)               320512    \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_81 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_82 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dense_84 (Dense)             (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_85 (Dense)             (None, 16)                144       \n",
      "_________________________________________________________________\n",
      "dense_86 (Dense)             (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_87 (Dense)             (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_90 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dense_91 (Dense)             (None, 625)               320625    \n",
      "_________________________________________________________________\n",
      "reshape_10 (Reshape)         (None, 25, 25)            0         \n",
      "=================================================================\n",
      "Total params: 992,089\n",
      "Trainable params: 992,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##encoder\n",
    "encoder_inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32') #encoder_inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "print(\"input shape:\",np.shape(encoder_inputs))\n",
    "\n",
    "X = Flatten()(encoder_inputs)\n",
    "#print(np.shape(flatten_e1))\n",
    "\n",
    "X = Dense(units=512, activation='linear')(X) # 450\n",
    "\n",
    "X = Dense(units=256, activation='linear')(X) # 450\n",
    "\n",
    "\n",
    "X = Dense(units=128, activation='linear')(X) # 450\n",
    "#print(np.shape(dense_e1))\n",
    "\n",
    "\n",
    "\n",
    "X = Dense(units=64, activation='linear')(X) #150\n",
    "#print(np.shape(dense_e1))\n",
    "\n",
    "\n",
    "X = Dense(units=32, activation='linear')(X) #50 \n",
    "#print(np.shape(dense_e1))\n",
    "X = Dense(units=16, activation='linear')(X) #50 \n",
    "\n",
    "X = Dense(units=8, activation='linear')(X) #50 \n",
    "\n",
    "X = Dense(units=16, activation='linear')(X) #50 \n",
    "\n",
    "\n",
    "X = Dense(units=32, activation='linear')(X) #50 \n",
    "\n",
    "\n",
    "##without variational \n",
    "X = Dense(units=64, activation='linear')(X) # latent_dim *********************\n",
    "#print(np.shape(dense_e2))\n",
    "#output_encoder = dense_e2\n",
    "\n",
    "'''\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "#        print('sampling shape:  ',np.shape(z_mean))\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "z_mean = Dense(625, name=\"z_mean\")(X) #latent_dim\n",
    "z_log_var = Dense(625, name=\"z_log_var\")(X) #latent_dim\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "#print('z shape',np.shape(z))\n",
    "\n",
    "#encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "#encoder.summary()\n",
    "\n",
    "##decoder\n",
    "#latent_inputs = Input(shape=(latent_dim,), dtype='float32')\n",
    "#print(np.shape(latent_inputs))\n",
    "#dense_d1 = Dense(units=200, activation='relu')(latent_inputs)\n",
    "\n",
    "#dense_d1 = Dense(units=30, activation='linear')(z)\n",
    "#print(np.shape(dense_d1))\n",
    "\n",
    "\n",
    "#X = Dense(units=50, activation='relu')(X)\n",
    "'''\n",
    "\n",
    "\n",
    "X = Dense(units=128, activation='linear')(X) #X = Dense(units=num_filters*5, activation='relu')(X) #50\n",
    "#print(np.shape(dense_d2))\n",
    "\n",
    "\n",
    "X = Dense(units=256, activation='linear')(X) # 150\n",
    "#print(np.shape(dense_d3))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d3))\n",
    "\n",
    "X = Dense(units=512, activation='linear')(X) #450\n",
    "#print(np.shape(dense_d4))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d4))\n",
    "\n",
    "X = Dense(units=embedding_dim*sequence_length, activation='linear')(X)\n",
    "#print(np.shape(dense_d5))\n",
    "\n",
    "decoder_outputs = Reshape((sequence_length, embedding_dim))(X)\n",
    "#print('output shape:', np.shape(decoder_outputs))\n",
    "\n",
    "\n",
    "\n",
    "autoencoder = keras.Model(encoder_inputs, decoder_outputs, name=\"CVAE\")\n",
    "autoencoder.summary()\n",
    "\n",
    "#outputs = decoder(encoder(encoder_inputs)[2])\n",
    "#cvae = keras.Model(encoder_inputs, outputs, name='CVAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input shape: (None, 25, 25)\n",
      "(None, 25, 25, 1)\n",
      "Model: \"CVAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 25, 25)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape_14 (Reshape)            (None, 25, 25, 1)    0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 25, 1, 10)    260         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 24, 1, 10)    510         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 23, 1, 10)    760         reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 22, 1, 10)    1010        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 21, 1, 10)    1260        reshape_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, 1, 1, 10)     0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, 1, 1, 10)     0           conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling2D) (None, 1, 1, 10)     0           conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling2D) (None, 1, 1, 10)     0           conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling2D) (None, 1, 1, 10)     0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 1, 1, 50)     0           max_pooling2d_35[0][0]           \n",
      "                                                                 max_pooling2d_36[0][0]           \n",
      "                                                                 max_pooling2d_37[0][0]           \n",
      "                                                                 max_pooling2d_38[0][0]           \n",
      "                                                                 max_pooling2d_39[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 50)           0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_38 (Dense)                (None, 20)           1020        flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 20)           420         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 20)           420         dense_38[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "sampling_3 (Sampling)           (None, 20)           0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 50)           1050        sampling_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 150)          7650        dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 450)          67950       dense_40[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 625)          281875      dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "reshape_15 (Reshape)            (None, 25, 25)       0           dense_42[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 364,185\n",
      "Trainable params: 364,185\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "##encoder\n",
    "encoder_inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32') #encoder_inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "print(\"input shape:\",np.shape(encoder_inputs))\n",
    "\n",
    "#embedded_sequences = embedding_layer(encoder_inputs)\n",
    "#print(np.shape(embedded_sequences))\n",
    "\n",
    "#usually embedding is without Input layer\n",
    "#embedding_layer = Embedding(input_dim=20000, output_dim=embedding_dim, input_length=sequence_length, weights=[encoder_inputs])(encoder_inputs)\n",
    "\n",
    "inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(encoder_inputs)\n",
    "print(np.shape(inputs_reshaped))\n",
    "\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(1, embedding_dim), activation='linear', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_1 = LeakyReLU(alpha=0.3)(conv_1) #without activation at Conv2D\n",
    "#conv_1 = BatchNormalization()(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(2, embedding_dim), activation='linear', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_2 = LeakyReLU(alpha=0.3)(conv_2)\n",
    "#conv_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='linear', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_3 = LeakyReLU(alpha=0.3)(conv_3)\n",
    "#conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='linear', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_4 = LeakyReLU(alpha=0.3)(conv_4)\n",
    "#conv_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='linear', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_5 = LeakyReLU(alpha=0.3)(conv_5)\n",
    "#conv_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "'''\n",
    "conv_6 = Conv2D(num_filters, kernel_size=(6, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "conv_6 = BatchNormalization()(conv_6)\n",
    "conv_7 = Conv2D(num_filters, kernel_size=(7, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "conv_7 = BatchNormalization()(conv_7)\n",
    "conv_8 = Conv2D(num_filters, kernel_size=(8, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "conv_8 = BatchNormalization()(conv_8)\n",
    "'''\n",
    "\n",
    "#print(np.shape(conv_1))\n",
    "#print(np.shape(conv_2))\n",
    "#print(np.shape(conv_3))\n",
    "#print(np.shape(conv_4))\n",
    "#print(np.shape(conv_5))\n",
    "\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 1 + 1, 1), strides=(1,1))(conv_1) #maybe 1D\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 2 + 1, 1), strides=(1,1))(conv_2)\n",
    "maxpool_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1))(conv_3)\n",
    "maxpool_4 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1))(conv_4)\n",
    "maxpool_5 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1))(conv_5)\n",
    "\n",
    "'''\n",
    "maxpool_6 = MaxPool2D(pool_size=(sequence_length - 6 + 1, 1), strides=(1,1), padding='valid')(conv_6)\n",
    "maxpool_7 = MaxPool2D(pool_size=(sequence_length - 7 + 1, 1), strides=(1,1), padding='valid')(conv_7)\n",
    "maxpool_8 = MaxPool2D(pool_size=(sequence_length - 8 + 1, 1), strides=(1,1), padding='valid')(conv_8)\n",
    "'''\n",
    "                                                                                              \n",
    "#print(np.shape(maxpool_1))\n",
    "#print(np.shape(maxpool_2))\n",
    "#print(np.shape(maxpool_3))\n",
    "#print(np.shape(maxpool_4))\n",
    "#print(np.shape(maxpool_5))\n",
    "\n",
    "concatenated_e1 = Concatenate(axis=3)([maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5])\n",
    "#print('concatenated_1 shape:', np.shape(concatenated_e1))\n",
    "\n",
    "#flatten_e1 = Flatten()(concatenated_e1)\n",
    "#print(np.shape(flatten_e1))\n",
    "\n",
    "\n",
    "X = Flatten()(concatenated_e1)\n",
    "#print(np.shape(flatten_e1))\n",
    "\n",
    "#X = Dense(units=450, activation='linear')(X) # 450\n",
    "#print(np.shape(dense_e1))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_e2))\n",
    "\n",
    "\n",
    "#X = Dense(units=150, activation='linear')(X) #150\n",
    "#print(np.shape(dense_e1))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_e2))\n",
    "\n",
    "#dropout_e1 = Dropout(dropout_rate)(flatten_e1)\n",
    "#print(np.shape(dropout_e1))\n",
    "\n",
    "#X = Dense(units=50, activation='linear')(X) #50 \n",
    "#print(np.shape(dense_e1))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_e2))\n",
    "\n",
    "##without variational \n",
    "X = Dense(units=latent_dim, activation='linear')(X) # latent_dim\n",
    "#print(np.shape(dense_e2))\n",
    "#output_encoder = dense_e2\n",
    "\n",
    "\n",
    "class Sampling(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "#        print('sampling shape:  ',np.shape(z_mean))\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(X)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(X)\n",
    "z = Sampling()([z_mean, z_log_var])\n",
    "#print('z shape',np.shape(z))\n",
    "\n",
    "#encoder = Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
    "#encoder.summary()\n",
    "\n",
    "##decoder\n",
    "#latent_inputs = Input(shape=(latent_dim,), dtype='float32')\n",
    "#print(np.shape(latent_inputs))\n",
    "#dense_d1 = Dense(units=200, activation='relu')(latent_inputs)\n",
    "\n",
    "#dense_d1 = Dense(units=30, activation='linear')(z)\n",
    "#print(np.shape(dense_d1))\n",
    "\n",
    "\n",
    "X = Dense(units=50, activation='linear')(z)\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d1))\n",
    "\n",
    "#X = Dense(units=50, activation='linear')(X) #X = Dense(units=num_filters*5, activation='relu')(X) #50\n",
    "#print(np.shape(dense_d2))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d2))\n",
    "\n",
    "###################################### method 1\n",
    "X = Dense(units=150, activation='linear')(X) # 150\n",
    "#print(np.shape(dense_d3))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d3))\n",
    "\n",
    "X = Dense(units=450, activation='linear')(X) #450\n",
    "#print(np.shape(dense_d4))\n",
    "\n",
    "#X = Dropout(dropout_rate)(X)\n",
    "#print(np.shape(dropout_d4))\n",
    "\n",
    "X = Dense(units=embedding_dim*sequence_length, activation='linear')(X)\n",
    "#print(np.shape(dense_d5))\n",
    "\n",
    "decoder_outputs = Reshape((sequence_length, embedding_dim))(X)\n",
    "#print('output shape:', np.shape(decoder_outputs))\n",
    "\n",
    "'''\n",
    "\n",
    "################################# method 2\n",
    "reshape_d2 = Reshape((5, 1, num_filters))(dropout_d2)\n",
    "#print(np.shape(reshape_d2))\n",
    "\n",
    "tensor_d3_1 = reshape_d2[:,0]\n",
    "tensor_d3_1 = Reshape((1, 1, num_filters))(tensor_d3_1)\n",
    "#print(np.shape(tensor_d3_1))\n",
    "\n",
    "tensor_d3_2 = reshape_d2[:,1]\n",
    "tensor_d3_2 = Reshape((1, 1, num_filters))(tensor_d3_2)\n",
    "#print(np.shape(tensor_d3_2))\n",
    "\n",
    "tensor_d3_3 = reshape_d2[:,2]\n",
    "tensor_d3_3 = Reshape((1, 1, num_filters))(tensor_d3_3)\n",
    "#print(np.shape(tensor_d3_3))\n",
    "\n",
    "tensor_d3_4 = reshape_d2[:,3]\n",
    "tensor_d3_4 = Reshape((1, 1, num_filters))(tensor_d3_4)\n",
    "#print(np.shape(tensor_d3_4))\n",
    "\n",
    "tensor_d3_5 = reshape_d2[:,4]\n",
    "tensor_d3_5 = Reshape((1, 1, num_filters))(tensor_d3_5)\n",
    "#print(np.shape(tensor_d3_5))\n",
    "\n",
    "#tensor_d3_6 = reshape_d2[:,5]\n",
    "#tensor_d3_6 = Reshape((1, 1, num_filters))(tensor_d3_6)\n",
    "#tensor_d3_7 = reshape_d2[:,6]\n",
    "#tensor_d3_7 = Reshape((1, 1, num_filters))(tensor_d3_7)\n",
    "#tensor_d3_8 = reshape_d2[:,7]\n",
    "#tensor_d3_8 = Reshape((1, 1, num_filters))(tensor_d3_8)\n",
    "\n",
    "tensor_d4_1 = Conv2DTranspose(num_filters, (sequence_length -1 +1,1), activation='relu', strides=(1,1))(tensor_d3_1)\n",
    "#tensor_d4_1 = UpSampling2D((sequence_length -1 +1 ,1))(tensor_d3_1)\n",
    "#print(np.shape(tensor_d4_1))\n",
    "\n",
    "tensor_d4_2 = Conv2DTranspose(num_filters, (sequence_length -2 +1,1), activation='relu', strides=(1,1))(tensor_d3_2)\n",
    "#tensor_d4_2 = UpSampling2D((sequence_length -2 +1 ,1))(tensor_d3_2)\n",
    "#print(np.shape(tensor_d4_2))\n",
    "\n",
    "tensor_d4_3 = Conv2DTranspose(num_filters, (sequence_length -3 +1,1), activation='relu', strides=(1,1))(tensor_d3_3)\n",
    "#tensor_d4_3 = UpSampling2D((sequence_length -3 +1 ,1))(tensor_d3_3)\n",
    "#print(np.shape(tensor_d4_3))\n",
    "\n",
    "tensor_d4_4 = Conv2DTranspose(num_filters, (sequence_length -4 +1,1),  activation='relu', strides=(1,1))(tensor_d3_4)\n",
    "#tensor_d4_4 = UpSampling2D((sequence_length -4 +1 ,1))(tensor_d3_4)\n",
    "#print(np.shape(tensor_d4_4))\n",
    "\n",
    "tensor_d4_5 = Conv2DTranspose(num_filters, (sequence_length -5 +1,1), activation='relu', strides=(1,1))(tensor_d3_5)\n",
    "#tensor_d4_5 = UpSampling2D((sequence_length -5 +1 ,1))(tensor_d3_5)\n",
    "#print(np.shape(tensor_d4_5))\n",
    "\n",
    "#tensor_d4_6 = Conv2DTranspose(num_filters, (sequence_length -6 +1,1), strides=(1,1))(tensor_d3_6)\n",
    "#tensor_d4_6 = UpSampling2D((sequence_length -6 +1 ,1))(tensor_d3_6)\n",
    "#tensor_d4_7 = Conv2DTranspose(num_filters, (sequence_length -7 +1,1), strides=(1,1))(tensor_d3_7)\n",
    "#tensor_d4_7 = UpSampling2D((sequence_length -7 +1 ,1))(tensor_d3_7)\n",
    "#tensor_d4_8 = Conv2DTranspose(num_filters, (sequence_length -8 +1,1), strides=(1,1))(tensor_d3_8)\n",
    "#tensor_d4_8 = UpSampling2D((sequence_length -8 +1 ,1))(tensor_d3_8)\n",
    "\n",
    "tensor_d5_1 = Conv2DTranspose(num_filters, (1,embedding_dim), activation='relu', strides=(1,1))(tensor_d4_1)\n",
    "#print(np.shape(tensor_d5_1))\n",
    "\n",
    "tensor_d5_2 = Conv2DTranspose(num_filters, (2,embedding_dim), activation='relu', strides=(1,1))(tensor_d4_2)\n",
    "#print(np.shape(tensor_d5_2))\n",
    "\n",
    "tensor_d5_3 = Conv2DTranspose(num_filters, (3,embedding_dim), activation='relu', strides=(1,1))(tensor_d4_3)\n",
    "#print(np.shape(tensor_d5_3))\n",
    "\n",
    "tensor_d5_4 = Conv2DTranspose(num_filters, (4,embedding_dim), activation='relu', strides=(1,1))(tensor_d4_4)\n",
    "#print(np.shape(tensor_d5_4))\n",
    "\n",
    "tensor_d5_5 = Conv2DTranspose(num_filters, (5,embedding_dim), activation='relu', strides=(1,1))(tensor_d4_5)\n",
    "#print(np.shape(tensor_d5_5))\n",
    "\n",
    "#tensor_d5_6 = Conv2DTranspose(num_filters, (6,embedding_dim), strides=(1,1))(tensor_d4_6)\n",
    "#tensor_d5_7 = Conv2DTranspose(num_filters, (7,embedding_dim), strides=(1,1))(tensor_d4_7)\n",
    "#tensor_d5_8 = Conv2DTranspose(num_filters, (8,embedding_dim), strides=(1,1))(tensor_d4_8)\n",
    "\n",
    "concatenated_tensor_d5 = Concatenate(axis=3)([tensor_d5_1, tensor_d5_2, tensor_d5_3, tensor_d5_4, tensor_d5_5])\n",
    "#print(np.shape(concatenated_tensor_d5))\n",
    "\n",
    "output=Conv2D(1, (1, 1), activation='linear')(concatenated_tensor_d5)\n",
    "#print(np.shape(output))\n",
    "\n",
    "decoder_outputs = Reshape((sequence_length, embedding_dim))(output)\n",
    "print('outputshape:', np.shape(decoder_outputs))\n",
    "'''\n",
    "\n",
    "autoencoder = keras.Model(encoder_inputs, decoder_outputs, name=\"CVAE\")\n",
    "autoencoder.summary()\n",
    "\n",
    "#outputs = decoder(encoder(encoder_inputs)[2])\n",
    "#cvae = keras.Model(encoder_inputs, outputs, name='CVAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoder_inputs_reshaped=np.reshape(encoder_inputs, (encoder_inputs.shape[0]),-1)\n",
    "#decoder_outputs_reshaped=np.reshape(decoder_outputs, (decoder_outputs_.shape[0]),-1)\n",
    "#print(np.shape(decoder_outputs_reshaped))\n",
    "#reconstruction_loss = tf.keras.losses.mse(encoder_inputs_reshaped, decoder_outputs_reshaped) # tf.keras.losses.binary_crossentropy\n",
    "#print(np.shape(reconstruction_loss))\n",
    "\n",
    "##without reshape\n",
    "##reconstruction_loss = K.mean(tf.keras.losses.binary_crossentropy(encoder_inputs, decoder_outputs),axis=-1) \n",
    "#reconstruction_loss= customLoss(encoder_inputs, decoder_outputs)\n",
    "##############reconstruction_loss = K.mean(tf.keras.losses.mse(encoder_inputs, decoder_outputs),axis=-1) \n",
    "\n",
    "reconstruction_loss = K.mean(tf.keras.losses.mse(encoder_inputs, decoder_outputs),axis=-1) \n",
    "# cosine_similarity (bad), squared_hinge (very bad), sparse_categorical_crossentropy (not working),\n",
    "# poisson (loss:nan), KLD (very bad),\n",
    "# msle (good for 5 epochs / not good for 8), mse (good medium for 5/10 epochs), mean_absolute_error (very good for 5 epochs), \n",
    "# mape (good for 5 epochs), logcosh (good for 5 epochs),   huber (good for 5 epochs),\n",
    "#  hinge (very bad), categorical_hinge (very bad), categorical_crossentropy (very bad), binary_crossentropy (very bad),\n",
    "# for binary cross value the input should be between [0,1]\n",
    "\n",
    "#print(np.shape(reconstruction_loss))\n",
    "\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "#print(np.shape(kl_loss))\n",
    "\n",
    "cvae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "#cvae_loss = K.mean(reconstruction_loss )\n",
    "#print(np.shape(cvae_loss))\n",
    "autoencoder.add_loss(cvae_loss)\n",
    "\n",
    "#lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=1e-3, decay_steps=10000, dcay_rate=0.9)\n",
    "#optim = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "optim = keras.optimizers.Adam(learning_rate=1e-3) #(learning_rate=0.001)\n",
    "#optim = tf.keras.optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=False, name=\"Adam\")\n",
    "\n",
    "autoencoder.compile(optimizer=optim , loss= tf.keras.losses.MeanSquaredError())\n",
    "#autoencoder.compile(optimizer=optim )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##type 2\n",
    "sequence_length=25\n",
    "embedding_dim=25\n",
    "##encoder\n",
    "encoder_inputs1 = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "print(np.shape(encoder_inputs1))\n",
    "\n",
    "x = Reshape((sequence_length, embedding_dim, 1))(encoder_inputs1)\n",
    "\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Conv2D(8, (3,3), activation='relu', padding='same')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = MaxPooling2D((2, 2), padding='same')(x) \n",
    "print(np.shape(x))\n",
    "\n",
    "x = Flatten()(x)\n",
    "print(np.shape(x))\n",
    "#x = Dense(1764, activation=\"relu\")(x)\n",
    "\n",
    "'''\n",
    "class Sampling1(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling1()([z_mean, z_log_var])  #encoded data\n",
    "'''\n",
    "\n",
    "##decoder\n",
    "x = Dense(10, activation=\"relu\")(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Dense(128, activation=\"relu\")(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Reshape((4, 4, 8))(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Conv2DTranspose(8, (4, 4), activation='linear', padding='valid')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "print(np.shape(x))\n",
    "print('**********')\n",
    "\n",
    "#x = Conv2DTranspose(8, (7, 7), activation='relu', padding='valid')(x)\n",
    "#print(np.shape(x))\n",
    "\n",
    "#x = UpSampling2D((2, 2))(x)\n",
    "#print(np.shape(x))\n",
    "\n",
    "x = Conv2D(8, (2, 2), activation='linear', padding='valid')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "x = Conv2D(8, (2, 2), activation='linear', padding='valid')(x)\n",
    "print(np.shape(x))\n",
    "\n",
    "decoded = Conv2D(1, (2, 2), activation='linear', padding='same')(x)\n",
    "print(np.shape(decoded))\n",
    "\n",
    "decoder_outputs1 = Reshape((sequence_length, embedding_dim))(decoded)\n",
    "print(np.shape(decoder_outputs1))\n",
    "\n",
    "\n",
    "autoencoder = keras.Model(encoder_inputs1, decoder_outputs1)\n",
    "autoencoder.compile(optimizer='adam', loss='MeanSquaredError')\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "##type 2\n",
    "sequence_length=16 # or 24 or 32 or 64 \n",
    "##encoder\n",
    "encoder_inputs1 = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "\n",
    "x = Reshape((sequence_length, embedding_dim, 1))(encoder_inputs1)\n",
    "\n",
    "x = Conv2D(16, (4,4), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 4), padding='same')(x)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 4), padding='same')(x)\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 4), padding='same')(x) \n",
    "\n",
    "x = Flatten()(x)\n",
    "print(np.shape(x))\n",
    "#x = Dense(1764, activation=\"relu\")(x)\n",
    "\n",
    "class Sampling1(Layer):\n",
    "    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
    "\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch = tf.shape(z_mean)[0]\n",
    "        dim = tf.shape(z_mean)[1]\n",
    "        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "    \n",
    "z_mean = Dense(latent_dim, name=\"z_mean\")(x)\n",
    "z_log_var = Dense(latent_dim, name=\"z_log_var\")(x)\n",
    "z = Sampling1()([z_mean, z_log_var])  #encoded data\n",
    "\n",
    "##decoder\n",
    "x = Dense(192, activation=\"relu\")(z)\n",
    "x = Reshape((2, 12, 8))(x)\n",
    "\n",
    "x = Conv2DTranspose(8, (4, 4), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 4))(x)\n",
    "x = Conv2DTranspose(8, (4, 4), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 4))(x)\n",
    "x = Conv2DTranspose(16, (4, 4), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 4))(x)\n",
    "decoded = Conv2D(1, (4, 4), activation='sigmoid', padding='same')(x)\n",
    "decoder_outputs1 = Reshape((sequence_length, embedding_dim))(decoded)\n",
    "\n",
    "autoencoder1 = keras.Model(encoder_inputs1, decoder_outputs1)\n",
    "#autoencoder1.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "#autoencoder1.summary()\n",
    "\n",
    "#encoder_inputs_reshaped=np.reshape(encoder_inputs, (encoder_inputs.shape[0]),-1)\n",
    "#decoder_outputs_reshaped=np.reshape(decoder_outputs, (decoder_outputs_.shape[0]),-1)\n",
    "#print(np.shape(decoder_outputs_reshaped))\n",
    "#reconstruction_loss = tf.keras.losses.mse(encoder_inputs_reshaped, decoder_outputs_reshaped) # tf.keras.losses.binary_crossentropy\n",
    "#print(np.shape(reconstruction_loss))\n",
    "\n",
    "##without reshape\n",
    "##reconstruction_loss = K.mean(tf.keras.losses.binary_crossentropy(encoder_inputs, decoder_outputs),axis=-1) \n",
    "reconstruction_loss1 = K.mean(tf.keras.losses.mse(encoder_inputs1, decoder_outputs1),axis=-1) \n",
    "#print(np.shape(reconstruction_loss1))\n",
    "\n",
    "kl_loss1 = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss1 = K.sum(kl_loss1, axis=-1)\n",
    "kl_loss1 *= -0.5\n",
    "#print(np.shape(kl_loss1))\n",
    "\n",
    "cvae_loss1 = K.mean(reconstruction_loss1 + kl_loss1)\n",
    "#print(np.shape(cvae_loss1))\n",
    "autoencoder1.add_loss(cvae_loss1)\n",
    "\n",
    "optim = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "autoencoder1.compile(optimizer=optim)\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train, x_test, validation_train, validation_test = train_test_split(x, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 25, 25)\n",
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 39ms/step - loss: 30.3282 - val_loss: 20.8669\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 18.8877 - val_loss: 13.8989\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 12.5186 - val_loss: 9.2776\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 8.3170 - val_loss: 6.1608\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 5.5247 - val_loss: 4.1509\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 3.7523 - val_loss: 2.9669\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 2.6758 - val_loss: 2.2054\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.9871 - val_loss: 1.6963\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 1.5322 - val_loss: 1.3728\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 1.2209 - val_loss: 1.1461\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 1.0199 - val_loss: 0.9931\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.8898 - val_loss: 0.8938\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.7890 - val_loss: 0.8120\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.7190 - val_loss: 0.7601\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6708 - val_loss: 0.7240\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6409 - val_loss: 0.6986\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.6056 - val_loss: 0.6745\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5991 - val_loss: 0.6640\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5699 - val_loss: 0.6502\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5619 - val_loss: 0.6427\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5603 - val_loss: 0.6367\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5602 - val_loss: 0.6323\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.5592 - val_loss: 0.6292\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 25ms/step - loss: 0.5502 - val_loss: 0.6249\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5473 - val_loss: 0.6200\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5434 - val_loss: 0.6211\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5369 - val_loss: 0.6215\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5321 - val_loss: 0.6157\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 26ms/step - loss: 0.5301 - val_loss: 0.6148\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.5383 - val_loss: 0.6141\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5346 - val_loss: 0.6145\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5308 - val_loss: 0.6140\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 24ms/step - loss: 0.5358 - val_loss: 0.6174\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 1s 75ms/step - loss: 0.5323 - val_loss: 0.6111\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5321 - val_loss: 0.6122\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5326 - val_loss: 0.6144\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5411 - val_loss: 0.6139\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5216 - val_loss: 0.6096\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 1s 69ms/step - loss: 0.5261 - val_loss: 0.6108\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5232 - val_loss: 0.6095\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5338 - val_loss: 0.6132\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5338 - val_loss: 0.6135\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5197 - val_loss: 0.6132\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5273 - val_loss: 0.6087\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5163 - val_loss: 0.6091\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5246 - val_loss: 0.6094\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5283 - val_loss: 0.6109\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5287 - val_loss: 0.6079\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5202 - val_loss: 0.6094\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5260 - val_loss: 0.6080\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 22ms/step - loss: 0.5240 - val_loss: 0.6085\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5210 - val_loss: 0.6093\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5327 - val_loss: 0.6104\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5343 - val_loss: 0.6095\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5357 - val_loss: 0.6091\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.5204 - val_loss: 0.6088\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5298 - val_loss: 0.6109\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5215 - val_loss: 0.6065\n",
      "INFO:tensorflow:Assets written to: ./glove_results\\autoencoder\\assets\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 27ms/step - loss: 0.5371 - val_loss: 0.6090\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5417 - val_loss: 0.6102\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5319 - val_loss: 0.6082\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5234 - val_loss: 0.6085\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5228 - val_loss: 0.6092\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5174 - val_loss: 0.6072\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 21ms/step - loss: 0.5198 - val_loss: 0.6093\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5202 - val_loss: 0.6076\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5242 - val_loss: 0.6075\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 23ms/step - loss: 0.5305 - val_loss: 0.6098\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "checkpoint = ModelCheckpoint('./glove_results/autoencoder', verbose=0, save_best_only=True)\n",
    "\n",
    "csv_logger = CSVLogger('./glove_results/log.out', append=True, separator=';')\n",
    "\n",
    "#history= autoencoder.fit(x_train,x_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,batch_size=32,epochs=1000)\n",
    "print(np.shape(x_train))\n",
    "\n",
    "callbacks_list = [checkpoint, csv_logger, monitor]\n",
    "results=history=autoencoder.fit(x_train,x_train,\n",
    "                        epochs=100,\n",
    "                        #callbacks=[monitor],\n",
    "                        callbacks=callbacks_list ,       \n",
    "                        batch_size=128, # or 64\n",
    "                        shuffle= True,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.25)\n",
    "\n",
    "\n",
    "#results=autoencoder.fit(x_train,x_train, epochs=50, batch_size=1)\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEGCAYAAACNaZVuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAdoElEQVR4nO3dfZRcdZ3n8fe3qp+TTnceOiSkgQSCIQ+S0LQZFJAn5YCOz7gajLJMzkRdVHyaNcOyu5jjnBN1hyeXo8Yh0TlkcdWosIwSWRZ1EE3oZICExNAMBGnIQ6ch6Tx1uqvqu3/U7XSlU93pp1u3uu/ndU6dqrp1q+6nO5VP3f7dW/eauyMiIvGSiDqAiIgUnspfRCSGVP4iIjGk8hcRiSGVv4hIDJVEHWAgpkyZ4jNnzow6hojIqLJ58+b97l6X77FRUf4zZ86kqakp6hgiIqOKmb3S12Ma9hERiSGVv4hIDKn8RURiaFSM+YtI8enq6qKlpYWOjo6oo8ReRUUF9fX1lJaWDvg5Kn8RGZKWlhaqq6uZOXMmZhZ1nNhyd9ra2mhpaWHWrFkDfp6GfURkSDo6Opg8ebKKP2JmxuTJkwf9F5jKX0SGTMVfHIby7zCmy3///kd45ZVVUccQESk6Y7r833zzN/zlLyp/kbGora2NRYsWsWjRIqZNm8aMGTNO3O/s7BzQa9x8883s3Lmz33nuu+8+1q1bNxKRueyyy3jmmWdG5LWGa0xv8C0pqSWdbsc9g9mY/pwTiZ3JkyefKNI77riD8ePH89WvfvWkedwddyeRyP//f+3ataddzi233DL8sEVoTDdiSUkt4KRS7VFHEZECefHFF1mwYAGf+cxnaGhoYPfu3SxfvpzGxkbmz5/PypUrT8zbvSaeSqWora1lxYoVLFy4kLe//e3s27cPgNtvv5277777xPwrVqxg8eLFzJkzh6eeegqAI0eO8JGPfISFCxeyZMkSGhsbT7uG/8ADD/DWt76VBQsWcNtttwGQSqX45Cc/eWL6vffeC8Bdd93FvHnzWLhwIUuXLh2R39OYX/MHSKUOUFpaG3EakbGrufmLHD48ssMZ48cv4vzz7x7Sc7dv387atWv53ve+B8CqVauYNGkSqVSKq666ihtuuIF58+ad9JyDBw9yxRVXsGrVKr785S+zZs0aVqxYccpruzubNm3i4YcfZuXKlTz66KN85zvfYdq0aaxfv55nn32WhoaGfvO1tLRw++2309TURE1NDe9617t45JFHqKurY//+/WzduhWAAwcOAPCtb32LV155hbKyshPThisGa/7Z8heR+DjvvPN429veduL+gw8+SENDAw0NDezYsYPt27ef8pzKykquv/56AC6++GJ27dqV97U//OEPnzLPk08+ycc//nEAFi5cyPz58/vNt3HjRq6++mqmTJlCaWkpN954I7///e+ZPXs2O3fu5NZbb2XDhg3U1NQAMH/+fJYuXcq6desG9UWu/ozxNf+JgMpfJGxDXUMPy7hx407cbm5u5p577mHTpk3U1taydOnSvPvEl5WVnbidTCZJpVJ5X7u8vPyUedx9UPn6mn/y5Mk899xz/PrXv+bee+9l/fr1rF69mg0bNvC73/2Ohx56iG984xts27aNZDI5qGX2pjV/ERnT2tvbqa6uZsKECezevZsNGzaM+DIuu+wyfvKTnwCwdevWvH9Z5Lrkkkt44oknaGtrI5VK8eMf/5grrriC1tZW3J2PfvSjfP3rX2fLli2k02laWlq4+uqr+fa3v01raytHjx4dduYxvuav8heJu4aGBubNm8eCBQs499xzufTSS0d8GZ///Of51Kc+xYUXXkhDQwMLFiw4MWSTT319PStXruTKK6/E3Xnf+97He9/7XrZs2cKyZctwd8yMb37zm6RSKW688UYOHTpEJpPha1/7GtXV1cPObIP9cyUKjY2NPpSTuXR1vckf/jCJ8867k7PO+lIIyUTia8eOHcydOzfqGEUhlUqRSqWoqKigubmZa6+9lubmZkpKCrd+ne/fw8w2u3tjvvnH+Jr/BEBr/iISrsOHD3PNNdeQSqVwd77//e8XtPiHorjTDZNZkmRygspfREJVW1vL5s2bo44xKGN6gy9kx/1V/iLhGA3DxnEwlH+HGJT/RJW/SAgqKipoa2vTB0DEuo/nX1FRMajnhTbsY2ZnAf8MTAMywGp3v8fM7gD+FmgNZr3N3X8VVg6t+YuEo76+npaWFlpbW08/s4Sq+0xegxHmmH8K+Iq7bzGzamCzmT0WPHaXu/+PEJd9QklJLR0dLxdiUSKxUlpaOqgzR0lxCa383X03sDu4fcjMdgAzwlpeX7TmLyJyqoKM+ZvZTOAiYGMw6XNm9pyZrTGziX08Z7mZNZlZ03D+rFT5i4icKvTyN7PxwHrgi+7eDnwXOA9YRPYvg3/M9zx3X+3uje7eWFdXN+Tl9xzTPz3k1xARGWtCLX8zKyVb/Ovc/ecA7r7X3dPungF+ACwOM0PPIR4OhrkYEZFRJbTyt+wZhe8Hdrj7nTnTp+fM9iFgW1gZAEpLdWRPEZHewtzb51Lgk8BWM+s+y8NtwBIzWwQ4sAv4dIgZdHA3EZE8wtzb50nA8jwU2j79+aj8RUROFYNv+Kr8RUR6U/mLiMSQyl9EJIbGfPknk9VAglTqzaijiIgUjTFf/mYJSkpqtOYvIpJjzJc/6BAPIiK9qfxFRGJI5S8iEkMqfxGRGFL5i4jEUEzKX+fxFRHJFZPyryWdPkwm0xV1FBGRohCb8gcd019EpFvMyl9DPyIioPIXEYkllb+ISAyp/EVEYigm5a/z+IqI5IpJ+WvNX0QkVyzKP5kcByR1TH8RkUAsyt/MdIgHEZEcsSh/0PF9RERyqfxFRGJI5S8iEkOxKf/SUh3ZU0SkW2zKX2v+IiI9VP4iIjEUq/LPZI6SyXRGHUVEJHKhlb+ZnWVmT5jZDjN73sxuDaZPMrPHzKw5uJ4YVoZc+paviEiPMNf8U8BX3H0ucAlwi5nNA1YAj7v7+cDjwf3QqfxFRHqEVv7uvtvdtwS3DwE7gBnAB4AfBbP9CPhgWBlyqfxFRHoUZMzfzGYCFwEbgTPcfTdkPyCAqX08Z7mZNZlZU2tr67Az6MieIiI9Qi9/MxsPrAe+6O7tA32eu69290Z3b6yrqxt2Dq35i4j0CLX8zayUbPGvc/efB5P3mtn04PHpwL4wM3RT+YuI9Ahzbx8D7gd2uPudOQ89DNwU3L4JeCisDLlU/iIiPUpCfO1LgU8CW83smWDabcAq4Cdmtgz4C/DREDOckEhUYlaqY/qLiBBi+bv7k4D18fA1YS23Lzqmv4hIj9h8wxd0iAcRkW4xK38d2VNEBGJX/lrzFxEBlb+ISCyp/EVEYkjlLyISQ7Er/0ymg3S6I+ooIiKRil35g77lKyISs/LXkT1FRCB25a81fxERUPmLiMSSyl9EJIZU/iIiMRSr8i8tzW7w7eraH3ESEZFoxar8E4lySkom09n5etRRREQiFavyBygvP5Pjx1X+IhJvMSz/GXR2vhZ1DBGRSMWu/MvKZnD8uMpfROItduVfXn4mnZ17yWRSUUcREYlMDMt/BpChq2tv1FFERCITu/IvKzsTQBt9RSTWYlf+2TV/NO4vIrEW2/LXHj8iEmexK//S0jrMSjTsIyKxFrvyN0tQVjZdwz4iEmuxK3/IbvTVIR5EJM5iWf7l5fqil4jEW0zL/0yVv4jEWmjlb2ZrzGyfmW3LmXaHmb1mZs8El/eEtfz+lJXNIJ0+SDp9JIrFi4hELsw1/x8C1+WZfpe7Lwouvwpx+X3q2ddf4/4iEk+hlb+7/x54I6zXH47y8uy3fLXRV0TiKoox/8+Z2XPBsNDEvmYys+Vm1mRmTa2trSMaoKxM3/IVkXgbUPmb2XlmVh7cvtLMvmBmtUNY3neB84BFwG7gH/ua0d1Xu3ujuzfW1dUNYVF9617zV/mLSFwNdM1/PZA2s9nA/cAs4H8NdmHuvtfd0+6eAX4ALB7sa4yEkpIJJJPjNewjIrE10PLPuHsK+BBwt7t/CZg+2IWZWe5zPgRs62vesJWVaXdPEYmvkgHO12VmS4CbgPcF00r7e4KZPQhcCUwxsxbgvwNXmtkiwIFdwKeHkHlEZL/opTV/EYmngZb/zcBngH9w95fNbBbwQH9PcPcleSbfP8h8oSkvn8HBg09GHUNEJBIDKn933w58ASDYQ6fa3VeFGSxs2WGf13F3zCzqOCIiBTXQvX1+a2YTzGwS8Cyw1szuDDdauMrLZ+DeSVdXW9RRREQKbqAbfGvcvR34MLDW3S8G3hVerPB1n85RJ3URkTgaaPmXBHvq/AfgkRDzFIwO8SAicTbQ8l8JbAD+3d2fNrNzgebwYoVPX/QSkTgb6AbfnwI/zbn/EvCRsEIVQllZ9isH+qKXiMTRQDf41pvZL4JDNO81s/VmVh92uDAlEmWUlk7Vmr+IxNJAh33WAg8DZwIzgP8TTBvVdFIXEYmrgZZ/nbuvdfdUcPkhMLJHW4tAWdkMDfuISCwNtPz3m9lSM0sGl6XAqN9BXmv+IhJXAy3/vyG7m+cesodivoHsIR9GtfLyGXR17SOT6Yo6iohIQQ2o/N39L+7+fnevc/ep7v5Bsl/4GtV6vui1O+IkIiKFNZwzeX15xFJEpOeLXhr6EZF4GU75j/qjoXWXvzb6ikjcDKf8fcRSRKR72Edr/iISN/1+w9fMDpG/5A2oDCVRAZWWTsGsVMf3EZHY6bf83b26UEGiYGaUlZ2pI3uKSOwMZ9hnTMiezlHlLyLxovLXuXxFJIZiX/4a9hGROIp9+VdUzCSdPkxnZ2vUUURECib25V9VdQEAR4/+OeIkIiKFo/JX+YtIDMW+/CsqziaRqOTo0R1RRxERKZjYl79ZgqqqOVrzF5FYiX35Q3boR+UvInGi8geqqubS0bGLdPpY1FFERApC5U/3Rl/n2LEXoo4iIlIQoZW/ma0xs31mti1n2iQze8zMmoPriWEtfzC0x4+IxE2Ya/4/BK7rNW0F8Li7nw88HtyPXGXl+YBx5Ij2+BGReAit/N3998AbvSZ/APhRcPtHwAfDWv5gJJOVVFTM0pq/iMRGocf8z3D33QDB9dQCL79P2uNHROKkaDf4mtlyM2sys6bW1vCPu1NVdQHHju3EPR36skREolbo8t9rZtMBgut9fc3o7qvdvdHdG+vq6kIPVlU1l0ymg46Ov4S+LBGRqBW6/B8Gbgpu3wQ8VODl90l7/IhInIS5q+eDwB+BOWbWYmbLgFXAu82sGXh3cL8oqPxFJE76PYfvcLj7kj4euiasZQ5HWdkUSkun6ABvIhILRbvBNwra40dE4kLln0PlLyJxofLPUVU1l66uVrq62qKOIiISKpV/Dm30FZG4UPnnUPmLSFyo/HNUVJxDIlGhA7yJyJin8s9hlqSy8i1a8xeRMU/l34v2+BGROFD595I9pePLpNMdUUcREQmNyr+X7EbfDMeONUcdRUQkNCr/XrTHj4jEgcq/l6qqtwDG0aPbo44iIhIalX8vyWQVVVUX0N6+MeooIiKhUfnnUVNzOQcPPqWzeonImKXyz6Om5nLS6YMcObIt6igiIqFQ+edRU3MZAAcO/GvESUREwqHyz6Oi4hzKy+s5eFDlLyJjk8o/DzMLxv3/FXePOo6IyIhT+fehpuZyOjt309HxUtRRRERGnMq/DzU1lwMa9xeRsUnl34dx4+ZRUjKRgwefjDqKiMiIU/n3wSxBTc1l2ugrImOSyr8fNTWXcezYC3R27o06iojIiFL596N73F9DPyIy1qj8+1FdfTGJRKU2+orImKPy70ciUcaECX+lcX8RGXNU/qdRU3M5hw8/QyrVHnUUEZERo/I/jey4f4b29j9GHUVEZMSo/E9jwoRLgKQ2+orImFISxULNbBdwCEgDKXdvjCLHQJSUVDN+/CJt9BWRMSXKNf+r3H1RMRd/t9rayzl0aCPpdEfUUURERoSGfQZg0qTryWQ6aGt7JOooIiIjIqryd+A3ZrbZzJbnm8HMlptZk5k1tba2FjjeySZOvIby8nr27Lk/0hwiIiMlqvK/1N0bgOuBW8zsnb1ncPfV7t7o7o11dXWFT5jDLMm0af+RN97YQEfHq5FmEREZCZGUv7u/HlzvA34BLI4ix2BMm3Yz4OzZ86Ooo4iIDFvBy9/MxplZdfdt4Fqg6M+UXll5LrW1V7Fnz1rcM1HHEREZlijW/M8AnjSzZ4FNwL+4+6MR5Bi06dOX0dHxEgcO/C7qKCIiw1Lw/fzd/SVgYaGXOxKmTPkwyWQNe/asYeLEq6KOIyIyZNrVcxCSyUrOOONGWlt/Rip1MOo4IiJDpvIfpOnTl5HJdLB374NRRxERGTKV/yCNH9/AuHEXsmfPmqijiIgMmcp/kMyM6dOXcejQ0xw+vDXqOCIiQ6LyH4IzzvgEZmW89tp9UUcRERkSlf8QlJZOZvr0v2X37h9w6NCWqOOIiAyayn+Izj33Hygrm8oLL3wa93TUcUREBkXlP0QlJTWcd95dHDrUxGuvfTfqOCIig6LyH4apUz/GxInX8vLLt3H8+OtRxxERGTCV/zCYGeeffx+ZTCcvvvilqOOIiAyYyn+Yqqpmc845t9Pa+hPa2kbFIYpERFT+I+Hss/+Oyso5NDf/J1Kp9qjjiIiclsp/BCQS5cyZs5rjx19l69a/Jp0+EnUkEZF+qfxHSG3tO5k79wEOHvwD27Z9UCd7F5GipvIfQVOnfowLLljDm2/+X55//gYymc6oI4mI5KXyH2HTpt3EW97yPd5441/Yvn0JmUwq6kgiIqdQ+YfgzDM/zezZd7N//895/vkP0dnZGnUkEZGTqPxDUl9/K7Nnf4c33vgNTz89n9bWX0YdSUTkBJV/iOrrP8fFFzdRXj6D55//EDt23ERX14GoY4mIqPzDNn78W2lo2Mg55/xX9u5dx9NPL+C1175HOn0s6mgiEmMq/wJIJMqYNWslDQ1PUV5+Js3Nn+VPfzqbXbu+Tmfn/qjjiUgMqfwLaMKExTQ0bGTRot8yYcIl7Np1B3/609n8+c9/w/79j+ivAREpmJKoA8SNmVFbewW1tVdw5Mh2Xn31Tlpbf8qePWtJJKqYNOk6pkz5ADU176Si4hzMLOrIIjIGmbtHneG0GhsbvampKeoYoclkOjlw4Lfs3/9L9u9/iM7O7OGhS0unMmHCYqqrFzN+/EVUVc2homImiURpxIlFZDQws83u3pj3MZV/cXHPcPjws7S3/4lDhzbR3r6Jo0d3ANl/J7MSKipmUVn5Fioqzqa8fAZlZTMoL6+nvHw6JSWTKS2dRCJRFu0PIiKR66/8NexTZMwSVFdfRHX1RcBnAUil2jlyZBvHjjVz9OgLHDv2AkePNtPe/kdSqTfyvk4yOZ6SkkmUlNRSUjKBZHJCcF1NIlFFMlkVXI8jkSgnkSjHrDzndilmpSQSpZiVBfdLel2SOddJIIlZAkgEw1WJYHoCs9zbGsoSiZrKfxQoKZlATc07qKl5xymPpdPHOH78NTo7X6Ozcw9dXW10db1BKtVGV1cbqVQ76XQ7nZ17OXasmXT6EOn0UTKZo7hHfeiJBGAnPih6bndfclnOh0bPPL2nZT98uj94jJ6/bPv7Czd3ubn7QOR7Tk+uk5ed75pBfNCd+tz+l9/X6w7lL/n8r3Vy9lNznTxqMJjlWp7XH9xz+/75o5T7cxngwe+o//fe6cyZ8wNqay8fiYAnUfmPcslkJVVVs6mqmj3o52YyXWQyR8lkOshkjp+4uB8nk+nCPXvJZDpxT+VcuoLrdPABkg5up8m+4TNAptd1GvfMiXm6L9nHTr2d6+T/QN3z9jctE9zOkPtB0lfZ9MzbnSF/eecvu5Ovh1aIPa/h7oMs3dzHBl+qfQ/7nu7nGNoH3ckfxj2ZB6bvD/JTf29DM5DXyTfPqT9X98/WeyUl33P6l0xWD2i+wYqk/M3sOuAeIAn8k7uviiJH3CUSpSQSNUBN1FFEpMAKvp+/ZQd+7wOuB+YBS8xsXqFziIjEWRRf8loMvOjuL7l7J/Bj4AMR5BARia0oyn8G8GrO/ZZg2knMbLmZNZlZU2urDoksIjKSoij/fFtTTtny4e6r3b3R3Rvr6uoKEEtEJD6iKP8W4Kyc+/XA6xHkEBGJrSjK/2ngfDObZWZlwMeBhyPIISISWwXf1dPdU2b2OWAD2V0917j784XOISISZ5Hs5+/uvwJ+FcWyRURklBzYzcxagVcGOPsUYLSdIUWZC2c05h6NmWF05h6NmaHv3Oe4e949ZkZF+Q+GmTX1dRS7YqXMhTMac4/GzDA6c4/GzDC03DqTl4hIDKn8RURiaCyW/+qoAwyBMhfOaMw9GjPD6Mw9GjPDEHKPuTF/ERE5vbG45i8iIqeh8hcRiaExU/5mdp2Z7TSzF81sRdR5+mJma8xsn5lty5k2ycweM7Pm4HpilBl7M7OzzOwJM9thZs+b2a3B9KLNbWYVZrbJzJ4NMn89mD7LzDYGmf93cIiRomNmSTP7NzN7JLhf1LnNbJeZbTWzZ8ysKZhWtO+PbmZWa2Y/M7M/B+/vtxdzbjObE/yOuy/tZvbFoWQeE+U/yk4Q80Pgul7TVgCPu/v5wOPB/WKSAr7i7nOBS4Bbgt9vMec+Dlzt7guBRcB1ZnYJ8E3griDzm8CyCDP251ZgR8790ZD7KndflLO/eTG/P7rdAzzq7hcAC8n+zos2t7vvDH7Hi4CLgaPALxhKZncf9Rfg7cCGnPt/D/x91Ln6yTsT2JZzfycwPbg9HdgZdcbT5H8IePdoyQ1UAVuAvyL7LciSfO+bYrmQPdLt48DVwCNkD4Ne1LmBXcCUXtOK+v0BTABeJtjxZbTkzsl5LfCHoWYeE2v+DPAEMUXsDHffDRBcT404T5/MbCZwEbCRIs8dDJ08A+wDHgP+HTjg2bPOQ/G+T+4G/jPZs8oDTKb4czvwGzPbbGbLg2lF/f4AzgVagbXBENs/mdk4ij93t48DDwa3B515rJT/gE4QI8NjZuOB9cAX3b096jyn4+5pz/55XE/29KFz881W2FT9M7O/Bva5++bcyXlmLarcwKXu3kB26PUWM3tn1IEGoARoAL7r7hcBRyiiIZ7+BNt83g/8dKivMVbKf7SfIGavmU0HCK73RZznFGZWSrb417n7z4PJRZ8bwN0PAL8lu72i1sy6j2ZbjO+TS4H3m9kusue3vprsXwJFndvdXw+u95Edg15M8b8/WoAWd98Y3P8Z2Q+DYs8N2Q/ZLe6+N7g/6MxjpfxH+wliHgZuCm7fRHZMvWiYmQH3Azvc/c6ch4o2t5nVmVltcLsSeBfZjXlPADcEsxVVZgB3/3t3r3f3mWTfx//P3T9BEec2s3FmVt19m+xY9DaK+P0B4O57gFfNbE4w6RpgO0WeO7CEniEfGErmqDdajODGj/cAL5Ad1/0vUefpJ+eDwG6gi+yaxzKyY7qPA83B9aSoc/bKfBnZYYbngGeCy3uKOTdwIfBvQeZtwH8Lpp8LbAJeJPsnc3nUWfv5Ga4EHin23EG2Z4PL893//4r5/ZGTfRHQFLxPfglMLPbcZHdgaANqcqYNOrMO7yAiEkNjZdhHREQGQeUvIhJDKn8RkRhS+YuIxJDKX0QkhlT+Emtmlu51lMQR+4anmc3MPXqrSDEpOf0sImPaMc8eAkIkVrTmL5JHcHz6bwbnBNhkZrOD6eeY2eNm9lxwfXYw/Qwz+0Vw/oBnzewdwUslzewHwTkFfhN82xgz+4KZbQ9e58cR/ZgSYyp/ibvKXsM+H8t5rN3dFwP/k+zxdQhu/7O7XwisA+4Npt8L/M6z5w9oIPtNV4DzgfvcfT5wAPhIMH0FcFHwOp8J64cT6Yu+4SuxZmaH3X18num7yJ4M5qXgoHZ73H2yme0ne9z0rmD6bnefYmatQL27H895jZnAY549wQZm9jWg1N2/YWaPAofJHlLgl+5+OOQfVeQkWvMX6Zv3cbuvefI5nnM7Tc92tveSPfvcxcDmnCN2ihSEyl+kbx/Luf5jcPspskfbBPgE8GRw+3Hgs3DiJDIT+npRM0sAZ7n7E2RP2lILnPLXh0iYtLYhcVcZnO2r26Pu3r27Z7mZbSS7krQkmPYFYI2Z/R3Zs0DdHEy/FVhtZsvIruF/luzRW/NJAg+YWQ3ZE7Xc5dlzDogUjMb8RfIIxvwb3X1/1FlEwqBhHxGRGNKav4hIDGnNX0QkhlT+IiIxpPIXEYkhlb+ISAyp/EVEYuj/A5pM0F9yps7zAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "#plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = results.history['loss']\n",
    "val_loss = results.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "#plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=autoencoder.get_weights() \n",
    "#or\n",
    "'''\n",
    "for layer in autoencoder.layers:\n",
    "    print(layer.get_config(), layer.get_weights())\n",
    "#or    \n",
    "first_layer_weights = model.layers[0].get_weights()[0]\n",
    "first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "second_layer_biases  = model.layers[1].get_weights()[1]    \n",
    "'''\n",
    "#or\n",
    "#autoencoder.get_layer('conv2d_transpose_27').get_weights()[0]\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = np.expand_dims(x_train, -1).astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.27281773"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(np.shape(x_train))\n",
    "t0=time.time()\n",
    "reconstructions = autoencoder.predict(x_train)\n",
    "\n",
    "x_train_reshaped = np.reshape(x_train, (x_train.shape[0],-1)) \n",
    "#print(np.shape(x_train_reshaped))\n",
    "\n",
    "reconstructions_reshaped = np.reshape(reconstructions, (reconstructions.shape[0],-1)) \n",
    "#print(np.shape(reconstructions_reshaped))\n",
    "\n",
    "#train_loss = tf.keras.losses.mse(x_train_reshaped, reconstructions_reshaped)\n",
    "#or\n",
    "train_loss = K.mean(tf.keras.losses.mse(x_train, reconstructions),axis=-1)\n",
    "\n",
    "print(np.shape(train_loss))\n",
    "\n",
    "plt.hist(train_loss, bins=50)\n",
    "plt.xlabel(\"Train loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()\n",
    "#print( time.time() - t0)\n",
    "np.mean(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.3700211, -5.601961)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(reconstructions)\n",
    "max_val = np.max(reconstructions)\n",
    "min_val = np.min(reconstructions)\n",
    "max_val, min_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i,kk in enumerate(train_loss):\n",
    "#    if kk<0.00000025:\n",
    "#        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  0.43631572\n"
     ]
    }
   ],
   "source": [
    "threshold = np.mean(train_loss) + np.std(train_loss)\n",
    "print(\"Threshold: \", threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_:  0.27281773\n"
     ]
    }
   ],
   "source": [
    "mean_ =  np.mean(train_loss)\n",
    "print(\"mean_: \", mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2001, 25, 25)\n",
      "(2001,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.61273843"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.shape(x_test))\n",
    "t0=time.time()\n",
    "reconstructions = autoencoder.predict(x_test)\n",
    "\n",
    "x_test_reshaped = np.reshape(x_test, (x_test.shape[0],-1)) \n",
    "#print(np.shape(x_test_reshaped))\n",
    "\n",
    "reconstructions_reshaped = np.reshape(reconstructions, (reconstructions.shape[0],-1)) \n",
    "\n",
    "#test_loss = tf.keras.losses.mse(reconstructions_reshaped, x_test_reshaped)\n",
    "#or\n",
    "test_loss = K.mean(tf.keras.losses.mse(x_test, reconstructions),axis=-1)\n",
    "print(np.shape(test_loss))\n",
    "\n",
    "\n",
    "plt.hist(test_loss, bins=50)\n",
    "plt.xlabel(\"Test loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()\n",
    "#print( time.time() - t0)\n",
    "np.mean(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train1[13], seed_ent1[13], train_loss[13] # \"great work team\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test1[1000], texts[1104],test_loss[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "594"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_found=[]\n",
    "for i,kk in enumerate(test_loss):\n",
    "    if kk  <threshold:\n",
    "        ind_found.append(i)\n",
    "#    if kk>0.12:\n",
    "#        print(i)\n",
    "len(ind_found)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in ind_found:\n",
    "#    print(ent_all[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def predict(model, data, threshold):\n",
    "  reconstructions = model(data)\n",
    "  print(np.shape(reconstructions))\n",
    "  loss = tf.keras.losses.mae(reconstructions, data)\n",
    "  return tf.math.less(loss, threshold)\n",
    "\n",
    "preds = predict(model_autoencoder, test_data, threshold)\n",
    "preds\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pred = autoencoder.predict(x_normal_test)\n",
    "pred=np.reshape(pred, (pred.shape[0],-1)) \n",
    "x_normal_test=np.reshape(x_normal_test, (x_normal_test.shape[0],-1)) \n",
    "score1 = np.sqrt(metrics.mean_squared_error(pred,x_normal_test))\n",
    "\n",
    "pred = autoencoder.predict(x_train)\n",
    "pred=np.reshape(pred, (pred.shape[0],-1)) \n",
    "x_normal_test=np.reshape(x_normal_test, (x_normal_test.shape[0],-1)) \n",
    "score2 = np.sqrt(metrics.mean_squared_error(pred,x_train))\n",
    "\n",
    "pred = autoencoder.predict(x_abnormal_test)\n",
    "pred=np.reshape(pred, (pred.shape[0],-1)) \n",
    "x_abnormal_test=np.reshape(x_abnormal_test, (x_abnormal_test.shape[0],-1)) \n",
    "score3 = np.sqrt(metrics.mean_squared_error(pred,x_abnormal_test))\n",
    "\n",
    "print(f\"Out of Sample Normal error (RMSE): {score1}\")\n",
    "#print(f\"Insample Normal error (RMSE): {score2}\")\n",
    "print(f\"Abnormal error (RMSE): {score3}\")\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['make money marketing',\n",
       " 'top b2b strategies to market your business in',\n",
       " 'when they do not have the business they start doing business which is not their business .',\n",
       " 'great work team',\n",
       " 'rt great team doing important work .',\n",
       " 'the latest business and money by thanks to investment',\n",
       " 'no value in the market',\n",
       " 'the latest business and money by thanks to investment business',\n",
       " 'business success being there via by',\n",
       " 'which is more important sales or marketing']"
      ]
     },
     "execution_count": 1713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_ent[10:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 768)\n",
      "0.14576053619384766\n"
     ]
    }
   ],
   "source": [
    "x_test2=embedder0(['work team','work group','hated song hated song hated song hated song hated song','hated song',\n",
    "                   'pizza hotel',\n",
    "                  'woman amp child amp human trafficker euphemism evil sex traffic rapist amp pedophile . drug traffic plague ravage land . fresh flow caravan asylum seeker amp undetected illegals rag . dems wall .'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_test2 = (x_test2 - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 1, 768)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer CVAE: expected shape=(None, 25, 25), found shape=(None, 1, 768)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1716-ad83c8217c04>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mreconstructions2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx_test_reshaped2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2939\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m-> 2941\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[1;32m-> 3358\u001b[1;33m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[0;32m   3359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[1;32m-> 3280\u001b[1;33m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[0;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3282\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3206\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 990\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    991\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    992\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    633\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 634\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    635\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    975\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 977\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    978\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    979\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1434 predict_step\n        return self(x, training=False)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    C:\\Users\\jafar\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer CVAE: expected shape=(None, 25, 25), found shape=(None, 1, 768)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(x_test2))\n",
    "t0=time.time()\n",
    "reconstructions2 = autoencoder.predict(x_test2)\n",
    "\n",
    "x_test_reshaped2 = np.reshape(x_test2, (x_test2.shape[0],-1)) \n",
    "print(np.shape(x_test_reshaped2))\n",
    "\n",
    "reconstructions_reshaped2 = np.reshape(reconstructions2, (reconstructions2.shape[0],-1)) \n",
    "\n",
    "test_loss2 = tf.keras.losses.mse(reconstructions_reshaped2, x_test_reshaped2)\n",
    "#print(np.shape(test_loss))\n",
    "\n",
    "plt.hist(test_loss2, bins=50)\n",
    "plt.xlabel(\"Test loss\")\n",
    "plt.ylabel(\"No of examples\")\n",
    "plt.show()\n",
    "print( time.time() - t0)\n",
    "test_loss2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2001, 20)"
      ]
     },
     "execution_count": 1662,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(conv_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([autoencoder.get_layer('input_8').input], autoencoder.get_layer('dense_52').output) # index=23\n",
    "conv_output = func(x_test) \n",
    "#conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1868,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('sovereign people responsibility amp desire reliant derives human dignity . dignity canot derived gov cradle grave schemes amp dependence mere tribal identity . true identity creator',\n",
       " 'left amp blindly follow sublime ignorance road sex amp forms human trafficking drug smuggling amp form degradation erasing citizenship individual amp national sovereignty . road intentions amp road serfdom .')"
      ]
     },
     "execution_count": 1868,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[2000],texts[2835]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=conv_output[20] # for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=conv_output[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.024239"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a-conv_output[20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5708503127098083\n",
      "0.45175701379776\n",
      "0.35338667035102844\n",
      "0.20746617019176483\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(1 - cosine(conv_output[55], conv_output[2000]) )\n",
    "print(1 - cosine(conv_output[55], a))\n",
    "print(1 - cosine(conv_output[200], a ))\n",
    "print(1 - cosine(conv_output[2000], conv_output[835]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "func1 = K.function([autoencoder.get_layer('input_8').input], autoencoder.get_layer('dense_53').output) # index=23\n",
    "conv_output1 = func1(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=conv_output1[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.4961147"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a1-conv_output1[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5590571761131287\n",
      "0.5348398685455322\n",
      "0.2820291817188263\n",
      "0.12689349055290222\n"
     ]
    }
   ],
   "source": [
    "print(1 - cosine(conv_output1[55], conv_output1[2000]) )\n",
    "print(1 - cosine(conv_output1[55], a1))\n",
    "print(1 - cosine(conv_output1[200], a1))\n",
    "print(1 - cosine(conv_output1[2000], conv_output1[835]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "func2 = K.function([autoencoder.get_layer('input_8').input], autoencoder.get_layer('dense_54').output) # index=23\n",
    "conv_output2 = func2(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2=conv_output2[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.521377"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a2-conv_output2[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6495592594146729\n",
      "0.6184407472610474\n",
      "0.3839885890483856\n",
      "0.18407268822193146\n"
     ]
    }
   ],
   "source": [
    "print(1 - cosine(conv_output2[55], conv_output2[2000]) )\n",
    "print(1 - cosine(conv_output2[55], a2))\n",
    "print(1 - cosine(conv_output2[200], a2 ))\n",
    "print(1 - cosine(conv_output2[2000], conv_output2[835]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "func3 = K.function([autoencoder.get_layer('input_8').input], autoencoder.get_layer('dense_55').output) # index=23\n",
    "conv_output3 = func3(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "a3=conv_output3[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.9144344"
      ]
     },
     "execution_count": 491,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(a3-conv_output3[200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6601640582084656\n",
      "0.6673491597175598\n",
      "0.36744484305381775\n",
      "0.2436715066432953\n"
     ]
    }
   ],
   "source": [
    "print(1 - cosine(conv_output3[55], conv_output3[2000]) )\n",
    "print(1 - cosine(conv_output3[55], a3))\n",
    "print(1 - cosine(conv_output3[200], a3 ))\n",
    "print(1 - cosine(conv_output3[2000], conv_output3[835]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time market'"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_ent2[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.013736018>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.03094145>)"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss[200],train_loss[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.6894426345825195, 2.3884826)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "dst = distance.euclidean(conv_output[1], conv_output[4])\n",
    "dist = np.linalg.norm(conv_output[0]-conv_output[5])\n",
    "dst,dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 20, 768)\n",
      "0.06979703903198242\n"
     ]
    }
   ],
   "source": [
    "text1=['hat song','work team']\n",
    "a1=embedder2(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-334-d2e9e56e3c4d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mcosine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma1\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text1' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "print(text1[0][7],text1[1][8])\n",
    "print(1 - cosine(a1[0][0], a1[1][0]) )\n",
    "print(1 - cosine(a1[0][1], a1[1][1]) )\n",
    "print(1 - cosine(a1[0][2], a1[1][2]) )\n",
    "print(1 - cosine(a1[0][3], a1[1][3]) )\n",
    "print(1 - cosine(a1[0][4], a1[1][4]) )\n",
    "print(1 - cosine(a1[0][5], a1[1][18]) )\n",
    "print(1 - cosine(a1[0][19], a1[1][19]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1=['team work']\n",
    "a2=['hated song']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 20, 768)\n",
      "0.049430131912231445\n",
      "(1, 20, 768)\n",
      "0.036902427673339844\n",
      "(1, 20, 768)\n",
      "0.019643783569335938\n",
      "(1, 20, 768)\n",
      "0.05220937728881836\n",
      "(1, 20, 768)\n",
      "0.04548144340515137\n",
      "(1, 20, 768)\n",
      "0.021014690399169922\n"
     ]
    }
   ],
   "source": [
    "ans1=embedder(a1)\n",
    "ans2=embedder2(a1)\n",
    "ans0=embedder0(a1)\n",
    "bns1=embedder(a2)\n",
    "bns2=embedder2(a2)\n",
    "bns0=embedder0(a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(0, 3), dtype=int64)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argwhere(np.isnan(bns0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45770159363746643\n",
      "0.35634854435920715\n",
      "0.3105013072490692\n",
      "0.3177756667137146\n",
      "0.7120208740234375\n",
      "0.7404587268829346\n",
      "\n",
      "0.9911509156227112\n",
      "0.5502008199691772\n",
      "0.33191806077957153\n",
      "0.3362172842025757\n",
      "0.9181116819381714\n",
      "0.9677206873893738\n",
      "\n",
      "0.44497671723365784\n",
      "0.3434632420539856\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "print(1 - cosine(ans1[0][0], bns2[0][0]))\n",
    "print(1 - cosine(ans1[0][0], bns2[0][1]))\n",
    "print(1 - cosine(ans1[0][0], bns2[0][3]))\n",
    "print(1 - cosine(ans1[0][0], bns2[0][4]))\n",
    "print(1 - cosine(ans1[0][4], bns2[0][19]))\n",
    "print(1 - cosine(ans1[0][19], bns2[0][19]))\n",
    "print()\n",
    "print(1 - cosine(ans1[0][0], ans2[0][0]))\n",
    "print(1 - cosine(ans1[0][0], ans2[0][1]))\n",
    "print(1 - cosine(ans1[0][0], ans2[0][3]))\n",
    "print(1 - cosine(ans1[0][0], ans2[0][4]))\n",
    "print(1 - cosine(ans1[0][4], ans2[0][19]))\n",
    "print(1 - cosine(ans1[0][19], ans2[0][19]))\n",
    "print()\n",
    "print(1 - cosine(bns0[0][0], ans0[0][0]))\n",
    "print(1 - cosine(bns0[0][0], ans0[0][1]))\n",
    "print(1 - cosine(bns0[0][0], ans0[0][3]))\n",
    "print(1 - cosine(bns0[0][0], ans0[0][4]))\n",
    "print(1 - cosine(bns0[0][4], ans0[0][19]))\n",
    "print(1 - cosine(bns0[0][19], ans0[0][19]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<KerasTensor: shape=(None, 25, 25) dtype=float32 (created by layer 'input_8')>,\n",
       " <KerasTensor: shape=(None, 625) dtype=float32 (created by layer 'flatten_7')>,\n",
       " <KerasTensor: shape=(None, 450) dtype=float32 (created by layer 'dense_52')>,\n",
       " <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'dense_53')>,\n",
       " <KerasTensor: shape=(None, 50) dtype=float32 (created by layer 'dense_54')>,\n",
       " <KerasTensor: shape=(None, 14) dtype=float32 (created by layer 'dense_55')>,\n",
       " <KerasTensor: shape=(None, 50) dtype=float32 (created by layer 'dense_56')>,\n",
       " <KerasTensor: shape=(None, 150) dtype=float32 (created by layer 'dense_57')>,\n",
       " <KerasTensor: shape=(None, 450) dtype=float32 (created by layer 'dense_58')>,\n",
       " <KerasTensor: shape=(None, 625) dtype=float32 (created by layer 'dense_59')>,\n",
       " <KerasTensor: shape=(None, 25, 25) dtype=float32 (created by layer 'reshape_9')>,\n",
       " <KerasTensor: shape=(None, 25, 25) dtype=float32 (created by layer 'tf.convert_to_tensor_4')>,\n",
       " <KerasTensor: shape=(None, 25, 25) dtype=float32 (created by layer 'tf.cast_4')>,\n",
       " <KerasTensor: shape=(None, 25, 25) dtype=float32 (created by layer 'tf.math.squared_difference_4')>,\n",
       " <KerasTensor: shape=(None, 25) dtype=float32 (created by layer 'tf.math.reduce_mean_11')>,\n",
       " <KerasTensor: shape=(None,) dtype=float32 (created by layer 'tf.math.reduce_mean_12')>,\n",
       " <KerasTensor: shape=() dtype=float32 (created by layer 'tf.math.reduce_mean_13')>,\n",
       " <KerasTensor: shape=() dtype=float32 (created by layer 'add_loss_3')>]"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = [layer.output for layer in autoencoder.layers]          # all layer outputs\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 19, 1, 20)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([autoencoder.layers[0].input],\n",
    "                                  [autoencoder.layers[3].output])\n",
    "layer_output = get_3rd_layer_output([x_test2])[0]\n",
    "np.shape(layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "#autoencoder.layers[1].output.get_shape()\n",
    "#autoencoder.layers[1].output\n",
    "#autoencoder.layers[0]._name\n",
    "#conv_weights = autoencoder.get_layer('conv2d_31').get_weights()  # numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new model\n",
    "layer_output=autoencoder.get_layer(index=3).output   #layer_output=model.get_layer(layer_name).output\n",
    "intermediate_model=tf.keras.models.Model(inputs=autoencoder.input,outputs=layer_output)\n",
    "intermediate_prediction=intermediate_model.predict(x_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.7650081e-01,  2.8579620e-01,  6.9967991e-01, -6.2938428e-01,\n",
       "         8.6302567e-01, -1.2203450e+00, -1.3634030e+00, -9.9799627e-01,\n",
       "         8.9768344e-01,  2.2071769e+00],\n",
       "       [-1.0538758e+00, -7.2922969e-01,  4.2215452e-02,  2.8998899e-01,\n",
       "        -1.6720887e+00, -1.1855352e+00, -9.4671112e-01,  1.0533788e+00,\n",
       "         1.8272312e-01,  4.5969564e-01],\n",
       "       [-1.7218441e+00,  1.8279363e-01, -1.3969603e+00, -1.4551117e-03,\n",
       "         1.1530080e+00, -6.0003912e-01,  1.3282999e+00,  2.5271830e-01,\n",
       "        -3.0976474e-01, -1.4425912e+00],\n",
       "       [-3.4123026e-02, -2.9204721e+00, -1.3632357e-01,  2.5320413e+00,\n",
       "         9.6690679e-01,  8.8957262e-01, -6.7900223e-01,  1.3935624e+00,\n",
       "        -1.2844133e-01, -1.3498430e-01]], dtype=float32)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = K.function([autoencoder.get_layer('input_6').input], autoencoder.get_layer('sampling_5').output)\n",
    "conv_output = func([x_test2]) \n",
    "conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To print the output of a single layer:\n",
    "from tensorflow.keras import backend as K\n",
    "layerIndex = 1\n",
    "func = K.function([autoencoder.get_layer(index=0).input], autoencoder.get_layer(index=layerIndex).output)\n",
    "layerOutput = func([x_test2])  # input_data is a numpy array\n",
    "#print(layerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To print output of every layer:\n",
    "from tensorflow.keras import backend as K\n",
    "for layerIndex, layer in enumerate(autoencoder.layers):\n",
    "    func = K.function([autoencoder.get_layer(index=0).input], layer.output)\n",
    "    layerOutput = func([x_test2])  # input_data is a numpy array\n",
    "#    print(layerOutput)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
