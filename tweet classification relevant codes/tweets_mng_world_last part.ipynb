{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas\n",
    "import csv\n",
    "import re #regular expression\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "##nltk.download('stopwords')# Download stopwords\n",
    "import textblob\n",
    "from textblob import TextBlob\n",
    "import sys\n",
    "import psycopg2\n",
    "import time\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'x'\n",
    "consumer_secret = 'x'\n",
    "access_token = 'x'\n",
    "access_secret = 'x'\n",
    "access_token_secret=access_secret\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "##print(x.translate(non_bmp_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('managers_world_names.csv', sep=';', na_values=\"(missing)\")\n",
    "df.shape[0]\n",
    "names=[]\n",
    "for jj in range(df.shape[0]):\n",
    "    names.append(df['names'][jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(tweet):\n",
    "    ##Handle Emoticons and Emojis\n",
    "    #HappyEmoticons\n",
    "    emoticons_happy = set([\n",
    "        ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "        ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "        '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "        'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "        '<3'\n",
    "        ])\n",
    "    \n",
    "    #Sad Emoticons\n",
    "    emoticons_sad = set([\n",
    "        ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "        ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "        ':c', ':{', '>:\\\\', ';('\n",
    "        ])\n",
    "    \n",
    "    ##Emoji patterns\n",
    "    #combine sad and happy emoticons\n",
    "    emoticons = emoticons_happy.union(emoticons_sad)\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "             u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "             u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "             u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "             u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "             u\"\\U00002702-\\U000027B0\"\n",
    "             u\"\\U000024C2-\\U0001F251\"\n",
    "             \"]+\", flags=re.UNICODE)\n",
    "\n",
    "##    extract_link\n",
    "##    regex = r' https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+ '\n",
    "##    match = re.search(regex, tweet.full_text)\n",
    "##    if match:\n",
    "##        print(\"links: \", match)\n",
    "\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet1 = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', tweet)\n",
    "##    print(\"a1             \",tweet1)\n",
    "\n",
    "    #remove emojis from tweet\n",
    "    tweet2 = emoji_pattern.sub(r'', tweet1)   \n",
    "##    print(\"a2             \",tweet2)\n",
    "\n",
    "    #utility function to clean tweet text by removing links, special characters using simple regex statements. \n",
    "    tweet3=re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z_ \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet2) \n",
    "##    print(\"a3             \",tweet3)\n",
    "\n",
    "    #removing numbers\n",
    "    tweet4= re.sub(\" (\\d+) | (\\d+)(.)(\\d+) \", ' ',tweet3) # number alone\n",
    "    tweet5= re.sub(\"(\\d+)\", ' ',tweet4) # number attached\n",
    "##    print(\"a4             \",tweet5)\n",
    "\n",
    "    # removing some charachters \n",
    "####    tweet6= re.sub(\".\", ' ',tweet4) # !!!! remove all\n",
    "    tweet6= re.sub(\"[\\\";:\\|,~!=\\-+#$%&*\\(\\)?\\.\\/]+\", ' ',tweet5)\n",
    "##    print(\"a5             \",tweet6)\n",
    "   \n",
    "    # Create a sublist of lower case words for each tweet\n",
    "    words_in_tweet = tweet6.lower().split()\n",
    "##    print(\"a5    \",words_in_tweet)\n",
    "\n",
    "#    stop_words = set(stopwords.words('english'))\n",
    "#    tweet_cleaned=''\n",
    "#    for word in words_in_tweet:\n",
    "#        if word not in stop_words:\n",
    "#            tweet_cleaned +=' '+ word     \n",
    "    tweet_cleaned = [word for word in words_in_tweet if word not in cachedStopWords]\n",
    "    tweet_cleaned=' '.join(tweet_cleaned)  \n",
    "\n",
    "##    print(\"a6    \",tweets_cleaned)\n",
    "\n",
    "    return tweet_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncsvFile_Loc = open(\\'manager_tweets10.csv\\', \\'w\\',newline=\\'\\')\\ncsvWriter = csv.writer(csvFile_Loc,delimiter=\\';\\', quotechar=\\'\"\\', quoting=csv.QUOTE_MINIMAL)\\ncsvWriter.writerow([\"screen_name\",\\n                    \"user_name\",\\n                    \"user_id\",\\n                    \"tweet\",\\n                    \"cleaned_tweet\",\\n                    \"lang\",\\n                    \"tweet_created_at\",\\n                    \"location_profile\",\\n                    \"description_profile\",\\n                    \"all_tweet\"])\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "csvFile_Loc = open('manager_tweets10.csv', 'w',newline='')\n",
    "csvWriter = csv.writer(csvFile_Loc,delimiter=';', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "csvWriter.writerow([\"screen_name\",\n",
    "                    \"user_name\",\n",
    "                    \"user_id\",\n",
    "                    \"tweet\",\n",
    "                    \"cleaned_tweet\",\n",
    "                    \"lang\",\n",
    "                    \"tweet_created_at\",\n",
    "                    \"location_profile\",\n",
    "                    \"description_profile\",\n",
    "                    \"all_tweet\"])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\na=(5,1)\\nn=np.zeros(a)\\nj=0\\nnames=['BillGates','richardbranson','Louis_Tomlinson','TheEllenShow','realDonaldTrump']\\nfor i in range(5):\\n    n[i]=0\\n    for tweet in tweepy.Cursor(api.user_timeline,screen_name=names[i]).items():\\n        n[i] +=1\\n        j +=1\\n        #print (tweet)\\n        print(j)\\n\\nwith open('manager_tweets1.json', 'w') as f:  # writing JSON object\\n    json.dump(1, f)\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for tweet in tweepy.Cursor(api.user_timeline,user_name='MansouriJafar').items():\n",
    "    print (tweet)\n",
    "'''\n",
    "\n",
    "'''\n",
    "n=0\n",
    "for tweet in tweepy.Cursor(api.user_timeline,id='USATODAY',since=\"2019-11-19\",\n",
    "                   until=\"2019-11-20\").items():\n",
    "    n +=1\n",
    "    #print (tweet)\n",
    "'''\n",
    "\n",
    "'''\n",
    "a=(5,1)\n",
    "n=np.zeros(a)\n",
    "j=0\n",
    "names=['BillGates','richardbranson','Louis_Tomlinson','TheEllenShow','realDonaldTrump']\n",
    "for i in range(5):\n",
    "    n[i]=0\n",
    "    for tweet in tweepy.Cursor(api.user_timeline,screen_name=names[i]).items():\n",
    "        n[i] +=1\n",
    "        j +=1\n",
    "        #print (tweet)\n",
    "        print(j)\n",
    "\n",
    "with open('manager_tweets1.json', 'w') as f:  # writing JSON object\n",
    "    json.dump(1, f)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names=['BillGates','richardbranson','Louis_Tomlinson','TheEllenShow','realDonaldTrump','melindagates']\n",
    "n=np.zeros(len(names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3201.0\n",
      "3180.0\n",
      "3048.0\n",
      "artificial break\n",
      "3235.0\n",
      "3226.0\n",
      "3006.0\n",
      "3216.0\n",
      "artificial break\n",
      "3202.0\n",
      "An exception occurred\n",
      "27793\n",
      "0.0\n",
      "2956.0\n",
      "3154.0\n",
      "artificial break\n",
      "3204.0\n",
      "443.0\n",
      "3189.0\n",
      "3202.0\n",
      "artificial break\n",
      "3030.0\n",
      "3176.0\n",
      "1395.0\n",
      "3221.0\n",
      "artificial break\n",
      "73.0\n",
      "3229.0\n",
      "3221.0\n",
      "556.0\n",
      "artificial break\n",
      "2764.0\n",
      "3222.0\n",
      "3221.0\n",
      "3188.0\n",
      "artificial break\n",
      "800.0\n",
      "3210.0\n",
      "1340.0\n",
      "3183.0\n",
      "artificial break\n",
      "An exception occurred\n",
      "27816\n",
      "0.0\n",
      "3210.0\n",
      "3224.0\n",
      "2966.0\n",
      "artificial break\n",
      "59.0\n",
      "109.0\n",
      "An exception occurred\n",
      "27822\n",
      "0.0\n",
      "10.0\n",
      "artificial break\n",
      "3222.0\n",
      "576.0\n",
      "3243.0\n",
      "3226.0\n",
      "artificial break\n",
      "561.0\n",
      "3190.0\n",
      "3223.0\n",
      "395.0\n",
      "artificial break\n",
      "3190.0\n",
      "1420.0\n",
      "1.0\n",
      "3234.0\n",
      "artificial break\n",
      "118.0\n",
      "988.0\n",
      "3216.0\n",
      "3214.0\n",
      "artificial break\n",
      "An exception occurred\n",
      "27840\n",
      "0.0\n",
      "2692.0\n",
      "1267.0\n",
      "3010.0\n",
      "artificial break\n",
      "An exception occurred\n",
      "27844\n",
      "0.0\n",
      "3211.0\n",
      "3168.0\n",
      "An exception occurred\n",
      "27847\n",
      "0.0\n",
      "artificial break\n",
      "980.0\n",
      "3224.0\n",
      "3218.0\n",
      "3158.0\n",
      "artificial break\n",
      "An exception occurred\n",
      "27852\n",
      "0.0\n",
      "1405.0\n",
      "3160.0\n",
      "An exception occurred\n",
      "27855\n",
      "0.0\n",
      "artificial break\n",
      "845.0\n",
      "3163.0\n",
      "23.0\n",
      "An exception occurred\n",
      "27859\n",
      "0.0\n",
      "artificial break\n",
      "3180.0\n",
      "3094.0\n",
      "2865.0\n",
      "1056.0\n",
      "artificial break\n",
      "3231.0\n",
      "38.0\n",
      "3175.0\n",
      "3207.0\n",
      "artificial break\n",
      "500.0\n",
      "338.0\n",
      "553.0\n",
      "1262.0\n",
      "artificial break\n",
      "3209.0\n",
      "3195.0\n",
      "3105.0\n",
      "An exception occurred\n",
      "27875\n",
      "0.0\n",
      "artificial break\n",
      "660.0\n",
      "3234.0\n",
      "1676.0\n"
     ]
    }
   ],
   "source": [
    "     \n",
    "for i in range(27785,len(names)):\n",
    "    \n",
    "    consumer_key = '1QRIUdf4Sx4xdMDc46nQ6vYZ3'\n",
    "    consumer_secret = '5tEVf8mm8dUjYftXiae9QERBDFiKXrVSWkjRm2jpfBNy0NRm1Q'\n",
    "    access_token = '1191719379186192384-Gn0pBMspYGX2BCQxqyZACjNtAQ67YL'\n",
    "    access_secret = 'WuVwxRsXdw9gtTK1OTWK7McCtAC7l8Y0BSfYEUhcYEWv0'\n",
    "    access_token_secret=access_secret\n",
    "\n",
    "    auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "    \n",
    "    try:\n",
    "        for tweet in tweepy.Cursor(api.user_timeline,screen_name=names[i],tweet_mode=\"extended\" ,lang=\"en\").items():\n",
    "         #   print (tweet)\n",
    "            n[i] +=1\n",
    "            \n",
    "#            data= [tweet.user.screen_name.translate(non_bmp_map),\n",
    "#                   tweet.user.name.translate(non_bmp_map),\n",
    "#                   tweet.user.id,\n",
    "#                   tweet.full_text.translate(non_bmp_map),\n",
    "#                   cleaning(tweet.full_text),\n",
    "#                   tweet.lang,\n",
    "#                   tweet.created_at,\n",
    "#                   tweet.user.location.translate(non_bmp_map),\n",
    "#                   tweet.user.description,\n",
    "#                   tweet._json]\n",
    "#            csvFile_Loc = open('manager_tweets8.csv', 'a',encoding=\"utf-8\",newline='')\n",
    "#           csvWriter = csv.writer(csvFile_Loc, delimiter=';' , quotechar='\"',  quoting=csv.QUOTE_MINIMAL)\n",
    "#            csvWriter.writerow(data)\n",
    "\n",
    "\n",
    "            data1= [tweet.user.screen_name.translate(non_bmp_map),\n",
    "                   tweet.user.name.translate(non_bmp_map),\n",
    "                   tweet.user.id,\n",
    "                   tweet.full_text.translate(non_bmp_map),\n",
    "                   cleaning(tweet.full_text),\n",
    "                   tweet.lang,\n",
    "                   tweet.created_at,\n",
    "                   tweet.user.location.translate(non_bmp_map),\n",
    "                   tweet.user.description,\n",
    "                   str(tweet._json)]\n",
    "\n",
    "            conn = psycopg2.connect(\"host=localhost dbname=postgres user=postgres password=Jafarsql\")\n",
    "            cur = conn.cursor()\n",
    "            cur.execute(\"INSERT INTO manager_world_tweets24_ph2 VALUES ( %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\",data1);\n",
    "            conn.commit()\n",
    "            \n",
    "\n",
    "#            with open('manager_tweets8.json', 'a') as f:  # writing JSON object\n",
    "#                json.dump(tweet._json, f)\n",
    "                \n",
    "    except:\n",
    "        print(\"An exception occurred\")\n",
    "        print(i)\n",
    "        \n",
    "    print(n[i])    \n",
    "    if i%4 == 3: \n",
    "        print('artificial break')\n",
    "        time.sleep(60*1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
