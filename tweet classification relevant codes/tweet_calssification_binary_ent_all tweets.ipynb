{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "### export PYTHONIOENCODING=utf-8  # at cmd of linux\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "import html\n",
    "import xml.sax.saxutils as saxutils\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel,DistilBertTokenizer\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "Stem=stemmer.stem\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemm=wordnet_lemmatizer.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_bert = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )  \n",
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(cachedStopWords))\n",
    "#print(len(cachedStopWords))\n",
    "#print(type(cachedStopWords))\n",
    "\n",
    "nltk_stopwords=set(cachedStopWords)\n",
    "\n",
    "english_alghabet=['b','c','e','f','g','h','j','k','l','n','p','q','r','u','v','w','x','z']\n",
    "\n",
    "numbers_remove=['one','two','three','four','five','six','seven','eight','nine','ten','tens','twenty',\n",
    "                'fourty','fifty','sixty','seventy','eighty','ninety','hundred','hundreds','million','billion','trillion',\n",
    "                'millions','thousand','thousands','second','third','forth','tenth','billions','trillions'] \n",
    "\n",
    "miscellaneous_remove=['absolutely', 'actually', 'adieu', 'ain', \"ain't\", 'aint', 'almost',\n",
    "                       'awesome','awfully','amazing','interesting',\n",
    "                       'alright','alrighty', 'amoungst', 'anybody', 'anymore', 'anyways', 'apart', 'apparently', 'anytime',\n",
    "                       'appropriate',  'approximately', 'arent', 'behold', 'better', 'bravo','briefly','bad','best','brilliant',\n",
    "                       'bye', 'cant', 'certainly', 'chrissakes', 'clearly', 'completely',\n",
    "                       'congrat', 'congrats','congratulation', 'congratulations', 'consequently', 'cool', 'couldnt',\n",
    "                       'darnit', 'de','dear', 'definitely','disappointing', 'didn', 'doesn', 'don', 'downwards',\n",
    "                       'disgusting','dude','down','eg',\"e.g.\",'i.e.',\n",
    "                       'encore','entirely', 'especially', 'et', 'etc', 'everybody', 'ex', 'exactly', 'excellent',\n",
    "                       'fantastic','far', 'farewell','funny',\n",
    "                       'felicitation', 'felicitations','finally', 'fully','furthermore', 'gadzooks', \n",
    "                       'good', 'goodby','goodness', 'gracious', 'great', \n",
    "                       'greetings', 'hallo', 'hardly', 'hasnt', 'haven', 'hello', 'here','hi', 'hither','higher','hopefully',\n",
    "                       'here','there','including',\n",
    "                       'howbeit', 'ie', 'immediately', 'inasmuch', 'inner', 'insofar', 'instead', 'inward', 'important',\n",
    "                       'indeed','just', \"it'd\", \"it'll\", 'inside','kertyschoo', 'kg', 'km', 'lackaday', \n",
    "                       'largely', 'lately', 'later','lovely','large','big','small',\n",
    "                       'lest', 'let', 'lets', 'likely', 'little', 'ltd', 'lower','magnificent', 'mainly', 'marvelous',\n",
    "                       'myself','yourself','yourselves','himself','herself','hisself','ourselves','themsleves',\n",
    "                       'maybe', 'meantime', 'merely', 'minus', 'near', 'nearly', 'necessary', 'never', \n",
    "                       'non', 'normally', 'obviously', 'ok', 'okay', 'ones', 'outside', 'over','other','others','only',\n",
    "                       'overall', 'particular', 'particularly', 'please', 'plus', 'poorly', 'possible','up',\n",
    "                       'possibly', 'potentially', 'predominantly', 'presumably', 'previously','primarily', 'probably',\n",
    "                       'promising',\n",
    "                       'promptly', 'readily', 'really', 'reasonably', 'recent', 'recently', 'ref',\n",
    "                       'refs', 'regardless', 'related', 'relatively', 'respectively', 'resulting', 'right', 'sec', \n",
    "                       'secondly','self', 'selves', 'seriously', 'shall', 'shucks','somebody', 'somethan','sorry',\n",
    "                       'somewhat', 'soon', 'late' , 'sorry', 'stupid', 'sub', 'substantially', 'successfully', 'sufficiently',\n",
    "                       'useful',\n",
    "                       'super', 'sure', \"t's\", 'th', 'thank', 'thanks', 'thanx', \"that've\", 'thats', 'there', \"there'll\",\n",
    "                       \"there've\", 'thered', 'thereof', 'therere', 'theres', 'thereto', 'theyd', 'theyre', 'thorough',\n",
    "                       'then','thankfully','too','today','yesterday','tomorrow','night',\"morning\",'afternoon','noon','tonight',\n",
    "                       'evening','day','everyday', 'everynight','todays','nights','mornings','noons','afternoons','days',\n",
    "                       'evenings','week','month','year',\n",
    "                       'thoroughly', 'tnx', 'too','truly', 'twice', 'undoubtedly','unfortunately', 'unlike','unlikely',\n",
    "                       'unto',  'usually', 'vs', 'welcome', 'well', 'went', 'werent', 'what', 'whatever', 'wheres', 'widely',\n",
    "                       'wonderful', 'wont', 'wouldnt', 'wrong', 'worst','worse','www', 'yes', 'youd', 'youre', 'yummy', \n",
    "                       'zoinks','shit','literally','literal','pleasure','effective','fabulous','delighted',\n",
    "                       'saturday','sunday','monday','tuesday','wednesday','thursday', 'friday','past','future','suitable',\n",
    "                       'much','many','less','least','few','lots','lot','fewer','fewset','therefore','pm',\n",
    "                       'afaik', 'br', 'idk','smh','qotd', 'ftw','bfn','yw', 'icymi','fomo','smdh', 'b4','imho',\n",
    "                       'urdddd','fab' ,'delightful','absolute','pleasure','huge','latest','nowadays',\n",
    "                       'january','february','april','june','july','august','september','october',\n",
    "                       'november','december', 'autumn' ,'spring','winter','summer',\n",
    "                       'mr','madam','sir','mrs','easy', 'difficult',\n",
    "                       'weekend','south','north','west','east','asia','africa','europe','america','totally',\n",
    "                       'come', 'comes', 'coming', 'came', 'seems', 'gives', 'gave', 'makes', 'made', 'keeps', 'kept', \n",
    "                       'calls', 'called', 'says', 'saying', 'said', 'goes', 'went', 'gone', 'got', 'saw', 'seen', 'shows',\n",
    "                       'shown', 'took', 'taken', 'uses', 'moved', 'moves', 'puts',\n",
    "                       'using','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "                       'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use',\n",
    "                       'find', 'finds', 'finding','aka',\n",
    "                       'lol' , 'brb', 'lmk', 'ama', 'tbh', 'irl', \"tl;dr\", 'fml', 'bfn' ,' br', 'ht', \"hth\",'j/k', 'lmao' ] #cool\n",
    "\n",
    "interjection_remove=['aaaahh', 'aaah', 'aaargh', 'aaay', 'aagh', 'aah',\n",
    "                   'aargh', 'achoo', 'adios', 'ah', 'aha', 'ahem', 'ahh', 'ahhh',\n",
    "                   'ahoy', 'alas', 'allo', 'amen', 'areet', 'argh', 'arrggh',\n",
    "                   'arrividerci', 'asap', 'attaboy', 'avaunt', 'aw', 'aw', 'aww',\n",
    "                   'awww', 'ay', 'ay', 'aye', 'ayeaugh', 'bada', 'badum', 'bah',\n",
    "                   'bahaha', 'bam', 'bazinga', 'behold', 'bingce', 'bingo', 'blah',\n",
    "                   'blech', 'bleh', 'blimey', 'bonjour', 'boo', 'booh', 'boohoo',\n",
    "                   'booyah', 'bravo', 'brr', 'brrrr', 'btw', 'bwahaha', 'capeesh',\n",
    "                   'capisce', 'cheerio', 'cheers', 'ciao', 'cor', 'cowabunga',\n",
    "                   'crikey', 'cripes', 'da', 'dabba', 'dah', 'dammit', 'damn', 'dang',\n",
    "                   'darn', 'de', 'dee', 'di', 'dizamn', 'doh', 'doo', 'drat', 'duh',\n",
    "                   'dum', 'eeeek', 'eek', 'eep', 'egad', 'egads', 'eh', 'ehem', 'em',\n",
    "                   'er', 'eureka', 'eww', 'ewww', 'eyh', 'fiddledeedee', 'fie',\n",
    "                   'fore', 'foul', 'fuff', 'gah', 'gak', 'gee', 'geez', 'gesundheit',\n",
    "                   'giddyap', 'golly', 'gosh', 'grr', 'grrrr', 'ha', 'hah', 'haha',\n",
    "                   'hahaha', 'hallelujah', 'halloa', 'harrumph', 'harumph', 'haw',\n",
    "                   'heck', 'heck', 'heeey', 'heh', 'hehe', 'hey', 'hhh', 'hic', 'hm',\n",
    "                   'hmm', 'hmmm', 'hmmmm', 'hmmph', 'hmpf', 'ho', 'hola', 'hoo',\n",
    "                   'hooray', 'howdy', 'hrmm', 'hrmph', 'hrmph', 'hrrmph', 'hu', 'huh',\n",
    "                   'hullo', 'humph', 'hurrah', 'huzza', 'huzzah', 'ich', 'ick',\n",
    "                   'ixnay', 'jeepers', 'jeez', 'kaboom', 'kapow', 'kerwham', 'la',\n",
    "                   'lala', 'lo', 'lordy', 'meh', 'mhm', 'ml', 'mm', 'mmh', 'mmhm',\n",
    "                   'mmm', 'muahaha', 'mwah', 'mwahaha', 'na','nay','nah', 'nanu', 'nooo', 'nope',\n",
    "                   'nuh', 'oh', 'ohh', 'oho', 'oi', 'okeydoke', 'om', 'oof', 'ooh',\n",
    "                   'oomph', 'oooh', 'ooooh', 'oops', 'ouch', 'ow', 'oww', 'oy',\n",
    "                   'oyez', 'oyh', 'pew', 'pff', 'pffh', 'pfft', 'phew', 'phut',\n",
    "                   'phweep', 'phwoar', 'phwoarr', 'poof', 'poogh', 'prethee',\n",
    "                   'prithee', 'prosit', 'pssh', 'psst', 'queep', 'roger', 'salaam',\n",
    "                   'salam', 'sheesh', 'shh', 'shhh', 'shitfire', 'shoo', 'shoop',\n",
    "                   'shush', 'sigh', 'sssh', 'strewth', 'ta', 'tarnations', 'tchah',\n",
    "                   'teehee', 'tish', 'touché', 'tsk', 'tss', 'tut', 'uggh', 'ugh',\n",
    "                   'uh', 'uhh', 'uhm', 'um', 'umm', 'ummm', 'umph', 'unh', 'upadaisy',\n",
    "                   'upsadaisy', 'ur', 'urgh', 'vay', 'vayf', 'viva', 'voila', 'waa',\n",
    "                   'waaaaah', 'waah', 'wah', 'wahey', 'wassup', 'weee', 'welp',\n",
    "                   'wham', 'whamo', 'whee', 'whew', 'whizz', 'whoa',\n",
    "                   'whoo', 'whoopee','whoop', 'whoops', 'whoopsy', 'whoosh', 'woah', 'woo',\n",
    "                   'woohoo', 'wotcha', 'wotcher', 'wow', 'wowsers', 'wowsers',\n",
    "                   'wuzzup', 'wuzzup', 'wuzzup', 'ya', 'yabba', 'yada', 'yadda',\n",
    "                   'yak', 'yarooh', 'yay', 'yea', 'yeah', 'yech', 'yee', 'yeeeeaah',\n",
    "                   'yeehaw', 'yeow', 'yes', 'yessiree', 'yew', 'yikes', 'yippee',\n",
    "                   'yo', 'yoo', 'yoohoo', 'yow', 'yowza', 'yuck', 'yuh', 'zing',\n",
    "                   'zoiks', 'zomfg', 'zomg', 'zounds', 'zut']\n",
    "             \n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "type(spacy_stopwords)\n",
    "#spacy_exclude=['using','name','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "#               'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use']# serious\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "stop_words1 = get_stop_words('english')\n",
    "#print(type(stop_words1))\n",
    "#print()\n",
    "#print(stop_words1)\n",
    "lib_stopwords=set(stop_words1)\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "#print(type(ENGLISH_STOP_WORDS))\n",
    "#print()\n",
    "#print(set(ENGLISH_STOP_WORDS))\n",
    "#sklearn_exclude=['find','get','found','go','see','seem','seems','give','seemed','take','keep','show','put','made'] # system  cry\n",
    "sklearn_stopwords=set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "#spacy_stopwords.difference_update(set(spacy_exclude))\n",
    "#sklearn_stopwords.difference_update(set(sklearn_stopwords))\n",
    "#for removing \"just\" one item, use \"remove\"\n",
    "temp_1=set([])\n",
    "#temp_1.update(nltk_stopwords)\n",
    "#temp_1.update(lib_stopwords)\n",
    "#temp_1.update(sklearn_stopwords)\n",
    "#temp_1.update(spacy_stopwords)\n",
    "#temp_1.update(set(english_alghabet))\n",
    "#temp_1.update(set(numbers_remove)) \n",
    "#temp_1.update(set(miscellaneous_remove))\n",
    "#temp_1.update(set(interjection_remove))\n",
    "#temp_1.update(['rt','be','will','was','were','is','am','are','have','has','had','do','does','done'])\n",
    "#temp_1.update(['rt'])\n",
    "cachedStopWords=temp_1\n",
    "#len(cachedStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "#print(lemmatizer.lemmatize(\"I am loving it\")) #I am loving it\n",
    "#print(lemmatizer.lemmatize(\"loving\")) #loving\n",
    "#print(lemmatizer.lemmatize(\"loving\", \"v\")) #love\n",
    "#print(lemmatize_sentence(\"I am loving it\")) #I be love it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "    \n",
    "    #order of lines is important\n",
    "    \n",
    "    text=strip_tags(text)\n",
    "    #text=html.unescape(text)   # stripping or converting html entities \n",
    "    #text=saxutils.unescape(text) \n",
    "    \n",
    "    #convertings words that their lower and uper cases are different\n",
    "    text=re.sub(\" US | U\\.S\\. \", ' USA ', text) # before lower\n",
    "    \n",
    "    #converting\n",
    "    text = re.sub(\"“|”\", ''' \" ''', text)  #before next lines\n",
    "    text = re.sub(\"’|′|‘|`\", \" ' \", text)  #before next lines\n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', ' ', text)\n",
    "    \n",
    "    #converting lower_case\n",
    "    text = text.lower() \n",
    "    \n",
    "    #converting\n",
    "#    text=re.sub('\\$|£|€|¥|dollar|dollars|yen|yens|euros', ' money ', text)   # not euro \n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text) \n",
    "\n",
    "    #removing emojis and non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', text)  \n",
    "\n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "\n",
    "    '''\n",
    "    #removing common expressions\n",
    "    text=re.sub(\"looking forward to|look forward to|make sure|kidding me|\\\n",
    "                |in my opinion|by the way,|as soon as possible|shaking my head|i don't know|I do not know|\\\n",
    "                |in real life|quote of the day|as far as i know|shake my head|\\\n",
    "                |to be honest|in other words|let me know|just kidding|hope that helps|hat tip|\\\n",
    "                |just like that|happy birthday|never mind|well-done|\\\n",
    "                |in my humble opinion|happy new year|you're welcome|you are welcome| \\\n",
    "                |it doesn't matter|it does not matter|i think|i wonder|do you think\", ' ', text)  \n",
    "    '''\n",
    "    \n",
    "    #convertings\n",
    "    text=re.sub(\"can't\", 'cannot', text) # before other n't \n",
    "    text=re.sub(\"can not \", 'cannot ', text)  \n",
    "    text=re.sub(\"'ve\",' have', text)\n",
    "    text=re.sub(\"n't\",' not', text)\n",
    "    text=re.sub(\"'ll\",' will', text)\n",
    "#    text=re.sub(\"'d\",' would', text)\n",
    "    text=re.sub(\"'re\",' are', text)\n",
    "    text=re.sub(\"i'm\",'i am', text)\n",
    "    text=re.sub(\"&\",' and ', text)\n",
    "    text=re.sub(\" w/ \",' with ', text)\n",
    "    text=re.sub(\" w/i | w/in \",' within ', text)\n",
    "    text=re.sub(\" w/o \",' without ', text)\n",
    "    text=re.sub(\" c/o \",' care of ', text)\n",
    "    text=re.sub(\" h/t \",' hat tip ', text)\n",
    "    text=re.sub(\" b/c \",' because ', text)\n",
    "#    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"=\",' = ', text)\n",
    "#    text=re.sub(\"\\+\",' plus ', text)\n",
    "    text=re.sub(\"\\+\",' + ', text)\n",
    "    text=re.sub(\"united states\",'usa', text)\n",
    "    text=re.sub(\"united kingdom\",'uk', text)\n",
    "    text=re.sub(\" the us \",' usa ', text)\n",
    "    text=re.sub(\"start-up|start_up\",'startup', text)\n",
    "    text=re.sub(\"u\\.s\\.a\", 'usa', text)  #try text=re.sub(\"u.s.a\", 'usa', text) with text=substantially \n",
    "    #text=re.sub(\"aka\", 'also known as', text)     \n",
    "    text=re.sub(\"'\",\" ' \", text)     \n",
    "    \n",
    "    text= re.sub(\"(\\?)+\", '? ',text)     \n",
    "    text= re.sub(\"(!)+\", '! ',text)     \n",
    "    text= re.sub(\"(\\.\\.)+\", ' ',text)   \n",
    "\n",
    "#    text = \"\".join(lemmatize_sentence(text))\n",
    "    \n",
    "    #removing some special charachter  \n",
    "#    text= re.sub(\"[\\\"\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]``<>\\.{}`′’‘'_;•«»,@:~!\\=%&]+\", ' ',text) \n",
    "#    text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`′’‘';•«,@:~!\\=%&]+\", ' ',text) \n",
    "    \n",
    "    #removing hashtag\n",
    "#    text=re.sub('#', ' ', text) \n",
    "    \n",
    "    #removing numbers not attached to alphabets\n",
    "    '''\n",
    "    text=re.sub(\"(^)(\\d+)?(\\.)?(\\d+)? \",' ',text)   #removing numer at the beginning\n",
    "    text=re.sub(\"(\\s)[0-9]?(\\.)?(\\d+) \",' ',text) #py6 and py9\n",
    "    text= re.sub(\" (\\.)(\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+)$\", ' ',text)\n",
    "    '''\n",
    "    #text=re.sub(\"\\S+(\\d+) \",' ',text) # alphabet+digit (attached)\n",
    "    #text=re.sub(\" (\\d+)\\S+\",' ',text) # digit+alphabet (attached)\n",
    "    #text=re.sub(\" \\S+(\\d+)\\S+ \",' ',text) # alphabet+digit+alphabet (attached)\n",
    "    #text=re.sub(\"(\\d+)\",' ',text)  #removing any number anywhere but keeps \\. for decimal numbers\n",
    "\n",
    "    #removing space\n",
    "    text=re.sub('\\s+',' ',text)    \n",
    "    \n",
    "    text=re.sub('(^)rt ','',text)    # if we do not want to remove stopwords\n",
    "\n",
    "#    text= nltk.word_tokenize(text) # necessary for removing stopwords\n",
    "    #text= text.split() #sometimes\n",
    "\n",
    "    #removing_stopwords \n",
    "    #text_without_sw = [word.lower() for word in text if word.lower() not in stopwords.words()] #very slow\n",
    "#    text = [word for word in text if word not in cachedStopWords]\n",
    "\n",
    "    #lemmatization\n",
    "    #text= [ lemm(word, pos=\"v\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"n\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"a\") for word in text]\n",
    "    \n",
    "    #stemming \n",
    "    #text = [Stem(word) for word in text]\n",
    "    \n",
    "#    text=' '.join(text)\n",
    "#    text=re.sub(\"''\",'''\"''', text)    #since nltk.tokenize converts second \" to ''\"\n",
    "#    text=re.sub(\"``\",'''\"''', text)   # since nltk.tokenize converts first \" to \" ``\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep(text):\n",
    "    text=text.translate(str.maketrans({'&': ' & ', '#': ' # ' , '\\\"':' \" ', '\\+': ' + ', '\\-': ' - ',\n",
    "                                       '\\|': ' | ', '\\*': ' * ', '\\?': ' ? ', '\\(':' ( ', '\\)':' ) ',\n",
    "                                       '\\/': ' / ', '\\\\':' \\ ', '\\^':' ^ ', '\\[':' [ ', '\\]':' ] ', \n",
    "                                       '<': ' < ', '>':' > ', '\\.':' . ' , '{':' { ', '}': ' } ', '`': ' ` ',\n",
    "                                       '′':' ′ ', '’':' ’ ', '‘':' ‘ ', \"'\":\" ' \", ';': ' ; ','•':' • ', '«':' « ',\n",
    "                                       '»': ' » ', ',':' , ', '@':' @ ', ':':' : ', '\\=': ' =', '!': ' ! ', '~':' ~ ', \n",
    "                                       '%': ' % ' })) #except _ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "##cur.execute(\"SELECT user_id, tweet from ent_2019_100K limit 100000 \")\n",
    "cur.execute(\"SELECT user_id, tweet from ent_2019_1000k \")\n",
    "rows_ent = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_ent))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47604376, 4)\n",
      "Index(['user_id', 'tweet', 'tweet_created_at', 'location_profile'], dtype='object')\n",
      "Number of tweets in ent: 47604376\n",
      "Memory size of ent: 402267520\n"
     ]
    }
   ],
   "source": [
    "#df_ent = pd.read_csv('/archives1/Datasets/TweetsWorld/ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "df_ent = pd.read_csv('ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "print(df_ent.shape)\n",
    "print(df_ent.columns)\n",
    "#print(df_ent.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_ent=list(df_ent[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_ent0\n",
    "#rows_ent= list(zip(df_ent.user_id, df_ent.tweet))\n",
    "#rows_ent=df_ent[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_ent\n",
    "\n",
    "print(\"Number of tweets in ent:\",len(rows_ent))  #rows_ent0\n",
    "print('Memory size of ent:',sys.getsizeof(rows_ent)) #rows_ent0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "df_mng = pd.read_csv('mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_mng = pd.read_csv('/archives1/Datasets/TweetsWorld/mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_mng.shape)\n",
    "print(df_mng.columns)\n",
    "#print(df_mng.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_mng=list(df_mng[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_mng0\n",
    "#rows_mng= list(zip(df_mng.user_id, df_mng.tweet))\n",
    "#rows_mng=df_mng[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_mng\n",
    "print(len(rows_mng)) #rows_mng0\n",
    "print('memry size of mng:', sys.getsizeof(rows_mng)) #rows_mng0\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from public_2019_1000k\")\n",
    "rows_public = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_public))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72182875, 4)\n",
      "Index(['user_id', 'tweet', 'tweet_created_at', 'location_profile'], dtype='object')\n",
      "72182875\n",
      "memory size of public: 644355008\n"
     ]
    }
   ],
   "source": [
    "df_public = pd.read_csv('public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "#df_public = pd.read_csv('/archives1/Datasets/TweetsWorld/public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "\n",
    "print(df_public.shape)\n",
    "print(df_public.columns)\n",
    "#print(df_public.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_public00=list(df_public[['user_id', 'tweet', 'tweet_created_at']].itertuples(index=False, name=None))\n",
    "#rows_public= list(zip(df_public.user_id, df_public.tweet))\n",
    "#rows_public=df_public[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_public\n",
    "print(len(rows_public00))\n",
    "print('memory size of public:', sys.getsizeof(rows_public00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53069041\n",
      "1000000\n",
      "memory size of public: 8697464\n"
     ]
    }
   ],
   "source": [
    "rows_public0=[]\n",
    "for i in rows_public00:\n",
    "    if ('2021' not in i[2] ) and ('2020-12' not in i[2]) and ('2020-11' not in i[2]) and ('2020-10' not in i[2]):\n",
    "        rows_public0.append(i)\n",
    "\n",
    "        \n",
    "print(len(rows_public0))\n",
    "del rows_public00\n",
    "\n",
    "\n",
    "#with open(\"rand_inds3.txt\", \"rb\") as fp:   \n",
    "#    rand_inds3=pickle.load(fp)\n",
    "    \n",
    "    \n",
    "rand_inds0e=np.sort(random.sample(range(0, len(rows_public0)), 1000000))  \n",
    "\n",
    "rows_public=[]\n",
    "for i in rand_inds0e:\n",
    "    rows_public.append(rows_public0[i])\n",
    "print(len(rows_public))\n",
    "\n",
    "del rows_public0\n",
    "\n",
    "\n",
    "with open(\"rand_inds0e.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(rand_inds0e, fp , protocol=4)\n",
    "\n",
    "print('memory size of public:',sys.getsizeof(rows_public))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7153.070677280426\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "ent_users_rows=[]\n",
    "ent_tweets_rows=[]\n",
    "for i in rows_ent:\n",
    "    ent_users_rows.append(i[0])\n",
    "    ent_tweets_rows.append(cleaning(i[1]))\n",
    "    \n",
    "print( time.time() - t0)\n",
    "\n",
    "#ent_users_rows_np=np.array(ent_users_rows)  \n",
    "#ent_users=np.unique(ent_users_rows_np)\n",
    "#print(len(ent_users))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "\n",
    "mng_users_rows=[]\n",
    "mng_tweets_rows=[]\n",
    "for i in rows_mng:\n",
    "    mng_users_rows.append(i[0])\n",
    "    mng_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "mng_users_rows_np=np.array(mng_users_rows)  \n",
    "mng_users=np.unique(mng_users_rows_np)\n",
    "print(len(mng_users))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320.355610370636\n",
      "33042\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "public_users_rows=[]\n",
    "public_tweets_rows=[]\n",
    "\n",
    "for i in rows_public:\n",
    "    public_users_rows.append(i[0])\n",
    "    public_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "public_users_rows_np=np.array(public_users_rows)  \n",
    "public_users=np.unique(public_users_rows_np)\n",
    "print(len(public_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder (tweets):\n",
    "    # padding after {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        \n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if len(tokenized_text)>max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "        segments_ids= segments_ids + [0] * (max_len_tokens+2 - len(segments_ids)) \n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,temp-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder2 (tweets):\n",
    "    #padding before {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = '[CLS]'+ text \n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "#        print(temp)\n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if temp>=max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "        else:\n",
    "#            print(type(tokenized_text))\n",
    "            tokenized_text = tokenized_text + ['[PAD]'] * (max_len_tokens+1 - temp)+ ['[SEP]']\n",
    "#            print('a44',tokenized_text)\n",
    "\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#                sequences, maxlen=10, dtype='int32', padding='post',\n",
    "#                truncating='post', value=0.0)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "#        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "#        segments_ids = [1] * len(tokenized_text)\n",
    "        segments_ids= [1]* min(temp,max_len_tokens+1) + [0] * (max_len_tokens+1 - temp)  + [1]\n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder0 (tweets):\n",
    "    #padding before {SEP} forcing zero\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=30\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "#    print('a11',np.shape(vector_temp))\n",
    "\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "        \n",
    "        \n",
    "                \n",
    "        marked_text = '[CLS]'+ text + '[SEP]'\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)-2\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('a88',len(token_embeddings))\n",
    "        if len(token_embeddings)>=max_len_tokens:\n",
    "            vector_temp= token_embeddings[0:max_len_tokens]\n",
    "#            print('a9',vector_temp)\n",
    "        else:\n",
    "            vector_temp = np.zeros([max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "            vector_temp[0:temp] = token_embeddings\n",
    "#            print('a99',vector_temp)\n",
    "        tweets_embedded[i]=vector_temp\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa=embedder0(['That is very good and joy '])\n",
    "#aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inds1e=random.sample(range(0, 1000000), 300000) #200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rand_inds1e.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(rand_inds1e, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set=set()\n",
    "seed_public0=[]\n",
    "for i in rand_inds1e:\n",
    "    temp=public_tweets_rows[i]\n",
    "    if temp !='' and temp !=' ':\n",
    "        if temp not in temp_set:\n",
    "            seed_public0.append(public_tweets_rows[i])\n",
    "            temp_set.add(temp) # in order that we do not have repetative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280488"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_public0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_public=seed_public0[0:200000]\n",
    "len(seed_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./seed_tweets_ent10m.txt\", \"rb\") as fp:   \n",
    "    seed_tweets_ent = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ent=[]\n",
    "for tweet in seed_tweets_ent:\n",
    "    seed_ent.append(cleaning(tweet))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_ent=seed_ent[0:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=[1]*len(seed_ent)+[0]*len(seed_public)\n",
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent\n",
      "mean length of tweets: 18.078025\n",
      "max length of tweets:  85\n",
      "std length of tweets:  7.736021797423081\n"
     ]
    }
   ],
   "source": [
    "df_ent = pd.DataFrame({'tweet':seed_ent})\n",
    "df_ent['len'] = df_ent['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "df_ent\n",
    "\n",
    "print('ent')\n",
    "print(\"mean length of tweets: \" + str(df_ent['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_ent['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_ent['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public\n",
      "mean length of tweets: 14.827295\n",
      "max length of tweets:  75\n",
      "std length of tweets:  9.565618928658463\n"
     ]
    }
   ],
   "source": [
    "df_public = pd.DataFrame({'tweet':seed_public})\n",
    "df_public['len'] = df_public['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_public\n",
    "\n",
    "print('public')\n",
    "print(\"mean length of tweets: \" + str(df_public['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_public['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_public['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#print(\"test set size \" + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=embedder0(ent_all[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts=seed_ent+seed_public\n",
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in ent_tweets_rows:\n",
    "#    texts.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1912.6158392429352"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0=time.time()\n",
    "train_texts_tokens=[]\n",
    "for text in train_texts:\n",
    "#    tokens=text.split()\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    train_texts_tokens.append(tokens)\n",
    "    \n",
    "print(len(train_texts_tokens))\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext.util.reduce_model(ft, 100)\n",
    "#ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131.23730373382568"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "embedding_dim=300\n",
    "max_tokens=50\n",
    "#X_train_test=[]\n",
    "x_train=np.zeros([len(train_texts_tokens),max_tokens,embedding_dim],dtype='float32')\n",
    "\n",
    "for kk,tokens in enumerate(train_texts_tokens):\n",
    "    if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "        a1=[]\n",
    "        for token in tokens:\n",
    "            a1.append( ft.get_word_vector(token) )\n",
    "                    \n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "        if len(tokens)>max_tokens:\n",
    "            temp=a1[0:max_tokens]\n",
    "        elif len(tokens)==max_tokens:\n",
    "            temp=a1\n",
    "        else: # if len(tokens)<max_tokens:\n",
    "            temp[0:len(tokens)]=a1\n",
    "#        X_train_test.append(temp) \n",
    "        x_train[kk]=temp\n",
    "\n",
    "    else:\n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "#        X_train_test.append(temp)\n",
    "        x_train[kk]=temp\n",
    "        \n",
    "time.time()-t0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train, tf.float32)\n",
    "y_train = tf.cast(y_data, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train1, x_test1, y_train, y_test = train_test_split(data, y_data, test_size=0.2, shuffle=True, stratify= y_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=50\n",
    "num_filters=100\n",
    "embedding_dim=300   #768 for bert\n",
    "dropout_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 300, 1)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 50, 1, 100)   30100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 49, 1, 100)   60100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 1, 100)   90100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 47, 1, 100)   120100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 46, 1, 100)   150100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 45, 1, 100)   180100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 44, 1, 100)   210100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 1, 100)   400         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 49, 1, 100)   400         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 1, 100)   400         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 47, 1, 100)   400         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 46, 1, 100)   400         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 45, 1, 100)   400         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 44, 1, 100)   400         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 100)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 1, 700)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 700)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          358912      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            9           dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,377,645\n",
      "Trainable params: 1,376,245\n",
      "Non-trainable params: 1,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "#inputs = Input(shape=(sequence_length,), dtype='float32')\n",
    "\n",
    "#embedded_inputs = embedding_layer(inputs)\n",
    "#embedding_layer = Embedding(input_dim=20000, output_dim=embedding_dim, input_length=sequence_length, weights=[inputs])(inputs)\n",
    "\n",
    "#inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(embedded_inputs)\n",
    "inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(1, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_1 = LeakyReLU(alpha=0.2)(conv_1) #without activation at Conv2D\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(2, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_2 = LeakyReLU(alpha=0.2)(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_3 = LeakyReLU(alpha=0.2)(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_4 = LeakyReLU(alpha=0.2)(conv_4)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_5 = LeakyReLU(alpha=0.2)(conv_5)\n",
    "conv_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(num_filters, kernel_size=(6, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_6 = LeakyReLU(alpha=0.2)(conv_6)\n",
    "conv_6 = BatchNormalization()(conv_6)\n",
    "\n",
    "conv_7 = Conv2D(num_filters, kernel_size=(7, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_7 = LeakyReLU(alpha=0.2)(conv_7)\n",
    "conv_7 = BatchNormalization()(conv_7)\n",
    "\n",
    "conv_8 = Conv2D(num_filters, kernel_size=(8, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_8 = LeakyReLU(alpha=0.2)(conv_8)\n",
    "#conv_8 = BatchNormalization()(conv_8)\n",
    "\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 1 + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 2 + 1, 1), strides=(1,1))(conv_2)\n",
    "maxpool_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1))(conv_3)\n",
    "maxpool_4 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1))(conv_4)\n",
    "maxpool_5 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1))(conv_5)\n",
    "maxpool_6 = MaxPool2D(pool_size=(sequence_length - 6 + 1, 1), strides=(1,1))(conv_6)\n",
    "maxpool_7 = MaxPool2D(pool_size=(sequence_length - 7 + 1, 1), strides=(1,1))(conv_7)\n",
    "maxpool_8 = MaxPool2D(pool_size=(sequence_length - 8 + 1, 1), strides=(1,1))(conv_8)\n",
    "\n",
    "#concatenated_e1 = Concatenate(axis=3)([maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5])\n",
    "concatenated_e1 = Concatenate(axis=3)([ maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5, maxpool_6, maxpool_7 ])\n",
    "\n",
    "X = Flatten()(concatenated_e1)\n",
    "\n",
    "X = Dense(units=512, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=256, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=128, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=64, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=32, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=16, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=8, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "#outputs = Dense(units=5, activation='softmax')(X) \n",
    "outputs = Dense(units=1, activation='sigmoid')(X) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "classifier.summary()\n",
    "#classifier.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3) , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.compile(optimizer=keras.optimizers.Adamax() , loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#optim= adamax, adam\n",
    "#loss:categorical_crossentropy, KLDivergence, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# not good results ##type 2( small kernels like images)\n",
    "#sequence_length=16 # or 24 or 32 or 64 \n",
    "##encoder\n",
    "print(sequence_length,embedding_dim)\n",
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "\n",
    "x = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x) \n",
    "print(x.shape)\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "x = Flatten()(x)\n",
    "print(np.shape(x))\n",
    "#x = Dense(1764, activation=\"relu\")(x)\n",
    "\n",
    "#x = Dense(units=8, activation='linear')(x)\n",
    "#x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = Dense(units=5, activation='softmax')(x) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "#optim = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#classifier.compile(optimizer=optim)\n",
    "classifier.compile(optimizer=keras.optimizers.Adam() , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 50, 300)\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - 595s 2s/step - loss: 5.1488 - accuracy: 0.8715 - val_loss: 0.2569 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - 537s 2s/step - loss: 0.2898 - accuracy: 0.9619 - val_loss: 0.1862 - val_accuracy: 0.9967\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - 516s 1s/step - loss: 0.2343 - accuracy: 0.9685 - val_loss: 0.1895 - val_accuracy: 0.9804\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - 518s 1s/step - loss: 0.2193 - accuracy: 0.9729 - val_loss: 0.1718 - val_accuracy: 0.9907\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - 517s 1s/step - loss: 0.2255 - accuracy: 0.9727 - val_loss: 0.1848 - val_accuracy: 0.9807\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - 514s 1s/step - loss: 0.2120 - accuracy: 0.9745 - val_loss: 0.1946 - val_accuracy: 0.9760\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - 562s 2s/step - loss: 0.2055 - accuracy: 0.9755 - val_loss: 0.1695 - val_accuracy: 0.9870\n",
      "Epoch 8/1000\n",
      "352/352 [==============================] - 521s 1s/step - loss: 0.2032 - accuracy: 0.9749 - val_loss: 0.1502 - val_accuracy: 0.9821\n",
      "Epoch 9/1000\n",
      "352/352 [==============================] - 1217s 3s/step - loss: 0.1845 - accuracy: 0.9775 - val_loss: 0.1551 - val_accuracy: 0.9850\n",
      "Epoch 10/1000\n",
      "352/352 [==============================] - 456s 1s/step - loss: 0.1880 - accuracy: 0.9765 - val_loss: 0.1929 - val_accuracy: 0.9747\n",
      "Epoch 11/1000\n",
      "352/352 [==============================] - 437s 1s/step - loss: 0.1834 - accuracy: 0.9764 - val_loss: 0.1353 - val_accuracy: 0.9952\n",
      "Epoch 12/1000\n",
      "352/352 [==============================] - 425s 1s/step - loss: 0.1804 - accuracy: 0.9776 - val_loss: 0.1728 - val_accuracy: 0.9758\n",
      "Epoch 13/1000\n",
      "352/352 [==============================] - 427s 1s/step - loss: 0.1734 - accuracy: 0.9775 - val_loss: 0.1671 - val_accuracy: 0.9802\n",
      "Epoch 14/1000\n",
      "352/352 [==============================] - 408s 1s/step - loss: 0.1691 - accuracy: 0.9780 - val_loss: 0.1126 - val_accuracy: 0.9942\n",
      "Epoch 15/1000\n",
      "352/352 [==============================] - 446s 1s/step - loss: 0.1625 - accuracy: 0.9785 - val_loss: 0.1384 - val_accuracy: 0.9850\n",
      "Epoch 16/1000\n",
      "352/352 [==============================] - 425s 1s/step - loss: 0.1593 - accuracy: 0.9783 - val_loss: 0.1137 - val_accuracy: 0.9930\n",
      "Epoch 17/1000\n",
      "352/352 [==============================] - 410s 1s/step - loss: 0.1611 - accuracy: 0.9777 - val_loss: 0.1134 - val_accuracy: 0.9907\n",
      "Epoch 18/1000\n",
      "352/352 [==============================] - 413s 1s/step - loss: 0.1536 - accuracy: 0.9777 - val_loss: 0.1473 - val_accuracy: 0.9818\n",
      "Epoch 19/1000\n",
      "352/352 [==============================] - 424s 1s/step - loss: 0.1524 - accuracy: 0.9783 - val_loss: 0.1536 - val_accuracy: 0.9785\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00019: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "#history= classifier.fit(x_train,x_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,batch_size=32,epochs=1000)\n",
    "print(np.shape(x_train))\n",
    "\n",
    "history=classifier.fit(x_train,y_train,\n",
    "                        epochs=1000,\n",
    "                        callbacks=[monitor],\n",
    "                        batch_size=512, # or 64\n",
    "                        shuffle= True,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.25)\n",
    "\n",
    "#history = classifier.fit(x_train, y_train, epochs=8, batch_size=512, verbose=1, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# for bert\\nt0=time.time()\\nent_ind_detected=[]\\nb=ent_tweets_rows[0:200000]\\nent_test_embedded=embedder0(b)\\ny_predicted=classifier.predict(ent_test_embedded)\\nfor ind, value in enumerate(y_predicted):\\n    if value >= 0.5:\\n        ent_ind_detected.append(ind)\\nprint(time.time()-t0) \\n'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# for bert\n",
    "t0=time.time()\n",
    "ent_ind_detected=[]\n",
    "b=ent_tweets_rows[0:200000]\n",
    "ent_test_embedded=embedder0(b)\n",
    "y_predicted=classifier.predict(ent_test_embedded)\n",
    "for ind, value in enumerate(y_predicted):\n",
    "    if value >= 0.5:\n",
    "        ent_ind_detected.append(ind)\n",
    "print(time.time()-t0) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-315535605eaf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mres_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mresults_ent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1627\u001b[0m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    860\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2943\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2945\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1919\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "\n",
    "max_tokens=50\n",
    "embedding_dim=300\n",
    "batch_size=10000\n",
    "batch=0\n",
    "results_ent=[]\n",
    "len_ent=len(ent_tweets_rows)\n",
    "\n",
    "while batch <len_ent:\n",
    "    test =  ent_tweets_rows [batch : batch + batch_size]\n",
    "    test_data=[]\n",
    "    \n",
    "    for tweet in test:\n",
    "    #    tokens=text.split()\n",
    "        tokens=nltk.word_tokenize(tweet)\n",
    "        if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "            a1=[]\n",
    "            for token in tokens[0:max_tokens]:\n",
    "                a1.append( ft.get_word_vector(token) )\n",
    "            \n",
    "            a1=np.asarray(a1, dtype=np.float32)            \n",
    "            temp=np.zeros([max_tokens,embedding_dim])\n",
    "\n",
    "            if len(tokens)>max_tokens:\n",
    "                temp=a1[0:max_tokens]\n",
    "            elif len(tokens)==max_tokens:\n",
    "                temp=a1\n",
    "            else: #if len(tokens)<max_tokens:\n",
    "                temp[0:len(tokens)]=a1\n",
    "        \n",
    "            #x_test=temp.reshape((1,max_tokens,embedding_dim))  \n",
    "            #print(np.shape(temp))\n",
    "            #x_test = tf.cast(temp, tf.float32)\n",
    "            test_data.append(temp)\n",
    "            \n",
    "        else:\n",
    "            test_data.append(np.zeros([max_tokens,embedding_dim]))\n",
    "              \n",
    "#    test_data = tf.cast(test_data, tf.float32)\n",
    "    test_data = np.asarray(test_data, dtype=np.float32)\n",
    "    res_test=classifier.predict(test_data)\n",
    "    results_ent.extend(res_test)\n",
    "    batch += batch_size\n",
    "     \n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293153.90668821335"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34630000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34630000"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_entx=results_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-68-2727f4de82fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresults_ent\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m34630000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "results_ent[34630000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47604376"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232875.82859826088"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "\n",
    "\n",
    "batch_size=10000\n",
    "batch=34630000\n",
    "\n",
    "len_ent=len(ent_tweets_rows)\n",
    "\n",
    "while batch <len_ent:\n",
    "    test =  ent_tweets_rows [batch : batch + batch_size]\n",
    "    test_data=[]\n",
    "    \n",
    "    for tweet in test:\n",
    "    #    tokens=text.split()\n",
    "        tokens=nltk.word_tokenize(tweet)\n",
    "        if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "            a1=[]\n",
    "            for token in tokens[0:max_tokens]:\n",
    "                a1.append( ft.get_word_vector(token) )\n",
    "            \n",
    "            a1=np.asarray(a1, dtype=np.float32)            \n",
    "            temp=np.zeros([max_tokens,embedding_dim])\n",
    "\n",
    "            if len(tokens)>max_tokens:\n",
    "                temp=a1[0:max_tokens]\n",
    "            elif len(tokens)==max_tokens:\n",
    "                temp=a1\n",
    "            else: #if len(tokens)<max_tokens:\n",
    "                temp[0:len(tokens)]=a1\n",
    "        \n",
    "            #x_test=temp.reshape((1,max_tokens,embedding_dim))  \n",
    "            #print(np.shape(temp))\n",
    "            #x_test = tf.cast(temp, tf.float32)\n",
    "            test_data.append(temp)\n",
    "            \n",
    "        else:\n",
    "            test_data.append(np.zeros([max_tokens,embedding_dim]))\n",
    "              \n",
    "#    test_data = tf.cast(test_data, tf.float32)\n",
    "    test_data = np.asarray(test_data, dtype=np.float32)\n",
    "    res_test=classifier.predict(test_data)\n",
    "    results_ent.extend(res_test)\n",
    "    batch += batch_size\n",
    "     \n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ent_results300.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(results_ent, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ent_numpy=np.asarray(results_ent, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47604376"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ent_results300_np.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(results_ent_numpy, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
