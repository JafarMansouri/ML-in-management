{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas\n",
    "import csv\n",
    "import re #regular expression\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "##nltk.download('stopwords')# Download stopwords\n",
    "from textblob import TextBlob\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_key = 'xxx'\n",
    "consumer_secret = 'xxx'\n",
    "access_token = 'xxx'\n",
    "access_secret = 'xxx'\n",
    "access_token_secret=access_secret\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_bmp_map = dict.fromkeys(range(0x10000, sys.maxunicode + 1), 0xfffd)\n",
    "##print(x.translate(non_bmp_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(tweet):\n",
    "    ##Handle Emoticons and Emojis\n",
    "    #HappyEmoticons\n",
    "    emoticons_happy = set([\n",
    "        ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "        ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "        '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "        'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "        '<3'\n",
    "        ])\n",
    "    \n",
    "    #Sad Emoticons\n",
    "    emoticons_sad = set([\n",
    "        ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "        ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "        ':c', ':{', '>:\\\\', ';('\n",
    "        ])\n",
    "    \n",
    "    ##Emoji patterns\n",
    "    #combine sad and happy emoticons\n",
    "    emoticons = emoticons_happy.union(emoticons_sad)\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "             u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "             u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "             u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "             u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "             u\"\\U00002702-\\U000027B0\"\n",
    "             u\"\\U000024C2-\\U0001F251\"                  \n",
    "             \"]+\", flags=re.UNICODE)\n",
    "\n",
    "##    extract_link\n",
    "##    regex = r' https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+ '\n",
    "##    match = re.search(regex, tweet.full_text)\n",
    "##    if match:\n",
    "##        print(\"links: \", match)\n",
    "\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet1 = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', tweet)\n",
    "##    print(\"a1             \",tweet1)\n",
    "\n",
    "    #remove emojis from tweet\n",
    "    tweet2 = emoji_pattern.sub(r'', tweet1)   \n",
    "##    print(\"a2             \",tweet2)\n",
    "\n",
    "    #utility function to clean tweet text by removing links, special characters using simple regex statements. \n",
    "    tweet3=re.sub(\"(@[A-Za-z0-9_]+)|([^0-9A-Za-z_ \\t]) |(\\w+:\\/\\/\\S+)\", \" \", tweet2) \n",
    "##    print(\"a3             \",tweet3)\n",
    "\n",
    "    #removing numbers\n",
    "    tweet4= re.sub(\" (\\d+) | (\\d+)(.)(\\d+) \", ' ',tweet3) # number alone\n",
    "    tweet5= re.sub(\"(\\d+)\", ' ',tweet4) # number attached\n",
    "##    print(\"a4             \",tweet5)\n",
    "\n",
    "    # removing some charachters \n",
    "####    tweet6= re.sub(\".\", ' ',tweet4) # !!!! remove all\n",
    "    tweet6= re.sub(\"[\\\";:\\|,~!=\\-+#$%&*\\(\\)?\\.\\/]+\", ' ',tweet5)\n",
    "##    print(\"a5             \",tweet6)\n",
    "   \n",
    "    # Create a sublist of lower case words for each tweet\n",
    "    words_in_tweet = tweet6.lower().split()\n",
    "##    print(\"a5    \",words_in_tweet)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tweet_cleaned=''\n",
    "    for word in words_in_tweet:\n",
    "        if word not in stop_words:\n",
    "            tweet_cleaned +=' '+ word       \n",
    "##    print(\"a6    \",tweets_cleaned)\n",
    "\n",
    "    return tweet_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can feed the keywords and other info necesaary for runing the code manually or by the input command or by the reading from info file\n",
    "##KEYWORDS_str = input(\"Insert your keywords:\") \n",
    "##LANG = input(\"Insert the language code:\")\n",
    "##LOC=input(\"Insert locations(s):\")\n",
    "\n",
    "Info = pandas.read_csv('Info.csv', sep=';', na_values=\".\")\n",
    "Info.shape\n",
    "Info.columns\n",
    "##print(Info['keywords'])\n",
    "print(Info['keywords'][1])\n",
    "KEYWORDS_str=Info['keywords'][1]\n",
    "KEYWORDS_list=KEYWORDS_str.split(',')\n",
    "print(Info['language'][1])\n",
    "LANG=Info['language'][1]\n",
    "print(Info['location'][1])\n",
    "LOC=Info['location'][1]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_term = \"*  -filter:retweets\"\n",
    "##search_term = \"'#entrepreneur' OR business owner'' OR 'founded' OR 'founder'  -filter:retweets\"\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "                   q=search_term,\n",
    "                   result_type=\"recent\",\n",
    "                   count=100,\n",
    "                   lang=LANG,\n",
    "                   tweet_mode=\"extended\",\n",
    "                   ).items() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for the first time for creating the csv file, uncemment this block, then comment this block so that even after interruption due to interenet disconnection, twitter API termination and ... tweets can added to the file.\n",
    "\n",
    "##csvFile_Loc = open(LOC+'.csv', 'w')\n",
    "##csvWriter = csv.writer(csvFile_Loc, delimiter=';', quoting=csv.QUOTE_MINIMAL)\n",
    "##csvWriter.writerow([\"user screen_name\",\n",
    "##                    \"user name\",\n",
    "##                    \"user id\",\n",
    "##                    \"tweet\",\n",
    "##                    \"cleaned tweet\",\n",
    "##                    \"language\",\n",
    "##                    \"created at\",\n",
    "##                    \"full name of the city for tweet\",\n",
    "##                    \"country code for tweet\",\n",
    "##                    \"location in profile\",\n",
    "##                    \"profile description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collecting target tweets\n",
    "n_total=0\n",
    "n_target=0\n",
    "for tweet in tweets:\n",
    "    n_total +=1\n",
    "##    print(tweet.full_text.translate(non_bmp_map))\n",
    "##    print(tweet.user.screen_name.translate(non_bmp_map))\n",
    "##    print()\n",
    "    if LOC in tweet.user.location:\n",
    "####        print(tweet)\n",
    "####        print(tweet.author)\n",
    "####        print(tweet.geo)\n",
    "####        print(tweet.place)\n",
    "####        print(tweet.metadata)       \n",
    "\n",
    "        try:\n",
    "            city_name=tweet.place.full_name\n",
    "        except:\n",
    "            city_name=\"unknown\"\n",
    "\n",
    "        try:\n",
    "           country_code=tweet.place.country_code\n",
    "        except:\n",
    "            country_code=\"unknown\"    \n",
    "\n",
    "####        print(\"entities:\",tweet.user.entities)\n",
    "####        print(\"url:\",tweet.user.url)\n",
    "####        print(tweet.user.followers_count)\n",
    "####        print(\"Account created at: \",tweet.user.created_at)\n",
    "####        print(tweet.user.friends_count)\n",
    "####        print(tweet.user.favourites_count)\n",
    "####        print(\"geo_enabled\",tweet.user.geo_enabled)\n",
    "####        print(tweet.user.time_zone)\n",
    "####        print(\"verified\",tweet.user.verified)\n",
    "####        print(tweet.user.statuses_count)\n",
    "####        print(\"lang\",tweet.user.lang)\n",
    "####        print(tweet.user.contributors_enabled)\n",
    "####        print(tweet.user.is_translator)\n",
    "####        print(tweet.user.is_translation_enabled)\n",
    "####        print(\"following\",tweet.user.following)\n",
    "####        print()\n",
    "\n",
    "\n",
    "        words_in_description=cleaning(tweet.user.description)\n",
    "        KEYWORDS_list\n",
    "##        key__words=['entrepreneur','founder','founded','business owner']\n",
    "##        if set(key__words) & set(words_in_description.split(' ')):\n",
    "        \n",
    "        Istarget=0\n",
    "        for KEY in KEYWORDS_list:\n",
    "            if KEY in words_in_description:\n",
    "                Istarget+=1\n",
    "        if Istarget>0:\n",
    "##\t  if set(KEYWORDS_list) & set(words_in_description.split(' ')):\n",
    "            n_target +=1\n",
    "            print(\"target detected\")\n",
    "            words_in_tweet=cleaning(tweet.full_text)\n",
    "\n",
    "            #Open the file to append data\n",
    "            csvFile_Loc = open(LOC+'.csv', 'a',encoding=\"utf-8\")\n",
    "            csvWriter = csv.writer(csvFile_Loc, delimiter=';' , quoting=csv.QUOTE_MINIMAL)\n",
    "            csvWriter.writerow([tweet.user.screen_name.translate(non_bmp_map),\n",
    "                               tweet.user.name.translate(non_bmp_map),\n",
    "                               tweet.user.id,\n",
    "                               tweet.full_text.translate(non_bmp_map),\n",
    "                               words_in_tweet,\n",
    "                               tweet.lang,\n",
    "                               tweet.created_at,\n",
    "                               city_name,\n",
    "                               country_code,\n",
    "                               tweet.user.location.translate(non_bmp_map),\n",
    "                               tweet.user.description]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"nember of colleted tweets:\",n_total)\n",
    "print(\"nember of target tweets:\",n_target)\n",
    "info_csv_Loc = pandas.read_csv(LOC+'.csv', sep=';', na_values=\".\")\n",
    "info_csv_Loc.shape \n",
    "info_csv_Loc.columns\n",
    "info_csv_Loc.head()# Preview the first 5 lines of the loaded data \n",
    "print(info_csv_Loc['user id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
