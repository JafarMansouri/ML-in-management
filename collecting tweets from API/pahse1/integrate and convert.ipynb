{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas\n",
    "import sys\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(tweet):\n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "             u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "             u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "             u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "             u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "             u\"\\U00002702-\\U000027B0\"\n",
    "             u\"\\U000024C2-\\U0001F251\"\n",
    "             \"]+\", flags=re.UNICODE)\n",
    "\n",
    "##    extract_link\n",
    "##    regex = r' https?://[^\\s<>\"]+|www\\.[^\\s<>\"]+ '\n",
    "##    match = re.search(regex, tweet.full_text)\n",
    "##    if match:\n",
    "##        print(\"links: \", match)\n",
    "\n",
    "    #replace consecutive non-ASCII characters with a space\n",
    "    tweet1 = re.sub(r'[^\\x00-\\x7F]+|,Ä¶','', tweet)\n",
    "##    print(\"a1             \",tweet1)\n",
    "\n",
    "    #remove emojis from tweet\n",
    "    tweet2 = emoji_pattern.sub(r'', tweet1)   \n",
    "##    print(\"a2             \",tweet2)\n",
    "\n",
    "    #utility function to clean tweet text by removing links, special characters using simple regex statements. \n",
    " #   tweet3=re.sub(\"(@[A-Za-z0-9_]+)\", \"\", tweet2) \n",
    "\n",
    "##    print(\"a3             \",tweet3)\n",
    "    \n",
    " #   tweet4= re.sub(r\"\\r\", '',tweet3)\n",
    " #   tweet5= re.sub(r\"\\n\", '',tweet4)\n",
    " #   tweet6= re.sub(r\"www\\.[^\\s<>]+|https?://[^\\s<>]+|http?://[^\\s<>]+\", '',tweet5)\n",
    "    \n",
    "    tweet_cleaned=tweet2\n",
    "    return tweet_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_hashtag(tweet):\n",
    "    new=re.sub(r\"#[^\\s<>]+\", '',tweet)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_target(tweet):\n",
    "    new=re.sub(\"(@[A-Za-z0-9_]+)\", \"\", tweet) \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removing_link(tweet):\n",
    "    new= re.sub(r\"www\\.[^\\s<>]+|https?://[^\\s<>]+|http?://[^\\s<>]+\", '',tweet)\n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I’m : ; sorry I can't @dkf #jdfjd  222fjfkf :)\n",
      "I’m : ; sorry I can't  #jdfjd http://dfbjdfjdscfdjfjfd.fejfkre 222fjfkf :)\n",
      "I’m : ; sorry I can't @dkf  http://dfbjdfjdscfdjfjfd.fejfkre 222fjfkf :)\n",
      "Im : ; sorry I can't @dkf #jdfjd http://dfbjdfjdscfdjfjfd.fejfkre 222fjfkf :)\n"
     ]
    }
   ],
   "source": [
    "text=\"I’m : ; sorry I can't @dkf #jdfjd http://dfbjdfjdscfdjfjfd.fejfkre 222fjfkf :)\"\n",
    "print(removing_link(text))\n",
    "print(removing_target(text))\n",
    "print(removing_hashtag(text))\n",
    "print(cleaning(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "info_csv1 = pandas.read_csv('C:/New folder/codes/New York.csv', sep=';', na_values=\"(missing)\")\n",
    "info_csv1.head()# Preview the first 5 lines of the loaded data \n",
    "print(info_csv1.columns)\n",
    "info_csv1.shape \n",
    "\n",
    "info_csv2 = pandas.read_csv('C:/New folder/codes/Silicon Valley.csv', sep=';', na_values=\"(missing)\")\n",
    "info_csv2.head()# Preview the first 5 lines of the loaded data \n",
    "info_csv2.columns\n",
    "info_csv2.shape \n",
    "\n",
    "info_csv3 = pandas.read_csv('C:/New folder/codes/London.csv', sep=';', na_values=\"(missing)\")\n",
    "info_csv3.head()# Preview the first 5 lines of the loaded data \n",
    "info_csv3.columns\n",
    "info_csv3.shape \n",
    "\n",
    "\n",
    "info_csv4 = pandas.read_csv('C:/New folder/codes/world.csv', sep=';', na_values=\"(missing)\")\n",
    "info_csv4.head()# Preview the first 5 lines of the loaded data \n",
    "info_csv4.columns\n",
    "info_csv4.shape \n",
    "'''\n",
    "##df=info_csv_Loc\n",
    "##df.to_excel('data1.xlsx')\n",
    "##df.to_json('data1-columns.json')\n",
    "\n",
    "#csvFile = open('All tweets.csv', 'w')\n",
    "#csvWriter = csv.writer(csvFile, delimiter=';')\n",
    "\n",
    "locations=['New York','London','Silicon Valley','world']\n",
    "#locations=['New York','London','Silicon Valley']\n",
    "#locations=['world']\n",
    "\n",
    "csvFile_Loc = open('All tweets V2.csv', 'w',encoding=\"utf-8\")\n",
    "csvWriter = csv.writer(csvFile_Loc, delimiter=';' , quoting=csv.QUOTE_MINIMAL)\n",
    "csvWriter.writerow(['source','type','user screen_name', 'user name', 'user id', 'tweet', \"cleaned tweet\",\n",
    "                    'language', 'created at', 'full name of the city for tweet',\n",
    "                    'country code for tweet', 'location in profile', 'profile description',\n",
    "                    'Sample Day','JM','FC','DK'])\n",
    "\n",
    "\n",
    "#csvFile_Loc = open('All tweets.csv', 'a',encoding=\"utf-8\")\n",
    "#csvWriter = csv.writer(csvFile_Loc, delimiter=';' , quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "\n",
    "for city in locations:\n",
    "    info = pandas.read_csv('C:/New folder/codes/'+city+'.csv', sep=';', na_values=\".\")\n",
    "    for i in range(info.shape[0]):\n",
    "        if city == \"world\":\n",
    "            t_type=\"extended keywords\"\n",
    "        else:\n",
    "            t_type=None\n",
    "        \n",
    "        csvWriter.writerow([city,\n",
    "                            t_type,\n",
    "                            info['user screen_name'][i],\n",
    "                            info[\"user name\"][i],\n",
    "                            info[\"user id\"][i],\n",
    "                            info[\"tweet\"][i],\n",
    "                            cleaning(removing_target(removing_link(info[\"tweet\"][i]))),\n",
    "                            info[\"language\"][i],\n",
    "                            info[\"created at\"][i],\n",
    "                            info[\"full name of the city for tweet\"][i],\n",
    "                            info[\"country code for tweet\"][i],\n",
    "                            info[\"location in profile\"][i],\n",
    "                            info[\"profile description\"][i],\n",
    "                            None,None,None,None])\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('All tweets V2.csv', sep=';', na_values=\"(missing)\")\n",
    "df.to_excel('All tweets V2.xlsx', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(info[\"user id\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvFile_Loc = open('All twdfdsfsdfsdfdfdsfdeets2 V2.csv', 'w',encoding=\"utf-8\")\n",
    "csvWriter = csv.writer(csvFile_Loc, delimiter=';' , quoting=csv.QUOTE_MINIMAL)\n",
    "csvWriter.writerow(['source','type','user screen_name'])\n",
    "csvWriter.writerow([52,'type','user screen_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
