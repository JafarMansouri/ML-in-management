{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#!/usr/local/bin/python\n",
    "# -*- coding: utf-8 -*-\n",
    "### export PYTHONIOENCODING=utf-8  # at cmd of linux\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import regularizers\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.callbacks import *\n",
    "from tensorflow.keras import utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import re\n",
    "import nltk\n",
    "import sys\n",
    "import html\n",
    "import xml.sax.saxutils as saxutils\n",
    "from html.parser import HTMLParser\n",
    "from io import StringIO\n",
    "import random\n",
    "\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel,DistilBertTokenizer\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "Stem=stemmer.stem\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "lemm=wordnet_lemmatizer.lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import load_facebook_model\n",
    "\n",
    "import fasttext.util\n",
    "#fasttext.util.download_model('en', if_exists='ignore')  # English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model_bert = DistilBertModel.from_pretrained('distilbert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )  \n",
    "'''\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model_bert = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                       output_hidden_states = True, # Whether the model returns all hidden-states.\n",
    "                                       )\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(len(cachedStopWords))\n",
    "#print(len(cachedStopWords))\n",
    "#print(type(cachedStopWords))\n",
    "\n",
    "nltk_stopwords=set(cachedStopWords)\n",
    "\n",
    "english_alghabet=['b','c','e','f','g','h','j','k','l','n','p','q','r','u','v','w','x','z']\n",
    "\n",
    "numbers_remove=['one','two','three','four','five','six','seven','eight','nine','ten','tens','twenty',\n",
    "                'fourty','fifty','sixty','seventy','eighty','ninety','hundred','hundreds','million','billion','trillion',\n",
    "                'millions','thousand','thousands','second','third','forth','tenth','billions','trillions'] \n",
    "\n",
    "miscellaneous_remove=['absolutely', 'actually', 'adieu', 'ain', \"ain't\", 'aint', 'almost',\n",
    "                       'awesome','awfully','amazing','interesting',\n",
    "                       'alright','alrighty', 'amoungst', 'anybody', 'anymore', 'anyways', 'apart', 'apparently', 'anytime',\n",
    "                       'appropriate',  'approximately', 'arent', 'behold', 'better', 'bravo','briefly','bad','best','brilliant',\n",
    "                       'bye', 'cant', 'certainly', 'chrissakes', 'clearly', 'completely',\n",
    "                       'congrat', 'congrats','congratulation', 'congratulations', 'consequently', 'cool', 'couldnt',\n",
    "                       'darnit', 'de','dear', 'definitely','disappointing', 'didn', 'doesn', 'don', 'downwards',\n",
    "                       'disgusting','dude','down','eg',\"e.g.\",'i.e.',\n",
    "                       'encore','entirely', 'especially', 'et', 'etc', 'everybody', 'ex', 'exactly', 'excellent',\n",
    "                       'fantastic','far', 'farewell','funny',\n",
    "                       'felicitation', 'felicitations','finally', 'fully','furthermore', 'gadzooks', \n",
    "                       'good', 'goodby','goodness', 'gracious', 'great', \n",
    "                       'greetings', 'hallo', 'hardly', 'hasnt', 'haven', 'hello', 'here','hi', 'hither','higher','hopefully',\n",
    "                       'here','there','including',\n",
    "                       'howbeit', 'ie', 'immediately', 'inasmuch', 'inner', 'insofar', 'instead', 'inward', 'important',\n",
    "                       'indeed','just', \"it'd\", \"it'll\", 'inside','kertyschoo', 'kg', 'km', 'lackaday', \n",
    "                       'largely', 'lately', 'later','lovely','large','big','small',\n",
    "                       'lest', 'let', 'lets', 'likely', 'little', 'ltd', 'lower','magnificent', 'mainly', 'marvelous',\n",
    "                       'myself','yourself','yourselves','himself','herself','hisself','ourselves','themsleves',\n",
    "                       'maybe', 'meantime', 'merely', 'minus', 'near', 'nearly', 'necessary', 'never', \n",
    "                       'non', 'normally', 'obviously', 'ok', 'okay', 'ones', 'outside', 'over','other','others','only',\n",
    "                       'overall', 'particular', 'particularly', 'please', 'plus', 'poorly', 'possible','up',\n",
    "                       'possibly', 'potentially', 'predominantly', 'presumably', 'previously','primarily', 'probably',\n",
    "                       'promising',\n",
    "                       'promptly', 'readily', 'really', 'reasonably', 'recent', 'recently', 'ref',\n",
    "                       'refs', 'regardless', 'related', 'relatively', 'respectively', 'resulting', 'right', 'sec', \n",
    "                       'secondly','self', 'selves', 'seriously', 'shall', 'shucks','somebody', 'somethan','sorry',\n",
    "                       'somewhat', 'soon', 'late' , 'sorry', 'stupid', 'sub', 'substantially', 'successfully', 'sufficiently',\n",
    "                       'useful',\n",
    "                       'super', 'sure', \"t's\", 'th', 'thank', 'thanks', 'thanx', \"that've\", 'thats', 'there', \"there'll\",\n",
    "                       \"there've\", 'thered', 'thereof', 'therere', 'theres', 'thereto', 'theyd', 'theyre', 'thorough',\n",
    "                       'then','thankfully','too','today','yesterday','tomorrow','night',\"morning\",'afternoon','noon','tonight',\n",
    "                       'evening','day','everyday', 'everynight','todays','nights','mornings','noons','afternoons','days',\n",
    "                       'evenings','week','month','year',\n",
    "                       'thoroughly', 'tnx', 'too','truly', 'twice', 'undoubtedly','unfortunately', 'unlike','unlikely',\n",
    "                       'unto',  'usually', 'vs', 'welcome', 'well', 'went', 'werent', 'what', 'whatever', 'wheres', 'widely',\n",
    "                       'wonderful', 'wont', 'wouldnt', 'wrong', 'worst','worse','www', 'yes', 'youd', 'youre', 'yummy', \n",
    "                       'zoinks','shit','literally','literal','pleasure','effective','fabulous','delighted',\n",
    "                       'saturday','sunday','monday','tuesday','wednesday','thursday', 'friday','past','future','suitable',\n",
    "                       'much','many','less','least','few','lots','lot','fewer','fewset','therefore','pm',\n",
    "                       'afaik', 'br', 'idk','smh','qotd', 'ftw','bfn','yw', 'icymi','fomo','smdh', 'b4','imho',\n",
    "                       'urdddd','fab' ,'delightful','absolute','pleasure','huge','latest','nowadays',\n",
    "                       'january','february','april','june','july','august','september','october',\n",
    "                       'november','december', 'autumn' ,'spring','winter','summer',\n",
    "                       'mr','madam','sir','mrs','easy', 'difficult',\n",
    "                       'weekend','south','north','west','east','asia','africa','europe','america','totally',\n",
    "                       'come', 'comes', 'coming', 'came', 'seems', 'gives', 'gave', 'makes', 'made', 'keeps', 'kept', \n",
    "                       'calls', 'called', 'says', 'saying', 'said', 'goes', 'went', 'gone', 'got', 'saw', 'seen', 'shows',\n",
    "                       'shown', 'took', 'taken', 'uses', 'moved', 'moves', 'puts',\n",
    "                       'using','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "                       'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use',\n",
    "                       'find', 'finds', 'finding','aka',\n",
    "                       'lol' , 'brb', 'lmk', 'ama', 'tbh', 'irl', \"tl;dr\", 'fml', 'bfn' ,' br', 'ht', \"hth\",'j/k', 'lmao' ] #cool\n",
    "\n",
    "interjection_remove=['aaaahh', 'aaah', 'aaargh', 'aaay', 'aagh', 'aah',\n",
    "                   'aargh', 'achoo', 'adios', 'ah', 'aha', 'ahem', 'ahh', 'ahhh',\n",
    "                   'ahoy', 'alas', 'allo', 'amen', 'areet', 'argh', 'arrggh',\n",
    "                   'arrividerci', 'asap', 'attaboy', 'avaunt', 'aw', 'aw', 'aww',\n",
    "                   'awww', 'ay', 'ay', 'aye', 'ayeaugh', 'bada', 'badum', 'bah',\n",
    "                   'bahaha', 'bam', 'bazinga', 'behold', 'bingce', 'bingo', 'blah',\n",
    "                   'blech', 'bleh', 'blimey', 'bonjour', 'boo', 'booh', 'boohoo',\n",
    "                   'booyah', 'bravo', 'brr', 'brrrr', 'btw', 'bwahaha', 'capeesh',\n",
    "                   'capisce', 'cheerio', 'cheers', 'ciao', 'cor', 'cowabunga',\n",
    "                   'crikey', 'cripes', 'da', 'dabba', 'dah', 'dammit', 'damn', 'dang',\n",
    "                   'darn', 'de', 'dee', 'di', 'dizamn', 'doh', 'doo', 'drat', 'duh',\n",
    "                   'dum', 'eeeek', 'eek', 'eep', 'egad', 'egads', 'eh', 'ehem', 'em',\n",
    "                   'er', 'eureka', 'eww', 'ewww', 'eyh', 'fiddledeedee', 'fie',\n",
    "                   'fore', 'foul', 'fuff', 'gah', 'gak', 'gee', 'geez', 'gesundheit',\n",
    "                   'giddyap', 'golly', 'gosh', 'grr', 'grrrr', 'ha', 'hah', 'haha',\n",
    "                   'hahaha', 'hallelujah', 'halloa', 'harrumph', 'harumph', 'haw',\n",
    "                   'heck', 'heck', 'heeey', 'heh', 'hehe', 'hey', 'hhh', 'hic', 'hm',\n",
    "                   'hmm', 'hmmm', 'hmmmm', 'hmmph', 'hmpf', 'ho', 'hola', 'hoo',\n",
    "                   'hooray', 'howdy', 'hrmm', 'hrmph', 'hrmph', 'hrrmph', 'hu', 'huh',\n",
    "                   'hullo', 'humph', 'hurrah', 'huzza', 'huzzah', 'ich', 'ick',\n",
    "                   'ixnay', 'jeepers', 'jeez', 'kaboom', 'kapow', 'kerwham', 'la',\n",
    "                   'lala', 'lo', 'lordy', 'meh', 'mhm', 'ml', 'mm', 'mmh', 'mmhm',\n",
    "                   'mmm', 'muahaha', 'mwah', 'mwahaha', 'na','nay','nah', 'nanu', 'nooo', 'nope',\n",
    "                   'nuh', 'oh', 'ohh', 'oho', 'oi', 'okeydoke', 'om', 'oof', 'ooh',\n",
    "                   'oomph', 'oooh', 'ooooh', 'oops', 'ouch', 'ow', 'oww', 'oy',\n",
    "                   'oyez', 'oyh', 'pew', 'pff', 'pffh', 'pfft', 'phew', 'phut',\n",
    "                   'phweep', 'phwoar', 'phwoarr', 'poof', 'poogh', 'prethee',\n",
    "                   'prithee', 'prosit', 'pssh', 'psst', 'queep', 'roger', 'salaam',\n",
    "                   'salam', 'sheesh', 'shh', 'shhh', 'shitfire', 'shoo', 'shoop',\n",
    "                   'shush', 'sigh', 'sssh', 'strewth', 'ta', 'tarnations', 'tchah',\n",
    "                   'teehee', 'tish', 'touché', 'tsk', 'tss', 'tut', 'uggh', 'ugh',\n",
    "                   'uh', 'uhh', 'uhm', 'um', 'umm', 'ummm', 'umph', 'unh', 'upadaisy',\n",
    "                   'upsadaisy', 'ur', 'urgh', 'vay', 'vayf', 'viva', 'voila', 'waa',\n",
    "                   'waaaaah', 'waah', 'wah', 'wahey', 'wassup', 'weee', 'welp',\n",
    "                   'wham', 'whamo', 'whee', 'whew', 'whizz', 'whoa',\n",
    "                   'whoo', 'whoopee','whoop', 'whoops', 'whoopsy', 'whoosh', 'woah', 'woo',\n",
    "                   'woohoo', 'wotcha', 'wotcher', 'wow', 'wowsers', 'wowsers',\n",
    "                   'wuzzup', 'wuzzup', 'wuzzup', 'ya', 'yabba', 'yada', 'yadda',\n",
    "                   'yak', 'yarooh', 'yay', 'yea', 'yeah', 'yech', 'yee', 'yeeeeaah',\n",
    "                   'yeehaw', 'yeow', 'yes', 'yessiree', 'yew', 'yikes', 'yippee',\n",
    "                   'yo', 'yoo', 'yoohoo', 'yow', 'yowza', 'yuck', 'yuh', 'zing',\n",
    "                   'zoiks', 'zomfg', 'zomg', 'zounds', 'zut']\n",
    "             \n",
    "import spacy\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "spacy_stopwords = sp.Defaults.stop_words\n",
    "type(spacy_stopwords)\n",
    "#spacy_exclude=['using','name','seem','give','make','keep','call','say','go','get','see','seems','seeming',\n",
    "#               'seemed','show','take','made','used','move','become','became','becoming','becomes','put','use']# serious\n",
    "\n",
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('en')\n",
    "stop_words1 = get_stop_words('english')\n",
    "#print(type(stop_words1))\n",
    "#print()\n",
    "#print(stop_words1)\n",
    "lib_stopwords=set(stop_words1)\n",
    "\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "#print(type(ENGLISH_STOP_WORDS))\n",
    "#print()\n",
    "#print(set(ENGLISH_STOP_WORDS))\n",
    "#sklearn_exclude=['find','get','found','go','see','seem','seems','give','seemed','take','keep','show','put','made'] # system  cry\n",
    "sklearn_stopwords=set(ENGLISH_STOP_WORDS)\n",
    "\n",
    "#spacy_stopwords.difference_update(set(spacy_exclude))\n",
    "#sklearn_stopwords.difference_update(set(sklearn_stopwords))\n",
    "#for removing \"just\" one item, use \"remove\"\n",
    "temp_1=set([])\n",
    "#temp_1.update(nltk_stopwords)\n",
    "#temp_1.update(lib_stopwords)\n",
    "#temp_1.update(sklearn_stopwords)\n",
    "#temp_1.update(spacy_stopwords)\n",
    "#temp_1.update(set(english_alghabet))\n",
    "#temp_1.update(set(numbers_remove)) \n",
    "#temp_1.update(set(miscellaneous_remove))\n",
    "#temp_1.update(set(interjection_remove))\n",
    "#temp_1.update(['rt','be','will','was','were','is','am','are','have','has','had','do','does','done'])\n",
    "#temp_1.update(['rt'])\n",
    "cachedStopWords=temp_1\n",
    "#len(cachedStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs= True\n",
    "        self.text = StringIO()\n",
    "    def handle_data(self, d):\n",
    "        self.text.write(d)\n",
    "    def get_data(self):\n",
    "        return self.text.getvalue()\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# function to convert nltk tag to wordnet tag\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))  \n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:        \n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "#print(lemmatizer.lemmatize(\"I am loving it\")) #I am loving it\n",
    "#print(lemmatizer.lemmatize(\"loving\")) #loving\n",
    "#print(lemmatizer.lemmatize(\"loving\", \"v\")) #love\n",
    "#print(lemmatize_sentence(\"I am loving it\")) #I be love it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning (text):\n",
    "    \n",
    "    #order of lines is important\n",
    "    \n",
    "    text=strip_tags(text)\n",
    "    #text=html.unescape(text)   # stripping or converting html entities \n",
    "    #text=saxutils.unescape(text) \n",
    "    \n",
    "    #convertings words that their lower and uper cases are different\n",
    "    text=re.sub(\" US | U\\.S\\. \", ' USA ', text) # before lower\n",
    "    \n",
    "    #converting\n",
    "    text = re.sub(\"“|”\", ''' \" ''', text)  #before next lines\n",
    "    text = re.sub(\"’|′|‘|`\", \" ' \", text)  #before next lines\n",
    "    \n",
    "    #removing tabs and lines\n",
    "    text=re.sub('\\t|\\n', ' ', text)\n",
    "    \n",
    "    #converting lower_case\n",
    "    text = text.lower() \n",
    "    \n",
    "    #converting\n",
    "#    text=re.sub('\\$|£|€|¥|dollar|dollars|yen|yens|euros', ' money ', text)   # not euro \n",
    "    \n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                               u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                               u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                               u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                               u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                               u\"\\U00002702-\\U000027B0\"\n",
    "                               u\"\\U000024C2-\\U0001F251\"\n",
    "                               u\"\\U0001f926-\\U0001f937\"\n",
    "                               u\"\\u2640-\\u2642\"\n",
    "                               u\"\\u2600-\\u2B55\"\n",
    "                               u\"\\u23cf\"\n",
    "                               u\"\\u23e9\"\n",
    "                               u\"\\u231a\"\n",
    "                               u\"\\u3030\"\n",
    "                               \"]+\", flags=re.UNICODE)\n",
    "    \n",
    "    #removing emoji\n",
    "    text = emoji_pattern.sub(r' ', text) \n",
    "\n",
    "    #removing emojis and non-ASCII characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+|,Ä¶',' ', text)  \n",
    "\n",
    "    #removeing http and https (URL)\n",
    "    text = re.sub(r'(http://|https://)\\S+', '', text)\n",
    "    \n",
    "    #removing www (URL)\n",
    "    text=re.sub(r'www\\.\\S+', '', text)\n",
    "    \n",
    "    #removing targets\n",
    "    text=re.sub('( |^)@\\S+', '', text) \n",
    "\n",
    "    '''\n",
    "    #removing common expressions\n",
    "    text=re.sub(\"looking forward to|look forward to|make sure|kidding me|\\\n",
    "                |in my opinion|by the way,|as soon as possible|shaking my head|i don't know|I do not know|\\\n",
    "                |in real life|quote of the day|as far as i know|shake my head|\\\n",
    "                |to be honest|in other words|let me know|just kidding|hope that helps|hat tip|\\\n",
    "                |just like that|happy birthday|never mind|well-done|\\\n",
    "                |in my humble opinion|happy new year|you're welcome|you are welcome| \\\n",
    "                |it doesn't matter|it does not matter|i think|i wonder|do you think\", ' ', text)  \n",
    "    '''\n",
    "    \n",
    "    #convertings\n",
    "    text=re.sub(\"can't\", 'cannot', text) # before other n't \n",
    "    text=re.sub(\"can not \", 'cannot ', text)  \n",
    "    text=re.sub(\"'ve\",' have', text)\n",
    "    text=re.sub(\"n't\",' not', text)\n",
    "    text=re.sub(\"'ll\",' will', text)\n",
    "#    text=re.sub(\"'d\",' would', text)\n",
    "    text=re.sub(\"'re\",' are', text)\n",
    "    text=re.sub(\"i'm\",'i am', text)\n",
    "    text=re.sub(\"&\",' and ', text)\n",
    "    text=re.sub(\" w/ \",' with ', text)\n",
    "    text=re.sub(\" w/i | w/in \",' within ', text)\n",
    "    text=re.sub(\" w/o \",' without ', text)\n",
    "    text=re.sub(\" c/o \",' care of ', text)\n",
    "    text=re.sub(\" h/t \",' hat tip ', text)\n",
    "    text=re.sub(\" b/c \",' because ', text)\n",
    "#    text=re.sub(\"=\",' equals to ', text)\n",
    "    text=re.sub(\"=\",' = ', text)\n",
    "#    text=re.sub(\"\\+\",' plus ', text)\n",
    "    text=re.sub(\"\\+\",' + ', text)\n",
    "    text=re.sub(\"united states\",'usa', text)\n",
    "    text=re.sub(\"united kingdom\",'uk', text)\n",
    "    text=re.sub(\" the us \",' usa ', text)\n",
    "    text=re.sub(\"start-up|start_up\",'startup', text)\n",
    "    text=re.sub(\"u\\.s\\.a\", 'usa', text)  #try text=re.sub(\"u.s.a\", 'usa', text) with text=substantially \n",
    "    #text=re.sub(\"aka\", 'also known as', text)     \n",
    "    text=re.sub(\"'\",\" ' \", text)     \n",
    "    \n",
    "    text= re.sub(\"(\\?)+\", '? ',text)     \n",
    "    text= re.sub(\"(!)+\", '! ',text)     \n",
    "    text= re.sub(\"(\\.\\.)+\", ' ',text)   \n",
    "\n",
    "#    text = \"\".join(lemmatize_sentence(text))\n",
    "    \n",
    "    #removing some special charachter  \n",
    "#    text= re.sub(\"[\\\"\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]``<>\\.{}`′’‘'_;•«»,@:~!\\=%&]+\", ' ',text) \n",
    "#    text= re.sub(\"[\\\"\\“\\”\\+\\-\\|\\*\\?\\(\\)\\/\\\\\\^\\[\\]\\.{}_`′’‘';•«,@:~!\\=%&]+\", ' ',text) \n",
    "    \n",
    "    #removing hashtag\n",
    "#    text=re.sub('#', ' ', text) \n",
    "    \n",
    "    #removing numbers not attached to alphabets\n",
    "    '''\n",
    "    text=re.sub(\"(^)(\\d+)?(\\.)?(\\d+)? \",' ',text)   #removing numer at the beginning\n",
    "    text=re.sub(\"(\\s)[0-9]?(\\.)?(\\d+) \",' ',text) #py6 and py9\n",
    "    text= re.sub(\" (\\.)(\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+) \", ' ',text)\n",
    "    text= re.sub(\" (\\d+)$\", ' ',text)\n",
    "    '''\n",
    "    #text=re.sub(\"\\S+(\\d+) \",' ',text) # alphabet+digit (attached)\n",
    "    #text=re.sub(\" (\\d+)\\S+\",' ',text) # digit+alphabet (attached)\n",
    "    #text=re.sub(\" \\S+(\\d+)\\S+ \",' ',text) # alphabet+digit+alphabet (attached)\n",
    "    #text=re.sub(\"(\\d+)\",' ',text)  #removing any number anywhere but keeps \\. for decimal numbers\n",
    "\n",
    "    #removing space\n",
    "    text=re.sub('\\s+',' ',text)    \n",
    "    \n",
    "    text=re.sub('(^)rt ','',text)    # if we do not want to remove stopwords\n",
    "\n",
    "#    text= nltk.word_tokenize(text) # necessary for removing stopwords\n",
    "    #text= text.split() #sometimes\n",
    "\n",
    "    #removing_stopwords \n",
    "    #text_without_sw = [word.lower() for word in text if word.lower() not in stopwords.words()] #very slow\n",
    "#    text = [word for word in text if word not in cachedStopWords]\n",
    "\n",
    "    #lemmatization\n",
    "    #text= [ lemm(word, pos=\"v\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"n\") for word in text]\n",
    "    #text= [ lemm(word, pos=\"a\") for word in text]\n",
    "    \n",
    "    #stemming \n",
    "    #text = [Stem(word) for word in text]\n",
    "    \n",
    "#    text=' '.join(text)\n",
    "#    text=re.sub(\"''\",'''\"''', text)    #since nltk.tokenize converts second \" to ''\"\n",
    "#    text=re.sub(\"``\",'''\"''', text)   # since nltk.tokenize converts first \" to \" ``\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "##cur.execute(\"SELECT user_id, tweet from ent_2019_100K limit 100000 \")\n",
    "cur.execute(\"SELECT user_id, tweet from ent_2019_1000k \")\n",
    "rows_ent = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_ent))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n#df_ent = pd.read_csv(\\'/archives1/Datasets/TweetsWorld/ent_tweets_world.csv\\', delimiter=\\'\\t\\', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\\ndf_ent = pd.read_csv(\\'ent_tweets_world.csv\\', delimiter=\\'\\t\\', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\\nprint(df_ent.shape)\\nprint(df_ent.columns)\\n#print(df_ent.head()) # Preview the first 5 lines of the loaded data \\n\\nrows_ent=list(df_ent[[\\'user_id\\', \\'tweet\\']].itertuples(index=False, name=None)) #rows_ent0\\n#rows_ent= list(zip(df_ent.user_id, df_ent.tweet))\\n#rows_ent=df_ent[[\\'user_id\\',\\'tweet\\']].apply(tuple, axis=1) \\ndel df_ent\\n\\nprint(\"Number of tweets in ent:\",len(rows_ent))  #rows_ent0\\nprint(\\'Memory size of ent:\\',sys.getsizeof(rows_ent)) #rows_ent0\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "#df_ent = pd.read_csv('/archives1/Datasets/TweetsWorld/ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "df_ent = pd.read_csv('ent_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "print(df_ent.shape)\n",
    "print(df_ent.columns)\n",
    "#print(df_ent.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_ent=list(df_ent[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_ent0\n",
    "#rows_ent= list(zip(df_ent.user_id, df_ent.tweet))\n",
    "#rows_ent=df_ent[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_ent\n",
    "\n",
    "print(\"Number of tweets in ent:\",len(rows_ent))  #rows_ent0\n",
    "print('Memory size of ent:',sys.getsizeof(rows_ent)) #rows_ent0\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from mng_2019_1000k \")\n",
    "rows_mng = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_mng))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46502302, 4)\n",
      "Index(['user_id', 'tweet', 'tweet_created_at', 'location_profile'], dtype='object')\n",
      "46502302\n",
      "memry size of mng: 402267520\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_mng = pd.read_csv('mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "#df_mng = pd.read_csv('/archives1/Datasets/TweetsWorld/mng_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df_mng.shape)\n",
    "print(df_mng.columns)\n",
    "#print(df_mng.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_mng=list(df_mng[['user_id', 'tweet']].itertuples(index=False, name=None)) #rows_mng0\n",
    "#rows_mng= list(zip(df_mng.user_id, df_mng.tweet))\n",
    "#rows_mng=df_mng[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_mng\n",
    "print(len(rows_mng)) #rows_mng0\n",
    "print('memry size of mng:', sys.getsizeof(rows_mng)) #rows_mng0\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import psycopg2\n",
    "con = psycopg2.connect(database=\"postgres\", user=\"postgres\", password=\"Jafarsql\", host=\"localhost\", port=\"5432\")\n",
    "print(\"Database opened successfully\")\n",
    "\n",
    "cur = con.cursor()\n",
    "cur.execute(\"SELECT user_id, tweet from public_2019_1000k\")\n",
    "rows_public = cur.fetchall()\n",
    "con.close()\n",
    "\n",
    "print(len(rows_public))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(72182875, 4)\n",
      "Index(['user_id', 'tweet', 'tweet_created_at', 'location_profile'], dtype='object')\n",
      "72182875\n",
      "memory size of public: 644355008\n"
     ]
    }
   ],
   "source": [
    "df_public = pd.read_csv('public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "#df_public = pd.read_csv('/archives1/Datasets/TweetsWorld/public_tweets_world.csv', delimiter='\\t', na_values=\".\",error_bad_lines=False)#,warn_bad_lines=False)\n",
    "\n",
    "print(df_public.shape)\n",
    "print(df_public.columns)\n",
    "#print(df_public.head()) # Preview the first 5 lines of the loaded data \n",
    "\n",
    "rows_public00=list(df_public[['user_id', 'tweet', 'tweet_created_at']].itertuples(index=False, name=None))\n",
    "#rows_public= list(zip(df_public.user_id, df_public.tweet))\n",
    "#rows_public=df_public[['user_id','tweet']].apply(tuple, axis=1) \n",
    "del df_public\n",
    "print(len(rows_public00))\n",
    "print('memory size of public:', sys.getsizeof(rows_public00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53069041\n",
      "1000000\n",
      "memory size of public: 8697464\n"
     ]
    }
   ],
   "source": [
    "rows_public0=[]\n",
    "for i in rows_public00:\n",
    "    if ('2021' not in i[2] ) and ('2020-12' not in i[2]) and ('2020-11' not in i[2]) and ('2020-10' not in i[2]):\n",
    "        rows_public0.append(i)\n",
    "\n",
    "        \n",
    "print(len(rows_public0))\n",
    "del rows_public00\n",
    "\n",
    "\n",
    "#with open(\"rand_inds3.txt\", \"rb\") as fp:   \n",
    "#    rand_inds3=pickle.load(fp)\n",
    "    \n",
    "    \n",
    "rand_inds0e=np.sort(random.sample(range(0, len(rows_public0)), 1000000))  \n",
    "\n",
    "rows_public=[]\n",
    "for i in rand_inds0e:\n",
    "    rows_public.append(rows_public0[i])\n",
    "print(len(rows_public))\n",
    "\n",
    "del rows_public0\n",
    "\n",
    "\n",
    "with open(\"rand_inds0e.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(rand_inds0e, fp , protocol=4)\n",
    "\n",
    "print('memory size of public:',sys.getsizeof(rows_public))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "t0 = time.time()\n",
    "\n",
    "ent_users_rows=[]\n",
    "ent_tweets_rows=[]\n",
    "for i in rows_ent:\n",
    "    ent_users_rows.append(i[0])\n",
    "    ent_tweets_rows.append(cleaning(i[1]))\n",
    "    \n",
    "print( time.time() - t0)\n",
    "\n",
    "#ent_users_rows_np=np.array(ent_users_rows)  \n",
    "#ent_users=np.unique(ent_users_rows_np)\n",
    "#print(len(ent_users))\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3395.7365942001343\n",
      "23261\n"
     ]
    }
   ],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "mng_users_rows=[]\n",
    "mng_tweets_rows=[]\n",
    "for i in rows_mng:\n",
    "    mng_users_rows.append(i[0])\n",
    "    mng_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "mng_users_rows_np=np.array(mng_users_rows)  \n",
    "mng_users=np.unique(mng_users_rows_np)\n",
    "print(len(mng_users))\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.00307559967041\n",
      "33096\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "public_users_rows=[]\n",
    "public_tweets_rows=[]\n",
    "\n",
    "for i in rows_public:\n",
    "    public_users_rows.append(i[0])\n",
    "    public_tweets_rows.append(cleaning(i[1]))\n",
    "\n",
    "print( time.time() - t0)\n",
    "\n",
    "public_users_rows_np=np.array(public_users_rows)  \n",
    "public_users=np.unique(public_users_rows_np)\n",
    "print(len(public_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder (tweets):\n",
    "    # padding after {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        \n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if len(tokenized_text)>max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "        segments_ids= segments_ids + [0] * (max_len_tokens+2 - len(segments_ids)) \n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,temp-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder2 (tweets):\n",
    "    #padding before {SEP}\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=20\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "\n",
    "        marked_text = '[CLS]'+ text \n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)\n",
    "#        print(temp)\n",
    "        # truncate if size of tekens is more than max_len_tokens\n",
    "        if temp>=max_len_tokens+2:\n",
    "#            print('a2',max_len_tokens+2)\n",
    "            tokenized_text= tokenized_text[0:max_len_tokens+2]\n",
    "#            print('a3',tokenized_text)\n",
    "            tokenized_text[max_len_tokens+2-1]=\"[SEP]\"\n",
    "#            print('a4',tokenized_text)\n",
    "        else:\n",
    "#            print(type(tokenized_text))\n",
    "            tokenized_text = tokenized_text + ['[PAD]'] * (max_len_tokens+1 - temp)+ ['[SEP]']\n",
    "#            print('a44',tokenized_text)\n",
    "\n",
    "#            tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#                sequences, maxlen=10, dtype='int32', padding='post',\n",
    "#                truncating='post', value=0.0)\n",
    "\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "#        print('a5',indexed_tokens)\n",
    "#        indexed_tokens = indexed_tokens + [0] * (max_len_tokens+2 - len(indexed_tokens))\n",
    "#        print('a6',indexed_tokens)\n",
    "\n",
    "#        segments_ids = [1] * len(tokenized_text)\n",
    "        segments_ids= [1]* min(temp,max_len_tokens+1) + [0] * (max_len_tokens+1 - temp)  + [1]\n",
    "#        print('a7',segments_ids) \n",
    "\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "\n",
    "        tweets_embedded[i]=token_embeddings\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedder0 (tweets):\n",
    "    #padding before {SEP} forcing zero\n",
    "    embedding_dim=768\n",
    "    t0 = time.time()\n",
    "    max_len_tokens=30\n",
    "    num_tweets=np.shape(tweets)[0]\n",
    "    tweets_embedded= np.zeros([num_tweets,max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "#    print('a11',np.shape(vector_temp))\n",
    "\n",
    "    #mng_full_embedding_word=[]\n",
    "#    mng_full_tokenized=[]\n",
    "    \n",
    "    for i, text in enumerate(tweets):\n",
    "        \n",
    "        \n",
    "                \n",
    "        marked_text = '[CLS]'+ text + '[SEP]'\n",
    "        tokenized_text = tokenizer.tokenize(marked_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "#        print('a1',tokenized_text)\n",
    "        temp=len(tokenized_text)-2\n",
    "        indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        with torch.no_grad():\n",
    "            outputs = model_bert(tokens_tensor, segments_tensors)\n",
    "            out = outputs[0]\n",
    "        token_embeddings = torch.squeeze(out, dim=0)  \n",
    "#        print('a8',token_embeddings)\n",
    "        token_embeddings=np.delete(token_embeddings, (0,-1), axis = 0)\n",
    "#        print('a88',len(token_embeddings))\n",
    "        if len(token_embeddings)>=max_len_tokens:\n",
    "            vector_temp= token_embeddings[0:max_len_tokens]\n",
    "#            print('a9',vector_temp)\n",
    "        else:\n",
    "            vector_temp = np.zeros([max_len_tokens,embedding_dim],dtype=\"float32\")\n",
    "            vector_temp[0:temp] = token_embeddings\n",
    "#            print('a99',vector_temp)\n",
    "        tweets_embedded[i]=vector_temp\n",
    "#        mng_full_tokenized.append(tokenized_text)\n",
    "\n",
    "#    print(np.shape(tweets_embedded))\n",
    "#    print( time.time() - t0)\n",
    "    return tweets_embedded    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aa=embedder0(['That is very good and joy '])\n",
    "#aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_inds1e=random.sample(range(0, 1000000), 300000) #200000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rand_inds1e.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(rand_inds1e, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_set=set()\n",
    "seed_public0=[]\n",
    "for i in rand_inds1e:\n",
    "    temp=public_tweets_rows[i]\n",
    "    if temp !='' and temp !=' ':\n",
    "        if temp not in temp_set:\n",
    "            seed_public0.append(public_tweets_rows[i])\n",
    "            temp_set.add(temp) # in order that we do not have repetative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280736"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(seed_public0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_public=seed_public0[0:200000]\n",
    "len(seed_public)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./seed_tweets_mng10m.txt\", \"rb\") as fp:   \n",
    "    seed_tweets_mng = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mng=[]\n",
    "for tweet in seed_tweets_mng:\n",
    "    seed_mng.append(cleaning(tweet))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_mng=seed_mng[0:40000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data=[1]*len(seed_mng)+[0]*len(seed_public)\n",
    "len(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mng\n",
      "mean length of tweets: 20.2439\n",
      "max length of tweets:  66\n",
      "std length of tweets:  7.279937343630546\n"
     ]
    }
   ],
   "source": [
    "df_mng = pd.DataFrame({'tweet':seed_mng})\n",
    "df_mng['len'] = df_mng['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "df_mng\n",
    "\n",
    "print('mng')\n",
    "print(\"mean length of tweets: \" + str(df_mng['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_mng['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_mng['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "public\n",
      "mean length of tweets: 14.828095\n",
      "max length of tweets:  86\n",
      "std length of tweets:  9.59740455653475\n"
     ]
    }
   ],
   "source": [
    "df_public = pd.DataFrame({'tweet':seed_public})\n",
    "df_public['len'] = df_public['tweet'].apply(lambda x: len(str(x).split(' ')))\n",
    "#df_public\n",
    "\n",
    "print('public')\n",
    "print(\"mean length of tweets: \" + str(df_public['len'].mean()))\n",
    "print(\"max length of tweets:  \" + str(df_public['len'].max()))\n",
    "print(\"std length of tweets:  \" + str(df_public['len'].std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "#print(\"test set size \" + str(len(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_test=embedder0(mng_all[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts=seed_mng+seed_public\n",
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in mng_tweets_rows:\n",
    "#    texts.append(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48.70391654968262"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "t0=time.time()\n",
    "train_texts_tokens=[]\n",
    "for text in train_texts:\n",
    "#    tokens=text.split()\n",
    "    tokens=nltk.word_tokenize(text)\n",
    "    train_texts_tokens.append(tokens)\n",
    "    \n",
    "print(len(train_texts_tokens))\n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "print(ft.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fasttext.util.reduce_model(ft, 100)\n",
    "#ft.get_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54.30865263938904"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "embedding_dim=300\n",
    "max_tokens=50\n",
    "#X_train_test=[]\n",
    "x_train=np.zeros([len(train_texts_tokens),max_tokens,embedding_dim],dtype='float32')\n",
    "\n",
    "for kk,tokens in enumerate(train_texts_tokens):\n",
    "    if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "        a1=[]\n",
    "        for token in tokens:\n",
    "            a1.append( ft.get_word_vector(token) )\n",
    "                    \n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "        if len(tokens)>max_tokens:\n",
    "            temp=a1[0:max_tokens]\n",
    "        elif len(tokens)==max_tokens:\n",
    "            temp=a1\n",
    "        else: # if len(tokens)<max_tokens:\n",
    "            temp[0:len(tokens)]=a1\n",
    "#        X_train_test.append(temp) \n",
    "        x_train[kk]=temp\n",
    "\n",
    "    else:\n",
    "        temp=np.zeros([max_tokens,embedding_dim])\n",
    "#        X_train_test.append(temp)\n",
    "        x_train[kk]=temp\n",
    "        \n",
    "time.time()-t0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "240000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.cast(x_train, tf.float32)\n",
    "y_train = tf.cast(y_data, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train1, x_test1, y_train, y_test = train_test_split(data, y_data, test_size=0.2, shuffle=True, stratify= y_data)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=50\n",
    "num_filters=100\n",
    "embedding_dim=300   #768 for bert\n",
    "dropout_rate=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 50, 300)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 50, 300, 1)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 50, 1, 100)   30100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 49, 1, 100)   60100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 48, 1, 100)   90100       reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 47, 1, 100)   120100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 46, 1, 100)   150100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 45, 1, 100)   180100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 44, 1, 100)   210100      reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 50, 1, 100)   400         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 49, 1, 100)   400         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 48, 1, 100)   400         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 47, 1, 100)   400         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 46, 1, 100)   400         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 45, 1, 100)   400         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 44, 1, 100)   400         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 1, 1, 100)    0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 100)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 1, 1, 700)    0           max_pooling2d[0][0]              \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "                                                                 max_pooling2d_2[0][0]            \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 700)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          358912      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          32896       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           8256        dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32)           2080        dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32)           0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16)           528         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16)           0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 8)            136         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 8)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            9           dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,377,645\n",
      "Trainable params: 1,376,245\n",
      "Non-trainable params: 1,400\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "#inputs = Input(shape=(sequence_length,), dtype='float32')\n",
    "\n",
    "#embedded_inputs = embedding_layer(inputs)\n",
    "#embedding_layer = Embedding(input_dim=20000, output_dim=embedding_dim, input_length=sequence_length, weights=[inputs])(inputs)\n",
    "\n",
    "#inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(embedded_inputs)\n",
    "inputs_reshaped = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "\n",
    "conv_1 = Conv2D(num_filters, kernel_size=(1, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_1 = LeakyReLU(alpha=0.2)(conv_1) #without activation at Conv2D\n",
    "conv_1 = BatchNormalization()(conv_1)\n",
    "\n",
    "conv_2 = Conv2D(num_filters, kernel_size=(2, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_2 = LeakyReLU(alpha=0.2)(conv_2)\n",
    "conv_2 = BatchNormalization()(conv_2)\n",
    "\n",
    "conv_3 = Conv2D(num_filters, kernel_size=(3, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_3 = LeakyReLU(alpha=0.2)(conv_3)\n",
    "conv_3 = BatchNormalization()(conv_3)\n",
    "\n",
    "conv_4 = Conv2D(num_filters, kernel_size=(4, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_4 = LeakyReLU(alpha=0.2)(conv_4)\n",
    "conv_4 = BatchNormalization()(conv_4)\n",
    "\n",
    "conv_5 = Conv2D(num_filters, kernel_size=(5, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_5 = LeakyReLU(alpha=0.2)(conv_5)\n",
    "conv_5 = BatchNormalization()(conv_5)\n",
    "\n",
    "conv_6 = Conv2D(num_filters, kernel_size=(6, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_6 = LeakyReLU(alpha=0.2)(conv_6)\n",
    "conv_6 = BatchNormalization()(conv_6)\n",
    "\n",
    "conv_7 = Conv2D(num_filters, kernel_size=(7, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_7 = LeakyReLU(alpha=0.2)(conv_7)\n",
    "conv_7 = BatchNormalization()(conv_7)\n",
    "\n",
    "conv_8 = Conv2D(num_filters, kernel_size=(8, embedding_dim), activation='relu', kernel_regularizer=regularizers.l2(3))(inputs_reshaped)\n",
    "#conv_8 = LeakyReLU(alpha=0.2)(conv_8)\n",
    "#conv_8 = BatchNormalization()(conv_8)\n",
    "\n",
    "maxpool_1 = MaxPool2D(pool_size=(sequence_length - 1 + 1, 1), strides=(1,1))(conv_1)\n",
    "maxpool_2 = MaxPool2D(pool_size=(sequence_length - 2 + 1, 1), strides=(1,1))(conv_2)\n",
    "maxpool_3 = MaxPool2D(pool_size=(sequence_length - 3 + 1, 1), strides=(1,1))(conv_3)\n",
    "maxpool_4 = MaxPool2D(pool_size=(sequence_length - 4 + 1, 1), strides=(1,1))(conv_4)\n",
    "maxpool_5 = MaxPool2D(pool_size=(sequence_length - 5 + 1, 1), strides=(1,1))(conv_5)\n",
    "maxpool_6 = MaxPool2D(pool_size=(sequence_length - 6 + 1, 1), strides=(1,1))(conv_6)\n",
    "maxpool_7 = MaxPool2D(pool_size=(sequence_length - 7 + 1, 1), strides=(1,1))(conv_7)\n",
    "maxpool_8 = MaxPool2D(pool_size=(sequence_length - 8 + 1, 1), strides=(1,1))(conv_8)\n",
    "\n",
    "#concatenated_e1 = Concatenate(axis=3)([maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5])\n",
    "concatenated_e1 = Concatenate(axis=3)([ maxpool_1, maxpool_2, maxpool_3, maxpool_4, maxpool_5, maxpool_6, maxpool_7 ])\n",
    "\n",
    "X = Flatten()(concatenated_e1)\n",
    "\n",
    "X = Dense(units=512, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=256, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=128, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=64, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=32, activation='linear')(X) \n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=16, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "X = Dense(units=8, activation='linear')(X)\n",
    "X = Dropout(dropout_rate)(X)\n",
    "\n",
    "#outputs = Dense(units=5, activation='softmax')(X) \n",
    "outputs = Dense(units=1, activation='sigmoid')(X) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "classifier.summary()\n",
    "#classifier.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3) , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.compile(optimizer=keras.optimizers.Adamax() , loss= 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#optim= adamax, adam\n",
    "#loss:categorical_crossentropy, KLDivergence, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# not good results ##type 2( small kernels like images)\n",
    "#sequence_length=16 # or 24 or 32 or 64 \n",
    "##encoder\n",
    "print(sequence_length,embedding_dim)\n",
    "inputs = Input(shape=(sequence_length,embedding_dim,), dtype='float32')\n",
    "\n",
    "x = Reshape((sequence_length, embedding_dim, 1))(inputs)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (4,4), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x)\n",
    "print(x.shape)\n",
    "x = Conv2D(8, (2, 2), activation='relu', padding='same')(x)\n",
    "print(x.shape)\n",
    "x = MaxPooling2D((2, 3), padding='same')(x) \n",
    "print(x.shape)\n",
    "\n",
    "#print(x.shape)\n",
    "\n",
    "x = Flatten()(x)\n",
    "print(np.shape(x))\n",
    "#x = Dense(1764, activation=\"relu\")(x)\n",
    "\n",
    "#x = Dense(units=8, activation='linear')(x)\n",
    "#x = Dropout(dropout_rate)(x)\n",
    "\n",
    "outputs = Dense(units=5, activation='softmax')(x) \n",
    "\n",
    "classifier = keras.Model(inputs, outputs)\n",
    "#optim = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "#classifier.compile(optimizer=optim)\n",
    "classifier.compile(optimizer=keras.optimizers.Adam() , loss= 'categorical_crossentropy', metrics=['accuracy'])\n",
    "classifier.summary()\n",
    "'''\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240000, 50, 300)\n",
      "Epoch 1/1000\n",
      "352/352 [==============================] - 497s 1s/step - loss: 4.2215 - accuracy: 0.8362 - val_loss: 0.2249 - val_accuracy: 1.0000\n",
      "Epoch 2/1000\n",
      "352/352 [==============================] - 455s 1s/step - loss: 0.3188 - accuracy: 0.9444 - val_loss: 0.1668 - val_accuracy: 0.9914\n",
      "Epoch 3/1000\n",
      "352/352 [==============================] - 453s 1s/step - loss: 0.2733 - accuracy: 0.9553 - val_loss: 0.2540 - val_accuracy: 0.9598\n",
      "Epoch 4/1000\n",
      "352/352 [==============================] - 458s 1s/step - loss: 0.2619 - accuracy: 0.9595 - val_loss: 0.2063 - val_accuracy: 0.9798\n",
      "Epoch 5/1000\n",
      "352/352 [==============================] - 450s 1s/step - loss: 0.2590 - accuracy: 0.9607 - val_loss: 0.2606 - val_accuracy: 0.9632\n",
      "Epoch 6/1000\n",
      "352/352 [==============================] - 450s 1s/step - loss: 0.2513 - accuracy: 0.9624 - val_loss: 0.1776 - val_accuracy: 0.9877\n",
      "Epoch 7/1000\n",
      "352/352 [==============================] - 450s 1s/step - loss: 0.2409 - accuracy: 0.9626 - val_loss: 0.2704 - val_accuracy: 0.9531\n",
      "Restoring model weights from the end of the best epoch.\n",
      "Epoch 00007: early stopping\n"
     ]
    }
   ],
   "source": [
    "monitor = EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "\n",
    "#history= classifier.fit(x_train,x_train,validation_data=(x_test,y_test),callbacks=[monitor],verbose=1,batch_size=32,epochs=1000)\n",
    "print(np.shape(x_train))\n",
    "\n",
    "history=classifier.fit(x_train,y_train,\n",
    "                        epochs=1000,\n",
    "                        callbacks=[monitor],\n",
    "                        batch_size=512, # or 64\n",
    "                        shuffle= True,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.25)\n",
    "\n",
    "#history = classifier.fit(x_train, y_train, epochs=8, batch_size=512, verbose=1, validation_split=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(5*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# for bert\\nt0=time.time()\\nmng_ind_detected=[]\\nb=mng_tweets_rows[0:200000]\\nmng_test_embedded=embedder0(b)\\ny_predicted=classifier.predict(mng_test_embedded)\\nfor ind, value in enumerate(y_predicted):\\n    if value >= 0.5:\\n        mng_ind_detected.append(ind)\\nprint(time.time()-t0) \\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# for bert\n",
    "t0=time.time()\n",
    "mng_ind_detected=[]\n",
    "b=mng_tweets_rows[0:200000]\n",
    "mng_test_embedded=embedder0(b)\n",
    "y_predicted=classifier.predict(mng_test_embedded)\n",
    "for ind, value in enumerate(y_predicted):\n",
    "    if value >= 0.5:\n",
    "        mng_ind_detected.append(ind)\n",
    "print(time.time()-t0) \n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71858.61234259605"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0=time.time()\n",
    "\n",
    "max_tokens=50\n",
    "embedding_dim=300\n",
    "batch_size=1000\n",
    "batch=0\n",
    "\n",
    "len_mng=len(mng_tweets_rows)\n",
    "results_mng=np.zeros([len_mng,1])\n",
    "\n",
    "while batch <len_mng:\n",
    "    test =  mng_tweets_rows [batch : batch + batch_size]\n",
    "    test_data=[]\n",
    "    \n",
    "    for tweet in test:\n",
    "    #    tokens=text.split()\n",
    "        tokens=nltk.word_tokenize(tweet)\n",
    "        if tokens !=\"\" and tokens!=' ' and  tokens!=[]:   \n",
    "            a1=[]\n",
    "            for token in tokens[0:max_tokens]:\n",
    "                a1.append( ft.get_word_vector(token) )\n",
    "            \n",
    "            a1=np.asarray(a1, dtype=np.float32)            \n",
    "            temp=np.zeros([max_tokens,embedding_dim])\n",
    "\n",
    "            if len(tokens)>max_tokens:\n",
    "                temp=a1[0:max_tokens]\n",
    "            elif len(tokens)==max_tokens:\n",
    "                temp=a1\n",
    "            else: #if len(tokens)<max_tokens:\n",
    "                temp[0:len(tokens)]=a1\n",
    "        \n",
    "            #x_test=temp.reshape((1,max_tokens,embedding_dim))  \n",
    "            #print(np.shape(temp))\n",
    "            #x_test = tf.cast(temp, tf.float32)\n",
    "            test_data.append(temp)\n",
    "            \n",
    "        else:\n",
    "            test_data.append(np.zeros([max_tokens,embedding_dim]))\n",
    "              \n",
    "#    test_data = tf.cast(test_data, tf.float32)\n",
    "    test_data = np.asarray(test_data, dtype=np.float32)\n",
    "    res_test=classifier.predict(test_data)\n",
    "    results_mng [ batch: batch +len (res_test)]= res_test\n",
    "    batch += batch_size\n",
    "     \n",
    "time.time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46502302"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(results_mng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46503000"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46502302"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_mng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(10*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mng_results300.txt\", \"wb\") as fp:   \n",
    "    pickle.dump(results_mng, fp , protocol=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
